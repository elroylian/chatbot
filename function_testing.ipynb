{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import streamlit as st\n",
    "\n",
    "# Load .env from the project root\n",
    "env_path = Path('..') / '.env'  # Go one directory up to locate .env\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY']= st.secrets[\"EXTRA_Langchain_key\"]\n",
    "# os.environ['LANGCHAIN_PROJECT']=\"pr-advanced-theism-85\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunk Retrieval using Metadata filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from utils.chunk_doc import get_retriever, get_vector_store\n",
    "\n",
    "\n",
    "\n",
    "# llm = ChatOpenAI(\n",
    "#     model=\"gpt-4o-mini\",\n",
    "#     api_key=st.secrets[\"OpenAI_key\"]\n",
    "# )\n",
    "\n",
    "vector_store = get_vector_store()\n",
    "\n",
    "query = \"What is Insertion Sort?\"\n",
    "metadata_filter = {\"keywords\": \"Insertion\"}\n",
    "# response = vector_store.search(query,search_type=\"mmr\", k=5, fetch_k=10)\n",
    "# print(response)\n",
    "found_docs = vector_store.max_marginal_relevance_search(query, filter=metadata_filter)\n",
    "print(found_docs)\n",
    "for i, doc in enumerate(found_docs):\n",
    "    print(f\"{i + 1}.\", doc.page_content, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Generation using LLAMA 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "from utils.custom_embeddings import MyEmbeddings\n",
    "from utils.chunk_doc import get_vector_store\n",
    "\n",
    "embedding_func = MyEmbeddings()\n",
    "\n",
    "# Initialize Ollama LLM\n",
    "llm = OllamaLLM(\n",
    "    # model=\"gemma2:2b\",\n",
    "    model = \"llama3.2:latest\",\n",
    "    base_url=\"http://localhost:11434\"  # Adjust this URL if needed\n",
    ")\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Define a prompt template for Ollama to generate keywords\n",
    "# Gemma2:2b Template\n",
    "# keyword_prompt_template = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\"system\", \"You are an assistant that generates keywords for a chunk of text. The keywords must be single words or two-word phrases. Format the output as: ['keyword1', 'keyword2']\"),\n",
    "#         (\"human\", \"Extract relevant keywords for the following chunk:\\n\\n{chunk_text}\")\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# Llama3.2:1b Template\n",
    "keyword_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an assistant that generates keywords for a chunk of text. \"\n",
    "                   \"Your response should only contain keywords in json format.\"),\n",
    "        (\"human\", \"Extract relevant keywords from the following chunk:\\n\\n{chunk_text}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = keyword_prompt_template | llm\n",
    "\n",
    "# Initialize Vector Store\n",
    "vector_store = get_vector_store()\n",
    "\n",
    "def split_chunks():\n",
    "    try:\n",
    "        from pathlib import Path\n",
    "        from langchain_core.documents import Document\n",
    "        from langchain_text_splitters import RecursiveCharacterTextSplitter as Rec\n",
    "        \n",
    "        # Path to markdown directory\n",
    "        md_dir = Path(\"../data/md/\")\n",
    "        chunk_id_counter = 1  # Initialize a counter for unique chunk IDs\n",
    "        ids = []\n",
    "        documents = []\n",
    "\n",
    "        # Loop through all markdown files in the md directory\n",
    "        for md_file in md_dir.glob(\"*.md\"):\n",
    "            with open(md_file, \"r\") as f:\n",
    "                md_content = f.read()\n",
    "\n",
    "            # Chunk the markdown content\n",
    "            text_splitter = Rec(\n",
    "                chunk_size=2000,\n",
    "                chunk_overlap=500,\n",
    "                length_function=len,\n",
    "                add_start_index=True\n",
    "            )\n",
    "            chunks = text_splitter.split_text(md_content)\n",
    "            \n",
    "            for chunk in chunks:\n",
    "                # Generate keywords for the chunk using Ollama\n",
    "                response = chain.invoke({\"chunk_text\": chunk})\n",
    "                \n",
    "                import json\n",
    "                # Convert the JSON string to a Python dictionary\n",
    "                dictionary_output = json.loads(response)\n",
    "\n",
    "                # Access the \"keywords\" list\n",
    "                keywords_list = dictionary_output[\"keywords\"]\n",
    "                \n",
    "                # Create a Document object with metadata for the chunk, including keywords\n",
    "                document_to_add = Document(\n",
    "                    page_content=chunk,\n",
    "                    metadata={\"source\": str(md_file), \"keywords\": str(keywords_list)}\n",
    "                )\n",
    "                \n",
    "                documents.append(document_to_add)\n",
    "                ids.append(str(chunk_id_counter))  # Add document ID to the list\n",
    "                chunk_id_counter += 1  # Increment the ID counter\n",
    "        \n",
    "        # Assuming vector_store is defined and initialized elsewhere\n",
    "        vector_store.add_documents(documents=documents, ids=ids)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    # split_chunks()\n",
    "    \n",
    "    # print(response)\n",
    "\n",
    "    response = chain.invoke({\"chunk_text\": \"\"\" ###### 2.1.1 Insertion\n",
    "\n",
    "In general when people talk about insertion with respect to linked lists of any\n",
    "form they implicitly refer to the adding of a node to the tail of the list. When\n",
    "you use an API like that of DSA and you see a general purpose method that\n",
    "adds a node to the list, you can assume that you are adding the node to the tail\n",
    "of the list not the head.\n",
    "\n",
    "Adding a node to a singly linked list has only two cases:\n",
    "\n",
    "1. head = in which case the node we are adding is now both the head and\n",
    "_∅_\n",
    "_tail of the list; or_\n",
    "\n",
    "2. we simply need to append our node onto the end of the list updating the\n",
    "_tail reference appropriately._\n",
    "\n",
    "1) algorithm Add(value)\n",
    "2) **Pre: value is the value to add to the list**\n",
    "3) **Post: value has been placed at the tail of the list**\n",
    "4) _n_ node(value)\n",
    "_←_\n",
    "5) **if head =**\n",
    "_∅_\n",
    "6) _head_ _n_\n",
    "_←_\n",
    "7) _tail_ _n_\n",
    "_←_\n",
    "8) **else**\n",
    "9) _tail.Next_ _n_\n",
    "_←_\n",
    "10) _tail_ _n_\n",
    "_←_\n",
    "11) **end if**\n",
    "12) end Add\n",
    "\n",
    "As an example of the previous algorithm consider adding the following sequence of integers to the list: 1, 45, 60, and 12, the resulting list is that of\n",
    "Figure 2.2.\n",
    "\n",
    "###### 2.1.2 Searching\n",
    "\n",
    "Searching a linked list is straightforward: we simply traverse the list checking\n",
    "the value we are looking for with the value of each node in the linked list. The\n",
    "algorithm listed in this section is very similar to that used for traversal in 2.1.4.\n",
    "_§_\n",
    "\n",
    "\n",
    "-----\n",
    "\n",
    "_CHAPTER 2. LINKED LISTS_ 11\n",
    "\n",
    "1) algorithm Contains(head, value)\n",
    "2) **Pre: head is the head node in the list**\n",
    "3) _value is the value to search for_\n",
    "4) **Post: the item is either in the linked list, true; otherwise false**\n",
    "5) _n_ _head_\n",
    "_←_\n",
    "6) **while n** = **and n.Value** = value\n",
    "_̸_ _∅_ _̸_\n",
    "7) _n_ _n.Next_\n",
    "_←_\n",
    "8) **end while**\n",
    "9) **if n =**\n",
    "_∅_\n",
    "10) **return false**\n",
    "11) **end if**\n",
    "12) **return true**\n",
    "13) end Contains\n",
    "\n",
    "###### 2.1.3 Deletion\n",
    "\n",
    "Deleting a node from a linked list is straightforward but there are a few cases\n",
    "we need to account for:\n",
    "\n",
    "1. the list is empty; or\n",
    "\n",
    "2. the node to remove is the only node in the linked list; or\n",
    "\n",
    "3. we are removing the head node; or\n",
    "\n",
    "4. we are removing the tail node; or\n",
    "\n",
    "5. the node to remove is somewhere in between the head and tail; or\n",
    "\n",
    "6. the item to remove doesn’t exist in the linked list\n",
    "\n",
    "The algorithm whose cases we have described will remove a node from anywhere within a list irrespective of whether the node is the head etc. If you know\n",
    "that items will only ever be removed from the head or tail of the list then you\n",
    "can create much more concise algorithms. In the case of always removing from\n",
    "the front of the linked list deletion becomes an O(1) operation.\"\"\"})\n",
    "\n",
    "    # print(dictionary_output)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from utils.custom_embeddings import MyEmbeddings\n",
    "import os\n",
    "import streamlit as st\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import OllamaLLM\n",
    "from utils.chunk_doc import get_vector_store\n",
    "\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY']= st.secrets[\"EXTRA_Langchain_key\"]\n",
    "os.environ['LANGCHAIN_PROJECT']=\"chatbot-test\"\n",
    "\n",
    "\n",
    "\n",
    "embedding_func = MyEmbeddings()\n",
    "\n",
    "\n",
    "# Multi Query: Different Perspectives\n",
    "template = \"\"\"You are an AI language model assistant. Your task is to generate five \n",
    "different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by a single newline. Original question: {question}\"\"\"\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "gpt4 = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    # api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    api_key=st.secrets[\"OpenAI_key\"],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# llm = OllamaLLM(model=\"gemma2:2b\", base_url=\"http://localhost:11434\")\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_perspectives \n",
    "    | gpt4\n",
    "    | StrOutputParser() \n",
    "    | (lambda x: [line for line in x.split(\"\\n\") if line.strip() != \"\"])  # Ensure empty strings are removed\n",
    ")\n",
    "\n",
    "from langchain.load import dumps, loads\n",
    "\n",
    "def get_unique_union(documents: list[list]):\n",
    "    \"\"\" Unique union of retrieved docs \"\"\"\n",
    "    # Flatten list of lists, and convert each Document to string\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    # Get unique documents\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "    # Return\n",
    "    return [loads(doc) for doc in unique_docs]\n",
    "\n",
    "# Initialize ChromaDB client\n",
    "vector_store = get_vector_store()\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# Retrieve\n",
    "question = \"What is Insertion Sort?\"\n",
    "retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
    "docs = retrieval_chain.invoke({\"question\":question})\n",
    "# print(docs)\n",
    "len(docs)\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | prompt\n",
    "    | gpt4\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\":question})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG-Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_chroma import Chroma\n",
    "from utils.custom_embeddings import MyEmbeddings\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from utils.chunk_doc import get_retriever, get_vector_store\n",
    "\n",
    "\n",
    "embedding_func = MyEmbeddings()\n",
    "\n",
    "\n",
    "# RAG-Fusion: Related\n",
    "template = \"\"\"You are a helpful assistant that generates multiple search queries based on a single input query. \\n\n",
    "Generate multiple search queries related to: {question} \\n\n",
    "Output (4 queries):\"\"\"\n",
    "prompt_rag_fusion = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    # api_key=st.secrets[\"OpenAI_key\"],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_rag_fusion \n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")\n",
    "\n",
    "from langchain.load import dumps, loads\n",
    "\n",
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    \"\"\" Reciprocal_rank_fusion that takes multiple lists of ranked documents \n",
    "        and an optional parameter k used in the RRF formula \"\"\"\n",
    "    \n",
    "    # Initialize a dictionary to hold fused scores for each unique document\n",
    "    fused_scores = {}\n",
    "\n",
    "    # Iterate through each list of ranked documents\n",
    "    for docs in results:\n",
    "        # Iterate through each document in the list, with its rank (position in the list)\n",
    "        for rank, doc in enumerate(docs):\n",
    "            # Convert the document to a string format to use as a key (assumes documents can be serialized to JSON)\n",
    "            doc_str = dumps(doc)\n",
    "            # If the document is not yet in the fused_scores dictionary, add it with an initial score of 0\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            # Retrieve the current score of the document, if any\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            # Update the score of the document using the RRF formula: 1 / (rank + k)\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "\n",
    "    # Sort the documents based on their fused scores in descending order to get the final reranked results\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "\n",
    "    # Return the reranked results as a list of tuples, each containing the document and its fused score\n",
    "    return reranked_results\n",
    "\n",
    "# Initialize Vector Store\n",
    "# vector_store = get_vector_store()\n",
    "\n",
    "retriever = get_retriever()\n",
    "\n",
    "# Retrieve\n",
    "question = \"What is Insertion Sort?\"\n",
    "retrieval_chain_rag_fusion  = generate_queries | retriever.map() | reciprocal_rank_fusion\n",
    "docs = retrieval_chain.invoke({\"question\":question})\n",
    "# print(docs)\n",
    "len(docs)\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\":question})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_chroma import Chroma\n",
    "from utils.custom_embeddings import MyEmbeddings\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from utils.chunk_doc import get_retriever, get_vector_store\n",
    "from prompt_templates.retrieval_check import get_rc_chain\n",
    "import streamlit as st\n",
    "from langchain_core.messages import HumanMessage\n",
    "from utils.image_processing import process_image, encode_image\n",
    "from prompt_templates.image_template import get_image_chain\n",
    "\n",
    "embedding_func = MyEmbeddings()\n",
    "\n",
    "def read_image_bytes(image_path):\n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        return image_file.read()\n",
    "\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    # api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    api_key=st.secrets[\"OpenAI_key\"],\n",
    "    temperature=0\n",
    ")\n",
    "import base64\n",
    "\n",
    "\n",
    "img = read_image_bytes('46bfac9.png')\n",
    "\n",
    "\n",
    "image_data = base64.b64encode(img).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "\n",
    "image_chain = get_image_chain(llm)\n",
    "\n",
    "message_content = [\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"}\n",
    "                    }\n",
    "                ]\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"\"),\n",
    "        (\n",
    "            \"human\",\n",
    "            [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Describe the image provided\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": \"data:image/jpeg;base64,{image_data}\"},\n",
    "                }\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({\"image_data\": image_data})\n",
    "print(response.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve\n",
    "question = \"Okay thank you so much thats all?\"\n",
    "retrieval_chain  = get_rc_chain(llm)\n",
    "response = retrieval_chain.invoke({\"input\":question})\n",
    "print(response)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.db_connection import ChatDatabase\n",
    "\n",
    "db = ChatDatabase('chat.db')\n",
    "\n",
    "result = db.load_chat_history(chat_id=\"638c132f-ecdb-4357-9b8c-3dff0c396cb1_1\",user_id=\"638c132f-ecdb-4357-9b8c-3dff0c396cb1\")\n",
    "\n",
    "for msg in result:\n",
    "    print(f'{msg[\"role\"]}: {msg[\"content\"]}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should Analyze:  False\n",
      "Time Threshold:  False\n",
      "Interaction Threshold:  False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "def should_analyze_user_level(user_id):\n",
    "    \"\"\"Determine if it's time to analyze the user's level.\"\"\"\n",
    "    last_analysis = db.get_last_analysis_timestamp(user_id)\n",
    "    \n",
    "    # If no previous analysis, definitely analyze\n",
    "    if last_analysis is None:\n",
    "        db.update_analysis_timestamp(user_id)\n",
    "        return False\n",
    "        \n",
    "    \n",
    "    # Get recent interactions count\n",
    "    recent_history = db.load_chat_history(user_id, f\"{user_id}_1\")\n",
    "    last_analysis_datetime = datetime.fromisoformat(last_analysis) if isinstance(last_analysis, str) else last_analysis\n",
    "    \n",
    "    # Count only messages after last analysis\n",
    "    interaction_count = 0\n",
    "    for message in recent_history:\n",
    "        message_timestamp = message.get(\"timestamp\")\n",
    "        \n",
    "        # Convert string timestamp to datetime\n",
    "        message_datetime = datetime.fromisoformat(message_timestamp)\n",
    "        \n",
    "        \n",
    "        if message_datetime and message[\"role\"] == \"user\":\n",
    "            if message_datetime > last_analysis_datetime:\n",
    "                interaction_count += 1\n",
    "    \n",
    "    # Criteria: At least 7 days and 10 interactions since last analysis\n",
    "    time_threshold = datetime.now() - last_analysis_datetime >= timedelta(days=7)\n",
    "    interaction_threshold = interaction_count >= 5\n",
    "    # print(\"Last Analysis: \", last_analysis_datetime)\n",
    "    # print(\"Current Time: \", datetime.now())\n",
    "    # print(\"Time Threshold: \", time_threshold)\n",
    "    # print(\"Interaction Count: \", interaction_count)\n",
    "    print(\"Should Analyze: \", time_threshold or interaction_threshold)\n",
    "    print(\"Time Threshold: \", time_threshold)\n",
    "    print(\"Interaction Threshold: \", interaction_threshold)\n",
    "    \n",
    "    return time_threshold or interaction_threshold\n",
    "\n",
    "should_analyze_user_level(\"638c132f-ecdb-4357-9b8c-3dff0c396cb1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insertion sort?\n",
      "**1. Simple Definition:**  \n",
      "Insertion sort is like sorting a hand of playing cards. You take one card at a time and place it in the right position among the cards you’ve already sorted. \n",
      "\n",
      "**2. Basic Step-by-Step Explanation with Example:**  \n",
      "Let’s say we have a small list of numbers: [4, 3, 2, 1, 5]. Here’s how insertion sort works:  \n",
      "- Start with the first number (4). It’s already sorted.  \n",
      "- Take the next number (3). Compare it with 4. Since 3 is smaller, move 4 to the right and place 3 in the first position: [3, 4, 2, 1, 5].  \n",
      "- Next, take 2. Compare it with 4 and 3, moving them to the right, and place 2 at the start: [2, 3, 4, 1, 5].  \n",
      "- Now, take 1. Move 2, 3, and 4 to the right and place 1 at the start: [1, 2, 3, 4, 5].  \n",
      "- Finally, 5 is already in the right place, so the sorted list is [1, 2, 3, 4, 5].\n",
      "\n",
      "**3. Very Basic Time Complexity:**  \n",
      "- Fast when the list is nearly sorted.  \n",
      "- Slow for a completely random list.\n",
      "\n",
      "**4. One Simple Real-World Application:**  \n",
      "Insertion sort is useful for organizing a small list of items, like sorting names in a contact list on your phone.\n",
      "\n",
      "By using this method, you can easily keep your list in order as you add new names.\n",
      "do you have the python code for it\n",
      "Certainly! Here is a simple implementation of the insertion sort algorithm in Python:\n",
      "\n",
      "```python\n",
      "def insertion_sort(arr):\n",
      "    # Traverse through 1 to len(arr)\n",
      "    for i in range(1, len(arr)):\n",
      "        key = arr[i]  # The current element to be positioned\n",
      "        j = i - 1\n",
      "\n",
      "        # Move elements of arr[0..i-1], that are greater than key,\n",
      "        # to one position ahead of their current position\n",
      "        while j >= 0 and arr[j] > key:\n",
      "            arr[j + 1] = arr[j]\n",
      "            j -= 1\n",
      "        arr[j + 1] = key  # Place the key in its correct position\n",
      "\n",
      "# Example usage\n",
      "if __name__ == \"__main__\":\n",
      "    arr = [6, 5, 3, 2, 8]\n",
      "    insertion_sort(arr)\n",
      "    print(\"Sorted array:\", arr)\n",
      "```\n",
      "\n",
      "### Explanation of the Code:\n",
      "- The function `insertion_sort` takes a list `arr` as input.\n",
      "- It iterates through the list starting from the second element (index 1).\n",
      "- For each element, it compares it with the elements before it and shifts those that are greater to the right.\n",
      "- Finally, it places the current element (key) in its correct position.\n",
      "\n",
      "### Time Complexity:\n",
      "- **Best Case:** O(n) when the array is already sorted.\n",
      "- **Average and Worst Case:** O(n²) when the array is in reverse order or randomly ordered. \n",
      "\n",
      "Feel free to run the code and test it with different input arrays!\n",
      "bubble sort?\n",
      "**1. Simple Definition:**  \n",
      "Bubble sort is a straightforward sorting algorithm that repeatedly steps through the list, compares adjacent elements, and swaps them if they are in the wrong order. The process is repeated until the list is sorted.\n",
      "\n",
      "**2. Basic Step-by-Step Explanation with Example:**  \n",
      "Consider the list [5, 3, 8, 4, 2]. Here’s how bubble sort works:  \n",
      "- **First Pass:**  \n",
      "  - Compare 5 and 3. Since 5 > 3, swap them: [3, 5, 8, 4, 2].  \n",
      "  - Compare 5 and 8. No swap needed: [3, 5, 8, 4, 2].  \n",
      "  - Compare 8 and 4. Swap them: [3, 5, 4, 8, 2].  \n",
      "  - Compare 8 and 2. Swap them: [3, 5, 4, 2, 8].  \n",
      "- **Second Pass:**  \n",
      "  - Compare 3 and 5. No swap: [3, 5, 4, 2, 8].  \n",
      "  - Compare 5 and 4. Swap: [3, 4, 5, 2, 8].  \n",
      "  - Compare 5 and 2. Swap: [3, 4, 2, 5, 8].  \n",
      "  - Compare 5 and 8. No swap: [3, 4, 2, 5, 8].  \n",
      "- **Third Pass:**  \n",
      "  - Compare 3 and 4. No swap: [3, 4, 2, 5, 8].  \n",
      "  - Compare 4 and 2. Swap: [3, 2, 4, 5, 8].  \n",
      "  - Compare 4 and 5. No swap: [3, 2, 4, 5, 8].  \n",
      "  - Compare 5 and 8. No swap: [3, 2, 4, 5, 8].  \n",
      "- **Fourth Pass:**  \n",
      "  - Compare 3 and 2. Swap: [2, 3, 4, 5, 8].  \n",
      "  - The list is now sorted: [2, 3, 4, 5, 8].\n",
      "\n",
      "**3. Very Basic Time Complexity:**  \n",
      "- **Best Case:** O(n) when the list is already sorted (with an optimization to stop early).\n",
      "- **Average and Worst Case:** O(n²) when the list is in reverse order or randomly ordered.\n",
      "\n",
      "**4. One Simple Real-World Application:**  \n",
      "Bubble sort can be used in educational contexts to teach sorting concepts due to its simplicity, but it is not efficient for large datasets.\n",
      "\n",
      "### Python Code for Bubble Sort:\n",
      "Here’s a simple implementation of bubble sort in Python:\n",
      "\n",
      "```python\n",
      "def bubble_sort(arr):\n",
      "    n = len(arr)\n",
      "    # Traverse through all array elements\n",
      "    for i in range(n):\n",
      "        # Last i elements are already sorted\n",
      "        for j in range(0, n-i-1):\n",
      "            # Traverse the array from 0 to n-i-1\n",
      "            # Swap if the element found is greater than the next element\n",
      "            if arr[j] > arr[j + 1]:\n",
      "                arr[j], arr[j + 1] = arr[j + 1], arr[j]\n",
      "\n",
      "# Example usage\n",
      "if __name__ == \"__main__\":\n",
      "    arr = [64, 34, 25, 12, 22, 11, 90]\n",
      "    bubble_sort(arr)\n",
      "    print(\"Sorted array:\", arr)\n",
      "```\n",
      "\n",
      "Feel free to run the code and test it with different input arrays!\n",
      "Why is Performance of Algorithms Important ?\n",
      "The performance of algorithms is crucial for several reasons:\n",
      "\n",
      "1. **Efficiency**: Algorithms are designed to solve problems, and their efficiency directly impacts how quickly and effectively they can do so. An efficient algorithm can handle larger inputs and produce results faster, which is essential in real-world applications.\n",
      "\n",
      "2. **Resource Utilization**: Algorithms consume computational resources such as time (execution speed) and space (memory usage). Understanding performance helps in optimizing resource utilization, which is particularly important in environments with limited resources, such as embedded systems or mobile devices.\n",
      "\n",
      "3. **Scalability**: As the size of input data grows, the performance of an algorithm can vary significantly. An algorithm that performs well on small datasets may become impractical on larger ones. Analyzing performance helps in selecting algorithms that scale effectively with increasing data sizes.\n",
      "\n",
      "4. **User Experience**: In applications where user interaction is involved, the speed of algorithms can significantly affect user experience. Slow algorithms can lead to delays and frustration, while fast algorithms can enhance usability and satisfaction.\n",
      "\n",
      "5. **Cost Efficiency**: In commercial applications, the cost of computing resources can be significant. Efficient algorithms can reduce the need for expensive hardware and lower operational costs.\n",
      "\n",
      "6. **Algorithm Comparison**: Understanding the performance of different algorithms allows developers to choose the most suitable one for a specific problem. This comparison often involves analyzing time complexity (how the execution time grows with input size) and space complexity (how memory usage grows with input size).\n",
      "\n",
      "7. **Theoretical Insights**: Performance analysis provides insights into the theoretical limits of computation and helps in understanding the fundamental principles of computer science.\n",
      "\n",
      "### Example\n",
      "Consider sorting algorithms:\n",
      "- **Quick Sort** has an average time complexity of \\(O(n \\log n)\\) and is generally faster in practice for large datasets.\n",
      "- **Bubble Sort**, on the other hand, has a time complexity of \\(O(n^2)\\) and is inefficient for large datasets.\n",
      "\n",
      "In this case, choosing Quick Sort over Bubble Sort for sorting a large array can lead to significant performance improvements.\n",
      "\n",
      "### Conclusion\n",
      "In summary, the performance of algorithms is vital for ensuring that software applications are efficient, scalable, and cost-effective, ultimately leading to better user experiences and resource management.\n",
      "What is Recursion?\n",
      "Recursion is a programming and mathematical concept where a function calls itself in order to solve a problem. It is a powerful technique used to break down complex problems into simpler subproblems. A recursive function typically has two main components:\n",
      "\n",
      "1. **Base Case**: This is the condition under which the recursion stops. It prevents the function from calling itself indefinitely and provides a simple, non-recursive solution to the simplest instance of the problem.\n",
      "\n",
      "2. **Recursive Case**: This is where the function calls itself with a modified argument, moving closer to the base case. The recursive case breaks the problem into smaller subproblems.\n",
      "\n",
      "### How Recursion Works\n",
      "When a recursive function is called, it performs its operations and may call itself with new parameters. Each call creates a new instance of the function, which has its own set of parameters and local variables. The function continues to call itself until it reaches the base case, at which point it starts returning values back up the call stack.\n",
      "\n",
      "### Example: Factorial Calculation\n",
      "A classic example of recursion is the calculation of the factorial of a number \\( n \\) (denoted as \\( n! \\)), which is the product of all positive integers up to \\( n \\).\n",
      "\n",
      "The recursive definition of factorial is:\n",
      "- **Base Case**: \\( 0! = 1 \\)\n",
      "- **Recursive Case**: \\( n! = n \\times (n-1)! \\) for \\( n > 0 \\)\n",
      "\n",
      "Here’s how you might implement this in Python:\n",
      "\n",
      "```python\n",
      "def factorial(n):\n",
      "    if n == 0:  # Base case\n",
      "        return 1\n",
      "    else:  # Recursive case\n",
      "        return n * factorial(n - 1)\n",
      "```\n",
      "\n",
      "### Time and Space Complexity\n",
      "- **Time Complexity**: The time complexity of a recursive function depends on the number of recursive calls made. For the factorial example, it is \\( O(n) \\) because there are \\( n \\) calls before reaching the base case.\n",
      "- **Space Complexity**: The space complexity is also \\( O(n) \\) due to the call stack that grows with each recursive call. Each call consumes stack space until the base case is reached and the calls start returning.\n",
      "\n",
      "### Advantages of Recursion\n",
      "- **Simplicity**: Recursive solutions can be more straightforward and easier to understand than their iterative counterparts, especially for problems that have a natural recursive structure (e.g., tree traversals, combinatorial problems).\n",
      "- **Reduced Code Size**: Recursive functions can often be written in fewer lines of code.\n",
      "\n",
      "### Disadvantages of Recursion\n",
      "- **Performance**: Recursive functions can be less efficient than iterative solutions due to the overhead of multiple function calls and the risk of stack overflow for deep recursions.\n",
      "- **Memory Usage**: Each recursive call consumes stack space, which can lead to higher memory usage compared to iterative solutions.\n",
      "\n",
      "### Conclusion\n",
      "Recursion is a fundamental concept in computer science that allows for elegant solutions to complex problems. Understanding how to implement and analyze recursive functions is essential for effective programming and algorithm design.\n",
      "can you explain all these questions\n",
      "Sure! Let’s break down these questions in a friendly and beginner-friendly way.\n",
      "\n",
      "---\n",
      "\n",
      "**What We're Looking At**\n",
      "\n",
      "I see you're working with a quiz on Data Structures and Algorithms (DSA)! This looks like a great opportunity to dive into linked lists, which are a fundamental concept in programming. We’ll explore how to manage student data using linked lists, which are like a chain of nodes, each holding information about a student.\n",
      "\n",
      "---\n",
      "\n",
      "**Key Concepts**\n",
      "\n",
      "### 1. Linked List\n",
      "You know what's cool about linked lists? They allow you to store data in a flexible way! Unlike arrays, where you need to define the size upfront, linked lists can grow and shrink as needed. Each node in a linked list contains data and a reference (or link) to the next node.\n",
      "\n",
      "### 2. Nodes\n",
      "Each node in your linked list will hold:\n",
      "- **Student Name**\n",
      "- **Roll Number**\n",
      "- **Phone Number**\n",
      "- **Semester**\n",
      "- **University Name**\n",
      "\n",
      "Think of a node as a little box that holds information about a student and points to the next box in line!\n",
      "\n",
      "---\n",
      "\n",
      "**Understanding the Details**\n",
      "\n",
      "### Q1: Implementing a Linked List\n",
      "To implement a linked list for students, you’ll need to create a `Node` class (or structure) that contains the student details and a pointer to the next node. Here’s a simple way to visualize it:\n",
      "\n",
      "```python\n",
      "class Node:\n",
      "    def __init__(self, name, roll_no, phone_no, semester, university):\n",
      "        self.name = name\n",
      "        self.roll_no = roll_no\n",
      "        self.phone_no = phone_no\n",
      "        self.semester = semester\n",
      "        self.university = university\n",
      "        self.next = None  # This will point to the next node\n",
      "```\n",
      "\n",
      "### Q2: Adding Students to the Linked List\n",
      "To add students, you’ll create a function that takes student details and adds a new node to the end of the list. Here’s a friendly way to think about it:\n",
      "\n",
      "```python\n",
      "def add_student(head, name, roll_no, phone_no, semester, university):\n",
      "    new_node = Node(name, roll_no, phone_no, semester, university)\n",
      "    if head is None:\n",
      "        return new_node  # If the list is empty, return the new node as the head\n",
      "    else:\n",
      "        current = head\n",
      "        while current.next:  # Traverse to the end of the list\n",
      "            current = current.next\n",
      "        current.next = new_node  # Link the new node\n",
      "    return head\n",
      "```\n",
      "\n",
      "### Q3: Displaying Student Details\n",
      "To display student details, you’ll create a function that goes through each node and prints the information. It’s like reading a book where each page is a student!\n",
      "\n",
      "```python\n",
      "def display_students(head):\n",
      "    current = head\n",
      "    while current:\n",
      "        print(f\"Name: {current.name}, Roll No: {current.roll_no}, Phone: {current.phone_no}, Semester: {current.semester}, University: {current.university}\")\n",
      "        current = current.next\n",
      "```\n",
      "\n",
      "### Q4: Copying Roll Numbers into an Array\n",
      "To copy all student roll numbers into an array, you’ll loop through the linked list and collect the roll numbers. It’s like gathering all your favorite stickers into a box!\n",
      "\n",
      "```python\n",
      "def copy_roll_numbers(head):\n",
      "    roll_numbers = []\n",
      "    current = head\n",
      "    while current:\n",
      "        roll_numbers.append(current.roll_no)  # Add roll number to the list\n",
      "        current = current.next\n",
      "    return roll_numbers\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "**Real-World Connection**\n",
      "\n",
      "You might think of linked lists as a train where each car (node) holds a passenger's information. Just like a train can add or remove cars easily, linked lists can grow or shrink without much hassle. This flexibility is super useful in many applications, like managing playlists, to-do lists, or even in databases!\n",
      "\n",
      "---\n",
      "\n",
      "I hope this breakdown helps you understand the concepts better! If you have any questions or need further clarification, feel free to ask. Keep up the great work!\n",
      "quick sort?\n",
      "**1. Simple Definition:**  \n",
      "Quick sort is an efficient sorting algorithm that uses a divide-and-conquer approach to sort elements in an array or list. It works by selecting a \"pivot\" element from the array and partitioning the other elements into two sub-arrays according to whether they are less than or greater than the pivot.\n",
      "\n",
      "**2. Basic Step-by-Step Explanation with Example:**  \n",
      "Let's say we have an array: [10, 7, 8, 9, 1, 5]. Here’s how quick sort works:\n",
      "\n",
      "- **Step 1: Choose a Pivot**  \n",
      "  Select a pivot element. For simplicity, let's choose the last element (5) as the pivot.\n",
      "\n",
      "- **Step 2: Partitioning**  \n",
      "  Rearrange the array so that elements less than the pivot come before it and elements greater than the pivot come after it. After partitioning around the pivot (5), the array might look like this: [1, 5, 8, 9, 10, 7]. The pivot (5) is now in its correct position.\n",
      "\n",
      "- **Step 3: Recursively Apply**  \n",
      "  Now, apply the same process recursively to the sub-arrays: [1] and [8, 9, 10, 7]. The sub-array [1] is already sorted. For [8, 9, 10, 7], choose a new pivot (7) and partition again, resulting in [7, 8, 9, 10].\n",
      "\n",
      "- **Final Sorted Array**  \n",
      "  Combining all the sorted parts, we get the final sorted array: [1, 5, 7, 8, 9, 10].\n",
      "\n",
      "**3. Time Complexity:**\n",
      "- **Best Case:** O(n log n) when the pivot divides the array into two equal halves.\n",
      "- **Average Case:** O(n log n) for random data.\n",
      "- **Worst Case:** O(n²) when the smallest or largest element is always chosen as the pivot (e.g., already sorted data).\n",
      "\n",
      "**4. Space Complexity:**  \n",
      "- O(log n) for the recursive stack space in the best and average cases, but O(n) in the worst case due to stack depth.\n",
      "\n",
      "**5. One Simple Real-World Application:**  \n",
      "Quick sort is widely used in applications where performance is critical, such as in database systems and large-scale data processing, due to its efficiency and speed.\n",
      "\n",
      "### Python Code for Quick Sort:\n",
      "Here’s a simple implementation of quick sort in Python:\n",
      "\n",
      "```python\n",
      "def quick_sort(arr):\n",
      "    if len(arr) <= 1:  # Base case: arrays with 0 or 1 element are already sorted\n",
      "        return arr\n",
      "    else:\n",
      "        pivot = arr[-1]  # Choose the last element as the pivot\n",
      "        less_than_pivot = [x for x in arr[:-1] if x <= pivot]  # Elements less than or equal to pivot\n",
      "        greater_than_pivot = [x for x in arr[:-1] if x > pivot]  # Elements greater than pivot\n",
      "        return quick_sort(less_than_pivot) + [pivot] + quick_sort(greater_than_pivot)  # Recursively sort and combine\n",
      "\n",
      "# Example usage\n",
      "if __name__ == \"__main__\":\n",
      "    arr = [10, 7, 8, 9, 1, 5]\n",
      "    sorted_arr = quick_sort(arr)\n",
      "    print(\"Sorted array:\", sorted_arr)\n",
      "```\n",
      "\n",
      "Feel free to run the code and test it with different input arrays! Quick sort is a powerful and efficient sorting algorithm that is widely used in practice.\n",
      "other sorting algorithms that are more efficient than this one\n",
      "While Quick Sort is a highly efficient sorting algorithm, there are other sorting algorithms that can be more efficient in specific scenarios or for certain types of data. Here are a few notable ones:\n",
      "\n",
      "### 1. Merge Sort\n",
      "- **Description**: Merge Sort is a divide-and-conquer algorithm that divides the array into halves, sorts each half, and then merges the sorted halves back together.\n",
      "- **Time Complexity**: O(n log n) in all cases (best, average, and worst).\n",
      "- **Space Complexity**: O(n) due to the temporary arrays used for merging.\n",
      "- **Advantages**: Stable sort (maintains the relative order of equal elements) and works well for large datasets and linked lists.\n",
      "\n",
      "### 2. Heap Sort\n",
      "- **Description**: Heap Sort uses a binary heap data structure to sort elements. It first builds a max heap from the input data, then repeatedly extracts the maximum element from the heap and rebuilds the heap.\n",
      "- **Time Complexity**: O(n log n) in all cases.\n",
      "- **Space Complexity**: O(1) since it sorts in place.\n",
      "- **Advantages**: Not recursive, and it has a good worst-case performance.\n",
      "\n",
      "### 3. Tim Sort\n",
      "- **Description**: Tim Sort is a hybrid sorting algorithm derived from Merge Sort and Insertion Sort. It is designed to perform well on many kinds of real-world data.\n",
      "- **Time Complexity**: O(n log n) in the worst case, but can be O(n) for nearly sorted data.\n",
      "- **Space Complexity**: O(n).\n",
      "- **Advantages**: It is the default sorting algorithm in Python's built-in `sort()` method and Java's `Arrays.sort()` for objects.\n",
      "\n",
      "### 4. Radix Sort\n",
      "- **Description**: Radix Sort is a non-comparative sorting algorithm that sorts numbers by processing individual digits. It works by distributing the numbers into buckets based on their digits and then collecting them back.\n",
      "- **Time Complexity**: O(nk), where n is the number of elements and k is the number of digits in the largest number.\n",
      "- **Space Complexity**: O(n + k).\n",
      "- **Advantages**: Efficient for sorting integers or strings and can outperform comparison-based algorithms for large datasets.\n",
      "\n",
      "### 5. Counting Sort\n",
      "- **Description**: Counting Sort is a non-comparative sorting algorithm that counts the occurrences of each unique element and uses this information to place elements in the correct position.\n",
      "- **Time Complexity**: O(n + k), where n is the number of elements and k is the range of the input.\n",
      "- **Space Complexity**: O(k).\n",
      "- **Advantages**: Very efficient for sorting integers within a known range and can be faster than comparison-based algorithms.\n",
      "\n",
      "### Summary\n",
      "While Quick Sort is efficient and widely used, the choice of sorting algorithm depends on the specific requirements of the problem, such as:\n",
      "- The size of the dataset.\n",
      "- The nature of the data (e.g., nearly sorted, small range of integers).\n",
      "- Memory constraints.\n",
      "\n",
      "In practice, algorithms like Merge Sort and Tim Sort are often preferred for their stability and consistent performance across various scenarios.\n",
      "oh thats cool\n",
      "I'm glad you think so! If you have any questions about data structures or algorithms, feel free to ask!\n",
      "tell me more about merge sort\n",
      "Merge Sort is a classic divide-and-conquer algorithm used for sorting an array or a list. Here’s a detailed overview:\n",
      "\n",
      "### Overview\n",
      "Merge Sort works by recursively dividing the array into two halves, sorting each half, and then merging the sorted halves back together. This process continues until the base case of the recursion is reached, which is when the array has one or zero elements (which are inherently sorted).\n",
      "\n",
      "### Steps of Merge Sort\n",
      "1. **Divide**: Split the unsorted list into two approximately equal halves.\n",
      "2. **Conquer**: Recursively sort both halves.\n",
      "3. **Combine**: Merge the two sorted halves to produce the sorted result.\n",
      "\n",
      "### Pseudocode\n",
      "Here’s a simple pseudocode representation of Merge Sort:\n",
      "\n",
      "```\n",
      "function mergeSort(array):\n",
      "    if length(array) <= 1:\n",
      "        return array\n",
      "    mid = length(array) / 2\n",
      "    left = mergeSort(array[0:mid])\n",
      "    right = mergeSort(array[mid:length(array)])\n",
      "    return merge(left, right)\n",
      "\n",
      "function merge(left, right):\n",
      "    result = []\n",
      "    while left and right are not empty:\n",
      "        if left[0] <= right[0]:\n",
      "            append left[0] to result\n",
      "            remove left[0] from left\n",
      "        else:\n",
      "            append right[0] to result\n",
      "            remove right[0] from right\n",
      "    append remaining elements of left and right to result\n",
      "    return result\n",
      "```\n",
      "\n",
      "### Time Complexity\n",
      "- **Best Case**: O(n log n)\n",
      "- **Average Case**: O(n log n)\n",
      "- **Worst Case**: O(n log n)\n",
      "\n",
      "### Space Complexity\n",
      "- O(n) due to the temporary arrays used for merging.\n",
      "\n",
      "### Characteristics\n",
      "- **Stable**: Merge Sort maintains the relative order of records with equal keys.\n",
      "- **Not In-Place**: It requires additional space proportional to the size of the input array.\n",
      "\n",
      "### Example\n",
      "Consider the array `[38, 27, 43, 3, 9, 82, 10]`.\n",
      "\n",
      "1. **Divide**: \n",
      "   - `[38, 27, 43]` and `[3, 9, 82, 10]`\n",
      "   - Further divide until single elements: `[38]`, `[27]`, `[43]`, `[3]`, `[9]`, `[82]`, `[10]`\n",
      "\n",
      "2. **Conquer**: \n",
      "   - Sort and merge: \n",
      "     - Merge `[38]` and `[27]` to get `[27, 38]`\n",
      "     - Merge `[27, 38]` and `[43]` to get `[27, 38, 43]`\n",
      "     - Merge `[3]`, `[9]`, `[82]`, and `[10]` similarly.\n",
      "\n",
      "3. **Combine**: \n",
      "   - Finally merge `[27, 38, 43]` and `[3, 9, 10, 82]` to get the sorted array `[3, 9, 10, 27, 38, 43, 82]`.\n",
      "\n",
      "### Use Cases\n",
      "Merge Sort is particularly useful for:\n",
      "- Sorting linked lists (as it doesn't require random access).\n",
      "- Large datasets that do not fit into memory (external sorting).\n",
      "\n",
      "If you need more specific details or examples, let me know!\n",
      "thanks\n",
      "You're welcome! If you have any more questions about Merge Sort or anything else in data structures and algorithms, just let me know!\n",
      "what other algorithms do you recommend\n",
      "There are several sorting algorithms, each with its own strengths and weaknesses. Here are some commonly recommended sorting algorithms besides Merge Sort:\n",
      "\n",
      "### 1. Quick Sort\n",
      "- **Description**: A divide-and-conquer algorithm that selects a \"pivot\" element and partitions the array into elements less than and greater than the pivot.\n",
      "- **Time Complexity**: O(n log n) on average; O(n²) in the worst case (when the pivot is the smallest or largest element).\n",
      "- **Space Complexity**: O(log n) for the recursive stack space.\n",
      "- **Advantages**: Generally faster in practice than other O(n log n) algorithms due to better cache performance.\n",
      "\n",
      "### 2. Heap Sort\n",
      "- **Description**: A comparison-based sorting algorithm that uses a binary heap data structure. It builds a max heap and repeatedly extracts the maximum element.\n",
      "- **Time Complexity**: O(n log n) in all cases.\n",
      "- **Space Complexity**: O(1) since it sorts in place.\n",
      "- **Advantages**: Good worst-case performance and does not require additional memory for sorting.\n",
      "\n",
      "### 3. Tim Sort\n",
      "- **Description**: A hybrid sorting algorithm derived from Merge Sort and Insertion Sort. It is designed to perform well on many kinds of real-world data.\n",
      "- **Time Complexity**: O(n log n) in the worst case; O(n) for nearly sorted data.\n",
      "- **Space Complexity**: O(n).\n",
      "- **Advantages**: Stable sort and is the default sorting algorithm in Python's built-in `sort()` method and Java's `Arrays.sort()` for objects.\n",
      "\n",
      "### 4. Radix Sort\n",
      "- **Description**: A non-comparative sorting algorithm that sorts numbers by processing individual digits. It distributes numbers into buckets based on their digits.\n",
      "- **Time Complexity**: O(nk), where n is the number of elements and k is the number of digits in the largest number.\n",
      "- **Space Complexity**: O(n + k).\n",
      "- **Advantages**: Efficient for sorting integers or strings and can outperform comparison-based algorithms for large datasets.\n",
      "\n",
      "### 5. Counting Sort\n",
      "- **Description**: A non-comparative sorting algorithm that counts the occurrences of each unique element and uses this information to place elements in the correct position.\n",
      "- **Time Complexity**: O(n + k), where n is the number of elements and k is the range of the input.\n",
      "- **Space Complexity**: O(k).\n",
      "- **Advantages**: Very efficient for sorting integers within a known range and can be faster than comparison-based algorithms.\n",
      "\n",
      "### 6. Insertion Sort\n",
      "- **Description**: A simple sorting algorithm that builds the final sorted array one item at a time. It is much less efficient on large lists than more advanced algorithms.\n",
      "- **Time Complexity**: O(n) in the best case (when the array is already sorted); O(n²) in the average and worst cases.\n",
      "- **Space Complexity**: O(1) since it sorts in place.\n",
      "- **Advantages**: Efficient for small datasets and for nearly sorted data.\n",
      "\n",
      "### 7. Bubble Sort\n",
      "- **Description**: A simple comparison-based algorithm that repeatedly steps through the list, compares adjacent elements, and swaps them if they are in the wrong order.\n",
      "- **Time Complexity**: O(n) in the best case (when the array is already sorted); O(n²) in the average and worst cases.\n",
      "- **Space Complexity**: O(1) since it sorts in place.\n",
      "- **Advantages**: Simple to understand and implement, but not efficient for large datasets.\n",
      "\n",
      "### Summary\n",
      "The choice of sorting algorithm depends on various factors, including:\n",
      "- The size of the dataset.\n",
      "- The nature of the data (e.g., nearly sorted, small range of integers).\n",
      "- Memory constraints.\n",
      "- Whether stability (maintaining the relative order of equal elements) is required.\n",
      "\n",
      "In practice, algorithms like Quick Sort, Merge Sort, and Tim Sort are often preferred for their efficiency and performance across various scenarios.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from utils.db_connection import ChatDatabase\n",
    "\n",
    "db = ChatDatabase('chat.db')\n",
    "\n",
    "chat_history = db.load_chat_history(\"638c132f-ecdb-4357-9b8c-3dff0c396cb1\", \"638c132f-ecdb-4357-9b8c-3dff0c396cb1_1\")\n",
    "messages = []\n",
    "for message in chat_history:\n",
    "    if message[\"role\"] == \"user\":\n",
    "        messages.append(HumanMessage(content=message[\"content\"]))\n",
    "        print(message[\"content\"])\n",
    "    else:\n",
    "        messages.append(AIMessage(content=message[\"content\"]))\n",
    "        print(message[\"content\"])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit User Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.save_user_data(\"6fcf537a-8e1e-496b-be68-84841722fa57\",\"\",\"elroy7602@gmail.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "users = db.get_all_users()\n",
    "\n",
    "for user in users:\n",
    "    print(user['user_id'],\" \",db.get_user_level(user['user_id']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Specific User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.delete_user(\"5b2429f2-7dde-4469-8b88-75910f2e5a5b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_level = \"intermediate\"\n",
    "levels = (\"Beginner\", \"Intermediate\", \"Advanced\")\n",
    "print(levels.index(user_level.capitalize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_level_tool(user_id: str) -> str:\n",
    "    \"\"\"Get user level for given user_id\"\"\"\n",
    "    try:\n",
    "        user_level = db.get_user_level(user_id)\n",
    "        return f\"Current user level is {user_level}.\" if user_level else \"User not found.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving user level: {str(e)}\"\n",
    "    \n",
    "\n",
    "hello = get_user_level_tool(\"6fcf537a-8e1e-496b-be68-84841722fa57\")\n",
    "\n",
    "print(hello)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset Analysis Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.reset_analysis_timestamp(\"638c132f-ecdb-4357-9b8c-3dff0c396cb1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get User Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sorting Algorithms': ['Insertion Sort', 'Bubble Sort', 'Quick Sort', 'Merge Sort'], 'Algorithm Performance': [], 'Recursion': []}\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "result = db.get_user_topics(user_id=\"638c132f-ecdb-4357-9b8c-3dff0c396cb1\")\n",
    "print(json.loads(result))\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update User Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.update_user_topics(user_id=\"0122656d-8999-4ae9-89d2-5f4d6c2ebd02\",topics=\"{}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tools with Langchain LCEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_StJMon95i5N4wk1gyNP4oyOr', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': 'call_l9XGcLbfxcdPv4w09zg1hzNR', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_chroma import Chroma\n",
    "from utils.custom_embeddings import MyEmbeddings\n",
    "import streamlit as st\n",
    "from langchain_openai import ChatOpenAI\n",
    "from utils.chunk_doc import get_retriever, get_vector_store\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "        model_name=\"gpt-4o-mini\", \n",
    "        temperature=0, \n",
    "        streaming=True, \n",
    "        api_key=st.secrets[\"OpenAI_key\"]\n",
    "    )\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "tools = [add, multiply]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "\n",
    "print(ai_msg.tool_calls)\n",
    "\n",
    "messages.append(ai_msg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 3 * 12? Also, what is 11 + 49?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_StJMon95i5N4wk1gyNP4oyOr', 'function': {'arguments': '{\"a\": 3, \"b\": 12}', 'name': 'multiply'}, 'type': 'function'}, {'index': 1, 'id': 'call_l9XGcLbfxcdPv4w09zg1hzNR', 'function': {'arguments': '{\"a\": 11, \"b\": 49}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c'}, id='run-6f538260-5986-4429-af39-b01af767677a-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_StJMon95i5N4wk1gyNP4oyOr', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': 'call_l9XGcLbfxcdPv4w09zg1hzNR', 'type': 'tool_call'}]),\n",
       " ToolMessage(content='36', name='multiply', tool_call_id='call_StJMon95i5N4wk1gyNP4oyOr'),\n",
       " ToolMessage(content='60', name='add', tool_call_id='call_l9XGcLbfxcdPv4w09zg1hzNR')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The result of \\\\(3 \\\\times 12\\\\) is 36, and the result of \\\\(11 + 49\\\\) is 60.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63'}, id='run-9c6964b2-9be9-4755-bc21-d71b95e0d175-0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current Retrieval Tool for Langgraph [Important]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing retriever...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from utils.chunk_doc import get_retriever\n",
    "import os\n",
    "import streamlit as st\n",
    "from langchain import hub\n",
    "from typing import Annotated, Literal, Sequence, Any, Dict\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate, ChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from model import llm_selected\n",
    "\n",
    "# TODO\n",
    "# LLM still unsure how to respond to Thank you, Goodbye, etc. Hi, still okay i guess\n",
    "# Keep testing!\n",
    "# Change clarification method\n",
    "\n",
    "# Initialize the retriever\n",
    "print(\"Initializing retriever...\")\n",
    "retriever = get_retriever()\n",
    "\n",
    "# Create the retriever tool\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retrieve_documents\",\n",
    "    \"\"\"Search and return relevant documents based on user's query.\"\"\"\n",
    ")\n",
    "\n",
    "# Add the retriever tool to the list of tools\n",
    "tools = [retriever_tool]\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    user_level: str\n",
    "\n",
    "def validate_dsa_question(state) -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Validates input to either handle DSA questions or engage in friendly conversation,\n",
    "    while redirecting other technical questions.\n",
    "    \n",
    "    Args:\n",
    "        state: Current state containing messages and user_level\n",
    "        \n",
    "    Returns:\n",
    "        dict[str, Any]: Dictionary containing:\n",
    "            - messages: List of conversation messages\n",
    "            - user_level: User's current level\n",
    "            - next: Literal[\"proceed\", \"redirect\"] indicating next action\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[-1].content\n",
    "    user_level = state[\"user_level\"]\n",
    "    \n",
    "    class ValidationResult(BaseModel):\n",
    "        message_type: str = Field(\n",
    "            description=\"Type of message: 'dsa', 'pleasantry', or 'other'\",\n",
    "        )\n",
    "        response: str = Field(\n",
    "        description=\"Customized response for pleasantries or redirects\",\n",
    "        default=\"\"  # Provide dynamic responses instead of a static default\n",
    "        )\n",
    "\n",
    "    # Get context from previous messages if they exist\n",
    "    context_messages = messages[-6:-1] if len(messages) > 6 else messages[:-1]\n",
    "    conversation_context = \"\\n\".join([\n",
    "        f\"{'User: ' if isinstance(m, HumanMessage) else 'Assistant: '}{m.content}\"\n",
    "        for m in context_messages\n",
    "    ])\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"Analyze the input as a friendly DSA tutor:\n",
    "\n",
    "Previous conversation:\n",
    "{context}\n",
    "\n",
    "Current input: {question}\n",
    "\n",
    "Classify the input into one of three categories:\n",
    "\n",
    "1. 'dsa' - Questions directly about:\n",
    "   - Data Structures (arrays, linked lists, trees, graphs, etc.)\n",
    "   - Algorithms (sorting, searching, traversal, etc.)\n",
    "   - Algorithm analysis (complexity, Big O notation)\n",
    "   - DSA implementation\n",
    "   - DSA problem-solving\n",
    "\n",
    "2. 'pleasantry' - Friendly conversation:\n",
    "   - Greetings (hi, hello, hey)\n",
    "   - Thanks/gratitude\n",
    "   - Goodbyes\n",
    "   - Emotional responses (\"that makes sense\", \"I'm confused\")\n",
    "   - Small encouragements (\"got it\", \"okay I understand\")\n",
    "   \n",
    "3. 'other' - Non-DSA technical content:\n",
    "   - General programming\n",
    "   - Math questions\n",
    "   - Other CS topics\n",
    "   - Non-technical questions\n",
    "\n",
    "For pleasantries: Respond naturally like a friendly tutor\n",
    "For other: Redirect to DSA while being encouraging\n",
    "\n",
    "Return:\n",
    "1. message_type: 'dsa', 'pleasantry', or 'other'\n",
    "2. response: Natural response for pleasantries or friendly redirect for other\"\"\",\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        model = ChatOpenAI(\n",
    "            model_name=\"gpt-4o-mini\", \n",
    "            temperature=0.4,  # Slightly higher temperature for more natural responses\n",
    "            streaming=True, \n",
    "            api_key=st.secrets[\"OpenAI_key\"]\n",
    "        )\n",
    "        chain = prompt | model.with_structured_output(ValidationResult)\n",
    "        result = chain.invoke({\n",
    "            \"context\": conversation_context,\n",
    "            \"question\": question\n",
    "        })\n",
    "        \n",
    "        # Add refined responses for pleasantries or \"other\"\n",
    "        if result.message_type == \"pleasantry\":\n",
    "            if \"thanks\" in question.lower():\n",
    "                result.response = \"You're very welcome! Let me know if there's anything else you'd like to explore about DSA.\"\n",
    "            elif any(greet in question.lower() for greet in [\"hi\", \"hello\", \"hey\"]):\n",
    "                result.response = \"Hi there! I'm here to help with any questions about data structures and algorithms. What would you like to learn about today?\"\n",
    "            elif any(farewell in question.lower() for farewell in [\"bye\", \"goodbye\"]):\n",
    "                result.response = \"Take care! Feel free to reach out whenever you're ready to dive into DSA again!\"\n",
    "\n",
    "        elif result.message_type == \"other\":\n",
    "            result.response = (\"That's an interesting topic, but my expertise is in data structures and algorithms. \"\n",
    "                               \"I'd be happy to help you explore concepts like trees, graphs, or sorting algorithms. \"\n",
    "                               \"Let me know what you'd like to dive into!\")\n",
    "        \n",
    "        # Determine the next step\n",
    "        if result.message_type == \"dsa\":\n",
    "            return {\n",
    "                \"messages\": messages,\n",
    "                \"user_level\": user_level,\n",
    "                \"next\": \"proceed\"\n",
    "            }\n",
    "        else:  # pleasantry or other\n",
    "            return {\n",
    "                \"messages\": [*messages, AIMessage(content=result.response)],\n",
    "                \"user_level\": user_level,\n",
    "                \"next\": \"redirect\"\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Validation error: {str(e)}\")\n",
    "        # On error, proceed with original message\n",
    "        return {\n",
    "            \"messages\": messages,\n",
    "            \"user_level\": user_level,\n",
    "            \"next\": \"proceed\"\n",
    "        }\n",
    "\n",
    "def clarify_question(state):\n",
    "    \"\"\"\n",
    "    Clarifies ambiguous questions by maintaining conversation context,\n",
    "    with improved handling of pronoun references to DSA concepts.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== DEBUG: CLARIFY NODE ===\")\n",
    "    messages = state[\"messages\"]\n",
    "    current_question = messages[-1].content\n",
    "    print(f\"Original question: {current_question}\")\n",
    "    \n",
    "    # Get the last 3 exchanges (up to 6 messages) for relevant context\n",
    "    context_messages = messages[-6:-1] if len(messages) > 6 else messages[:-1]\n",
    "    conversation_context = \"\\n\".join([\n",
    "        f\"{'User: ' if isinstance(m, HumanMessage) else 'Assistant: '}{m.content}\"\n",
    "        for m in context_messages\n",
    "    ])\n",
    "    \n",
    "    class ClarificationResult(BaseModel):\n",
    "        clarified_question: str = Field(\n",
    "            description=\"The clarified version of the question with pronouns replaced by their referents\",\n",
    "            default=\"\"  # Provide empty string as default\n",
    "        )\n",
    "        referenced_concept: str = Field(\n",
    "            description=\"The main DSA concept being referenced from previous context\",\n",
    "            default=\"\"  # Provide empty string as default\n",
    "        )\n",
    "    \n",
    "    model = ChatOpenAI(\n",
    "        model_name=\"gpt-4o-mini\", \n",
    "        temperature=0, \n",
    "        streaming=True, \n",
    "        api_key=st.secrets[\"OpenAI_key\"]\n",
    "    )\n",
    "    llm_with_clarification = model.with_structured_output(ClarificationResult)\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "You are a DSA question processor. Transform user's prompt into clear, context-aware queries.\n",
    "\n",
    "OBJECTIVE: Rewrite user's prompt to include relevant context from chat history while maintaining original intent.\n",
    "\n",
    "Previous conversation:\n",
    "{context}\n",
    "\n",
    "Current question: {question}\n",
    "\n",
    "TRANSFORMATION RULES:\n",
    "1. Replace pronouns with specific references\n",
    "   Before: \"How do I implement it?\"\n",
    "   After: \"How do I implement a binary search tree?\"\n",
    "\n",
    "2. Include relevant context\n",
    "   Before: \"What about the time complexity?\"\n",
    "   After: \"What is the time complexity of quicksort's partitioning step?\"\n",
    "\n",
    "3. Maintain technical precision\n",
    "   Before: \"How does the fast one work?\"\n",
    "   After: \"How does the O(n log n) merge sort algorithm work?\"\n",
    "\n",
    "4. Keep original meaning\n",
    "   Do NOT add assumptions or change the question's scope\n",
    "\n",
    "Return ONLY the reformulated question without explanation.\n",
    "\n",
    "\"\"\",\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm_with_clarification\n",
    "    \n",
    "    try:\n",
    "        result = chain.invoke({\n",
    "            \"context\": conversation_context,\n",
    "            \"question\": current_question\n",
    "        })\n",
    "        \n",
    "        # For non-DSA questions or greetings, use original question\n",
    "        if not result.needs_clarification:\n",
    "            print(\"No clarification needed - using original question\")\n",
    "            return {\"messages\": messages, \"user_level\": state[\"user_level\"]}\n",
    "            \n",
    "        # For questions needing clarification, verify we have the clarified version\n",
    "        if result.needs_clarification and result.clarified_question:\n",
    "            print(f\"Referenced concept: {result.referenced_concept}\")\n",
    "            print(f\"Clarified to: {result.clarified_question}\")\n",
    "            return {\"messages\": [HumanMessage(content=result.clarified_question)], \"user_level\": state[\"user_level\"]}\n",
    "        else:\n",
    "            print(\"No clarification needed\")\n",
    "            return {\"messages\": messages, \"user_level\": state[\"user_level\"]}\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in clarification: {str(e)}\")\n",
    "        # On error, proceed with original question\n",
    "        return {\"messages\": messages, \"user_level\": state[\"user_level\"]}\n",
    "\n",
    "def agent(state):\n",
    "    \"\"\"\n",
    "    Invokes the agent model to generate a response based on confidence level.\n",
    "    \n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with the agent response appended to messages\n",
    "    \"\"\"\n",
    "    print(\"---CALL AGENT---\")\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # System message that enforces confidence-based retrieval\n",
    "    system_message = \"\"\"You are a DSA expert assistant. For every question:\n",
    "\n",
    "1. First, assess your confidence in providing a complete, accurate answer:\n",
    "   - Consider if you need specific implementation details\n",
    "   - Consider if you need exact complexity analysis\n",
    "   - Consider if you need specific examples or edge cases\n",
    "\n",
    "2. If your confidence is less than 90%%:\n",
    "   - ALWAYS use the retrieve_documents tool\n",
    "   - Base your answer on the retrieved information\n",
    "   - Acknowledge when using retrieved information\n",
    "\n",
    "3. If your confidence is 90%% or higher:\n",
    "   - You may answer directly from your knowledge\n",
    "   - Still use the tool if additional detail would be helpful\n",
    "   - Mention that you're confident in your direct answer\n",
    "\n",
    "4. Always be explicit about tool usage:\n",
    "   - \"Let me check our reference materials for specific details...\"\n",
    "   - \"I'm very confident about this, but let me verify some details...\"\n",
    "   - \"This requires checking our documentation for precise information...\"\n",
    "\n",
    "Remember: It's better to verify with the tool than risk providing incomplete or inaccurate information.\"\"\"\n",
    "\n",
    "    # Prepare messages with system instruction\n",
    "    full_messages = [\n",
    "        HumanMessage(content=system_message),\n",
    "        *messages\n",
    "    ]\n",
    "    \n",
    "    # Initialize model with tools\n",
    "    model = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", streaming=True, api_key=st.secrets[\"OpenAI_key\"])\n",
    "    model = model.bind_tools(tools)\n",
    "    \n",
    "    # Get response\n",
    "    response = model.invoke(full_messages)\n",
    "    \n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def grade_documents(state) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    \"\"\"\n",
    "    Enhanced grading system for retrieved DSA documents.\n",
    "    \n",
    "    Evaluates:\n",
    "    1. Relevance to the question\n",
    "    2. Completeness of the answer\n",
    "    3. Technical accuracy\n",
    "    4. Need for clarification\n",
    "    \n",
    "    Returns:\n",
    "    - \"generate\": When documents are good enough to generate response\n",
    "    - \"rewrite\": When documents aren't relevant enough\n",
    "    - \"clarify\": When question needs clarification\n",
    "    \"\"\"\n",
    "    print(\"---ENHANCED GRADING SYSTEM---\")\n",
    "    \n",
    "    class GradeResult(BaseModel):\n",
    "        relevance_score: float = Field(description=\"0-1 score for topic relevance\")\n",
    "        completeness_score: float = Field(description=\"0-1 score for answer completeness\")\n",
    "        technical_accuracy: float = Field(description=\"0-1 score for technical accuracy\")\n",
    "        reasoning: str = Field(description=\"Explanation for the grading decision\")\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    retrieved_docs = messages[-1].content\n",
    "\n",
    "    # Define the grading prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a DSA expert grading retrieved content.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Retrieved Content:\n",
    "{content}\n",
    "\n",
    "Grade this content on:\n",
    "1. Relevance: Does it directly address the DSA concepts in the question?\n",
    "2. Completeness: Does it cover all aspects needed for a good answer?\n",
    "3. Technical Accuracy: Is the DSA information correct and precise?\n",
    "4. Clarity: Is the question clear or needs clarification?\n",
    "\n",
    "Example DSA concepts to check for:\n",
    "- Data structure definitions and properties\n",
    "- Algorithm steps and processes\n",
    "- Time/space complexity mentions\n",
    "- Implementation details\n",
    "- Common use cases and examples\n",
    "\n",
    "Return scores as decimals between 0 and 1, where:\n",
    "- 0.0-0.3: Poor\n",
    "- 0.4-0.6: Moderate\n",
    "- 0.7-1.0: Good\n",
    "\n",
    "Also explain your reasoning.\"\"\",\n",
    "        input_variables=[\"question\", \"content\"]\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Initialize model with lower temperature for consistent grading\n",
    "        model = ChatOpenAI(\n",
    "            model_name=\"gpt-4o-mini\",\n",
    "            temperature=0,\n",
    "            streaming=True,\n",
    "            api_key=st.secrets[\"OpenAI_key\"]\n",
    "        )\n",
    "        \n",
    "        # Grade with structured output\n",
    "        chain = prompt | model.with_structured_output(GradeResult)\n",
    "        result = chain.invoke({\n",
    "            \"question\": question,\n",
    "            \"content\": retrieved_docs\n",
    "        })\n",
    "        \n",
    "        print(f\"Grading Results:\\n\"\n",
    "              f\"Relevance: {result.relevance_score:.2f}\\n\"\n",
    "              f\"Completeness: {result.completeness_score:.2f}\\n\"\n",
    "              f\"Technical Accuracy: {result.technical_accuracy:.2f}\\n\")\n",
    "            \n",
    "        # Calculate weighted average score\n",
    "        weighted_score = (\n",
    "            result.relevance_score * 0.4 +      # Relevance is most important\n",
    "            result.completeness_score * 0.3 +    # Completeness next\n",
    "            result.technical_accuracy * 0.3      # Technical accuracy equally important\n",
    "        )\n",
    "        \n",
    "        # Decision thresholds\n",
    "        GOOD_THRESHOLD = 0.65\n",
    "        \n",
    "        if weighted_score >= GOOD_THRESHOLD:\n",
    "            print(\"---DECISION: CONTENT GOOD ENOUGH TO GENERATE---\")\n",
    "            return \"generate\"\n",
    "        else:\n",
    "            print(\"---DECISION: NEED TO REWRITE QUERY---\")\n",
    "            return \"rewrite\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Grading error: {str(e)}\")\n",
    "        # On error, default to rewrite for safety\n",
    "        return \"rewrite\"\n",
    "    \n",
    "def rewrite(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "\n",
    "    msg = [\n",
    "        HumanMessage(\n",
    "            content=f\"\"\" \\n \n",
    "    Look at the input and try to reason about the underlying semantic intent / meaning. \\n \n",
    "    Here is the initial question:\n",
    "    \\n ------- \\n\n",
    "    {question} \n",
    "    \\n ------- \\n\n",
    "    Formulate an improved question: \"\"\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Grader\n",
    "    model = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", streaming=True,api_key=st.secrets[\"OpenAI_key\"])\n",
    "    response = model.invoke(msg)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"Generate response based on retrieved content and question\"\"\"\n",
    "    print(\"\\n=== DEBUG: GENERATE NODE ===\")\n",
    "    messages = state[\"messages\"]\n",
    "    print(\"Messages: \", state[\"messages\"])\n",
    "    \n",
    "    # Find the last actual question by looking for the last HumanMessage\n",
    "    # that triggered the retrieval flow\n",
    "    question = None\n",
    "    \n",
    "    for msg in messages:\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            question = msg.content\n",
    "            \n",
    "    if not question:\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=\"I couldn't properly process your question. Could you please rephrase it?\")],\n",
    "            \"user_level\": state[\"user_level\"]\n",
    "        }\n",
    "        \n",
    "    user_level = state[\"user_level\"]\n",
    "    docs = messages[-1].content  # Retrieved content is always last\n",
    "    \n",
    "    print(f\"Generate received question: {question}\")\n",
    "    print(f\"User level: {user_level}\")\n",
    "    # print(f\"Docs length: {len(docs) if docs else 'None'}\")\n",
    "    \n",
    "    if not docs or len(docs.strip()) < 10:\n",
    "        print(\"---NO CONTENT TO GENERATE FROM---\")\n",
    "        return {\"messages\": [AIMessage(content=\"I apologize, but I couldn't find relevant information to answer your question. Please try rephrasing it.\")], \"user_level\": state[\"user_level\"]}\n",
    "        \n",
    "    try:\n",
    "        llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0, streaming=True, api_key=st.secrets[\"OpenAI_key\"])\n",
    "        \n",
    "        # prompt = PromptTemplate(\n",
    "        #     template=\"\"\"Answer based on the following context. If context is insufficient, say so clearly.\n",
    "        #     Question: {question}\n",
    "        #     User Level: {user_level}\n",
    "        #     Context: {context}\n",
    "            \n",
    "        #     If you don't find specific information about the topic, you can provide a general explanation based on your knowledge, but clearly state that you're doing so.\"\"\",\n",
    "        #     input_variables=[\"context\", \"question\", \"user_level\"],\n",
    "        # )\n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=['context', 'question','user_level'], \n",
    "            input_types={}, \n",
    "            partial_variables={}, \n",
    "            template=\"\"\"You are a DSA expert tutor. Adapt your teaching style to the user's level while maintaining technical accuracy.\n",
    "\n",
    "Current User Level: {user_level}\n",
    "\n",
    "• BEGINNER LEVEL APPROACH:\n",
    "  • Use simple analogies and metaphors\n",
    "    • Compare arrays to parking lots\n",
    "    • Explain stacks like plates in a cafeteria\n",
    "    • Describe trees as family trees\n",
    "  • Focus on basic understanding\n",
    "    • Avoid complexity discussions\n",
    "    • Use step-by-step explanations\n",
    "    • Provide visual examples when possible\n",
    "  • Keep language simple\n",
    "    • Minimize technical jargon\n",
    "    • Use everyday examples\n",
    "    • Explain concepts interactively\n",
    "\n",
    "• INTERMEDIATE LEVEL APPROACH:\n",
    "  • Technical content focus\n",
    "    • Include basic time/space complexity\n",
    "    • Show implementation details\n",
    "    • Provide code examples\n",
    "  • Teaching methods\n",
    "    • Compare different approaches\n",
    "    • Explain basic trade-offs\n",
    "    • Connect related concepts\n",
    "  • Code implementation\n",
    "    • Show practical examples\n",
    "    • Discuss common patterns\n",
    "    • Address basic optimizations\n",
    "\n",
    "• ADVANCED LEVEL APPROACH:\n",
    "  • Technical depth\n",
    "    • Deep optimization discussions\n",
    "    • Thorough edge case analysis\n",
    "    • Performance considerations\n",
    "  • System considerations\n",
    "    • Memory/cache implications\n",
    "    • Concurrency aspects\n",
    "    • Scalability factors\n",
    "  • Implementation focus\n",
    "    • Advanced optimization techniques\n",
    "    • System design impacts\n",
    "    • Complex trade-offs\n",
    "\n",
    "• UNIVERSAL RULES:\n",
    "  • Stay within DSA scope\n",
    "    • Redirect non-DSA questions politely\n",
    "    • Focus on one concept at a time\n",
    "    • Offer to explore related topics after\n",
    "  • Use context appropriately\n",
    "    • Start with provided context: \"{context}\"\n",
    "    • Clearly indicate when using general knowledge\n",
    "    • Stay within user's competency level\n",
    "  • Maintain level-appropriate depth\n",
    "    • Match technical depth to user level\n",
    "    • Scale example complexity appropriately\n",
    "    • Use suitable terminology\n",
    "\n",
    "Question: {question}\"\"\")\n",
    "        # prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "        \n",
    "        chain = prompt | llm | StrOutputParser()\n",
    "        response = chain.invoke({\n",
    "            \"context\": docs,\n",
    "            \"question\": question,\n",
    "            \"user_level\": user_level\n",
    "        })\n",
    "        \n",
    "        print(f\"Generated response length: {len(response)}\")\n",
    "        return {\"messages\": [AIMessage(content=response)], \"user_level\": state[\"user_level\"]}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in generate: {str(e)}\")\n",
    "        return {\"messages\": [AIMessage(content=\"I encountered an error generating a response. Please try asking your question again.\")], \"user_level\": state[\"user_level\"]}\n",
    "\n",
    "################################################################################################################\n",
    "# Graph setup\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"validate_topic\", validate_dsa_question)\n",
    "workflow.add_node(\"clarify\", clarify_question)\n",
    "workflow.add_node(\"agent\", agent)\n",
    "retrieve = ToolNode([retriever_tool])\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "workflow.add_node(\"rewrite\", rewrite)\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(START, \"validate_topic\")\n",
    "\n",
    "# Modify validation to return three possible outcomes\n",
    "workflow.add_conditional_edges(\n",
    "    \"validate_topic\",\n",
    "    lambda x: x[\"next\"],\n",
    "    {\n",
    "        \"proceed\": \"agent\",\n",
    "        \"clarify\": \"clarify\",\n",
    "        \"redirect\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# After clarification, go to agent\n",
    "workflow.add_edge(\"clarify\", \"agent\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    tools_condition,\n",
    "    {\n",
    "        \"tools\": \"retrieve\",\n",
    "        END: END,\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    grade_documents,\n",
    "    {\n",
    "        \"generate\": \"generate\",\n",
    "        \"rewrite\": \"rewrite\",\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"generate\", END)\n",
    "workflow.add_edge(\"rewrite\", \"agent\")\n",
    "\n",
    "# Compile graph\n",
    "from test_templates.memory import memory\n",
    "graph = workflow.compile()\n",
    "\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elroy\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\nltk\\metrics\\association.py:26: UserWarning: A NumPy version >=1.23.5 and <2.3.0 is required for this version of SciPy (detected version 1.23.2)\n",
      "  from scipy.stats import fisher_exact\n",
      "c:\\Users\\elroy\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing retriever...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from utils.chunk_doc import get_retriever\n",
    "import os\n",
    "import streamlit as st\n",
    "from langchain import hub\n",
    "from typing import Annotated, Literal, Sequence, Any, Dict\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate, ChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# TODO\n",
    "# Keep testing!\n",
    "# Change clarification method\n",
    "\n",
    "# Initialize the retriever\n",
    "print(\"Initializing retriever...\")\n",
    "retriever = get_retriever()\n",
    "\n",
    "# Create the retriever tool\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retrieve_documents\",\n",
    "    \"\"\"Search and return relevant documents based on user's query.\"\"\"\n",
    ")\n",
    "\n",
    "# Add the retriever tool to the list of tools\n",
    "tools = [retriever_tool]\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    user_level: str\n",
    "\n",
    "def classify_user_input(state) -> dict[str, Any]:\n",
    "    \"\"\"Validates input to handle DSA questions, ensuring English-only interaction.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[-1].content\n",
    "    user_level = state[\"user_level\"]\n",
    "    \n",
    "    \n",
    "    class ValidationResult(BaseModel):\n",
    "        message_type: str = Field(description=\"Type of message: 'dsa', 'pleasantry', 'non_english', or 'other'\")\n",
    "        response: str = Field(description=\"Response for non-DSA inputs\")\n",
    "\n",
    "    # First, check if current message is non-English\n",
    "    language_prompt = PromptTemplate(\n",
    "        template=\"\"\"Analyze ONLY the current input for language:\n",
    "\n",
    "Current input: {question}\n",
    "\n",
    "Determine if this input contains ANY non-English text or characters.\n",
    "Return:\n",
    "1. message_type: 'non_english' if ANY non-English content is present, 'english' if input is entirely in English\n",
    "2. response: \"I can only communicate in English. Please rephrase your question in English.\" for non-English content\"\"\",\n",
    "        input_variables=[\"question\"]\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.5, streaming=True, api_key=st.secrets[\"OpenAI_key\"])\n",
    "        language_chain = language_prompt | model.with_structured_output(ValidationResult)\n",
    "        language_result = language_chain.invoke({\"question\": question})\n",
    "        \n",
    "        # If non-English is detected, return immediately\n",
    "        if language_result.message_type == \"non_english\":\n",
    "            return {\n",
    "                \"messages\": [*messages, AIMessage(content=\"I can only communicate in English. Please rephrase your question in English.\")],\n",
    "                \"user_level\": user_level,\n",
    "                \"next\": \"redirect\"\n",
    "            }\n",
    "            \n",
    "        # If message is in English, proceed with full classification\n",
    "        context_messages = messages[-6:-1] if len(messages) > 6 else messages[:-1]\n",
    "        conversation_context = \"\\n\".join([f\"{'User: ' if isinstance(m, HumanMessage) else 'Assistant: '}{m.content}\" \n",
    "                                        for m in context_messages])\n",
    "        \n",
    "        classification_prompt = PromptTemplate(\n",
    "            template=\"\"\"Analyze the English input as a friendly DSA tutor:\n",
    "\n",
    "Previous conversation:\n",
    "{context}\n",
    "\n",
    "Current input: {question}\n",
    "\n",
    "Classify the input into:\n",
    "\n",
    "1. 'dsa' - Questions directly about:\n",
    "- Data Structures (arrays, linked lists, trees, graphs, etc.)\n",
    "- Algorithms (sorting, searching, traversal, etc.)\n",
    "- Algorithm analysis (complexity, Big O notation)\n",
    "- DSA implementation\n",
    "- DSA problem-solving\n",
    "\n",
    "2. 'pleasantry' - Friendly conversation:\n",
    "- Greetings (hi, hello, hey)\n",
    "- Thanks/gratitude\n",
    "- Goodbyes\n",
    "- Emotional responses (\"that makes sense\", \"I'm confused\")\n",
    "- Small encouragements (\"got it\", \"okay I understand\")\n",
    "\n",
    "3. 'other' - Non-DSA technical content:\n",
    "- General programming\n",
    "- Math questions\n",
    "- Other CS topics\n",
    "- Non-technical questions\n",
    "\n",
    "For pleasantries: Respond naturally like a friendly tutor\n",
    "For other: Redirect to DSA while being encouraging\n",
    "\n",
    "Return:\n",
    "1. message_type: 'dsa', 'pleasantry', or 'other'\n",
    "2. response: Appropriate response for non-DSA inputs\"\"\",\n",
    "            input_variables=[\"context\", \"question\"]\n",
    "        )\n",
    "        \n",
    "        chain = classification_prompt | model.with_structured_output(ValidationResult)\n",
    "        result = chain.invoke({\"context\": conversation_context, \"question\": question})\n",
    "        \n",
    "        if result.message_type == \"dsa\":\n",
    "            return {\"messages\": messages, \"user_level\": user_level, \"next\": \"proceed\"}\n",
    "        else:\n",
    "            return {\"messages\": [*messages, AIMessage(content=result.response)], \n",
    "                    \"user_level\": user_level, \n",
    "                    \"next\": \"redirect\"}\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Validation error: {str(e)}\")\n",
    "        return {\"messages\": messages, \"user_level\": user_level, \"next\": \"proceed\"}\n",
    "\n",
    "def expand_ambiguous_question(state):\n",
    "    \"\"\"\n",
    "    Clarifies ambiguous questions by maintaining conversation context,\n",
    "    with improved handling of pronoun references to DSA concepts.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== CLARIFY NODE ===\")\n",
    "    messages = state[\"messages\"]\n",
    "    current_question = messages[-1].content\n",
    "    print(f\"Original question: {current_question}\")\n",
    "    \n",
    "    # Get the last 3 exchanges (up to 6 messages) for relevant context\n",
    "    context_messages = messages[-6:-1] if len(messages) > 6 else messages[:-1]\n",
    "    conversation_context = \"\\n\".join([\n",
    "        f\"{'User: ' if isinstance(m, HumanMessage) else 'Assistant: '}{m.content}\"\n",
    "        for m in context_messages\n",
    "    ])\n",
    "    \n",
    "    class ClarificationResult(BaseModel):\n",
    "        clarified_question: str = Field(\n",
    "            description=\"The clarified version of the question with pronouns replaced by their referents\",\n",
    "            default=\"\"  # Provide empty string as default\n",
    "        )\n",
    "        referenced_concept: str = Field(\n",
    "            description=\"The main DSA concept being referenced from previous context\",\n",
    "            default=\"\"  # Provide empty string as default\n",
    "        )\n",
    "    \n",
    "    model = ChatOpenAI(\n",
    "        model_name=\"gpt-4o-mini\", \n",
    "        temperature=0, \n",
    "        streaming=True, \n",
    "        api_key=st.secrets[\"OpenAI_key\"]\n",
    "    )\n",
    "    llm_with_clarification = model.with_structured_output(ClarificationResult)\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "You are a DSA question processor. Transform user's prompt into clear, context-aware queries.\n",
    "\n",
    "OBJECTIVE: Rewrite user's prompt to include relevant context from chat history while maintaining original intent.\n",
    "\n",
    "Previous conversation:\n",
    "{context}\n",
    "\n",
    "Current question: {question}\n",
    "\n",
    "TRANSFORMATION RULES:\n",
    "1. Replace pronouns with specific references\n",
    "   Before: \"How do I implement it?\"\n",
    "   After: \"How do I implement a binary search tree?\"\n",
    "\n",
    "2. Include relevant context\n",
    "   Before: \"What about the time complexity?\"\n",
    "   After: \"What is the time complexity of quicksort's partitioning step?\"\n",
    "\n",
    "3. Maintain technical precision\n",
    "   Before: \"How does the fast one work?\"\n",
    "   After: \"How does the O(n log n) merge sort algorithm work?\"\n",
    "\n",
    "4. Keep original meaning\n",
    "   Do NOT add assumptions or change the question's scope\n",
    "\n",
    "Return ONLY the reformulated question without explanation.\n",
    "\n",
    "\"\"\",\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm_with_clarification\n",
    "    \n",
    "    try:\n",
    "        result = chain.invoke({\n",
    "            \"context\": conversation_context,\n",
    "            \"question\": current_question\n",
    "        })\n",
    "        \n",
    "        # For non-DSA questions or greetings, use original question\n",
    "        if not result.needs_clarification:\n",
    "            print(\"No clarification needed - using original question\")\n",
    "            return {\"messages\": messages, \"user_level\": state[\"user_level\"]}\n",
    "            \n",
    "        # For questions needing clarification, verify we have the clarified version\n",
    "        if result.needs_clarification and result.clarified_question:\n",
    "            print(f\"Referenced concept: {result.referenced_concept}\")\n",
    "            print(f\"Clarified to: {result.clarified_question}\")\n",
    "            return {\"messages\": [HumanMessage(content=result.clarified_question)], \"user_level\": state[\"user_level\"]}\n",
    "        else:\n",
    "            print(\"No clarification needed\")\n",
    "            return {\"messages\": messages, \"user_level\": state[\"user_level\"]}\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in clarification: {str(e)}\")\n",
    "        # On error, proceed with original question\n",
    "        return {\"messages\": messages, \"user_level\": state[\"user_level\"]}\n",
    "    \n",
    "\n",
    "def evaluate_and_retrieve(state):\n",
    "    \"\"\"\n",
    "    Invokes the agent model to generate a response based on confidence level.\n",
    "    \n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with the agent response appended to messages\n",
    "    \"\"\"\n",
    "    print(\"---CALL AGENT---\")\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # System message that enforces confidence-based retrieval\n",
    "    system_message = \"\"\"You are a DSA expert assistant. For every question:\n",
    "\n",
    "1. First, assess if you need additional reference information:\n",
    "   - Do you need specific implementation details?\n",
    "   - Do you need exact complexity analysis?\n",
    "   - Do you need specific examples or edge cases?\n",
    "\n",
    "2. Based on the assessment:\n",
    "   - Use the retrieve_documents tool if you need specific details\n",
    "   - Base your answer on the retrieved information when used\n",
    "   - Provide direct answers when appropriate\n",
    "\n",
    "3. Response guidelines:\n",
    "   - Be clear and concise\n",
    "   - Focus on accuracy and completeness\n",
    "   - Provide examples when helpful\n",
    "   - Use appropriate technical depth for the user's level\n",
    "\n",
    "Remember: Always prioritize providing accurate and helpful information.\"\"\"\n",
    "\n",
    "    # Prepare messages with system instruction\n",
    "    full_messages = [\n",
    "        HumanMessage(content=system_message),\n",
    "        *messages\n",
    "    ]\n",
    "    \n",
    "    # Initialize model with tools\n",
    "    model = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", streaming=True, api_key=st.secrets[\"OpenAI_key\"])\n",
    "    model = model.bind_tools(tools)\n",
    "    \n",
    "    # Get response\n",
    "    response = model.invoke(full_messages)\n",
    "    \n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def assess_document_relevance(state) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    \"\"\"\n",
    "    Enhanced grading system for retrieved DSA documents.\n",
    "    \n",
    "    Evaluates:\n",
    "    1. Relevance to the question\n",
    "    2. Completeness of the answer\n",
    "    3. Technical accuracy\n",
    "    4. Need for clarification\n",
    "    \n",
    "    Returns:\n",
    "    - \"generate\": When documents are good enough to generate response\n",
    "    - \"rewrite\": When documents aren't relevant enough\n",
    "    - \"clarify\": When question needs clarification\n",
    "    \"\"\"\n",
    "    print(\"---ENHANCED GRADING SYSTEM---\")\n",
    "    \n",
    "    class GradeResult(BaseModel):\n",
    "        relevance_score: float = Field(description=\"0-1 score for topic relevance\")\n",
    "        completeness_score: float = Field(description=\"0-1 score for answer completeness\")\n",
    "        technical_accuracy: float = Field(description=\"0-1 score for technical accuracy\")\n",
    "        reasoning: str = Field(description=\"Explanation for the grading decision\")\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    retrieved_docs = messages[-1].content\n",
    "\n",
    "    # Define the grading prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a DSA expert grading retrieved content.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Retrieved Content:\n",
    "{content}\n",
    "\n",
    "Grade this content on:\n",
    "1. Relevance: Does it directly address the DSA concepts in the question?\n",
    "2. Completeness: Does it cover all aspects needed for a good answer?\n",
    "3. Technical Accuracy: Is the DSA information correct and precise?\n",
    "4. Clarity: Is the question clear or needs clarification?\n",
    "\n",
    "Example DSA concepts to check for:\n",
    "- Data structure definitions and properties\n",
    "- Algorithm steps and processes\n",
    "- Time/space complexity mentions\n",
    "- Implementation details\n",
    "- Common use cases and examples\n",
    "\n",
    "Return scores as decimals between 0 and 1, where:\n",
    "- 0.0-0.3: Poor\n",
    "- 0.4-0.6: Moderate\n",
    "- 0.7-1.0: Good\n",
    "\n",
    "Also explain your reasoning.\"\"\",\n",
    "        input_variables=[\"question\", \"content\"]\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Initialize model with lower temperature for consistent grading\n",
    "        model = ChatOpenAI(\n",
    "            model_name=\"gpt-4o-mini\",\n",
    "            temperature=0,\n",
    "            streaming=True,\n",
    "            api_key=st.secrets[\"OpenAI_key\"]\n",
    "        )\n",
    "        \n",
    "        # Grade with structured output\n",
    "        chain = prompt | model.with_structured_output(GradeResult)\n",
    "        result = chain.invoke({\n",
    "            \"question\": question,\n",
    "            \"content\": retrieved_docs\n",
    "        })\n",
    "        \n",
    "        print(f\"Grading Results:\\n\"\n",
    "              f\"Relevance: {result.relevance_score:.2f}\\n\"\n",
    "              f\"Completeness: {result.completeness_score:.2f}\\n\"\n",
    "              f\"Technical Accuracy: {result.technical_accuracy:.2f}\\n\")\n",
    "            \n",
    "        # Calculate weighted average score\n",
    "        weighted_score = (\n",
    "            result.relevance_score * 0.4 +      # Relevance is most important\n",
    "            result.completeness_score * 0.3 +    # Completeness next\n",
    "            result.technical_accuracy * 0.3      # Technical accuracy equally important\n",
    "        )\n",
    "        \n",
    "        # Decision thresholds\n",
    "        GOOD_THRESHOLD = 0.65\n",
    "        \n",
    "        if weighted_score >= GOOD_THRESHOLD:\n",
    "            print(\"---DECISION: CONTENT GOOD ENOUGH TO GENERATE---\")\n",
    "            return \"generate\"\n",
    "        else:\n",
    "            print(\"---DECISION: NEED TO REWRITE QUERY---\")\n",
    "            return \"rewrite\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Grading error: {str(e)}\")\n",
    "        # On error, default to rewrite for safety\n",
    "        return \"rewrite\"\n",
    "    \n",
    "def optimize_query(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "\n",
    "    msg = [\n",
    "        HumanMessage(\n",
    "            content=f\"\"\" \\n \n",
    "    Look at the input and try to reason about the underlying semantic intent / meaning. \\n \n",
    "    Here is the initial question:\n",
    "    \\n ------- \\n\n",
    "    {question} \n",
    "    \\n ------- \\n\n",
    "    Formulate an improved question: \"\"\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Grader\n",
    "    model = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", streaming=True,api_key=st.secrets[\"OpenAI_key\"])\n",
    "    response = model.invoke(msg)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def synthesize_response(state):\n",
    "    \"\"\"Generate response based on retrieved content and question with strong user level differentiation\"\"\"\n",
    "    print(\"\\n=== GENERATE RESPONSE ===\")\n",
    "    messages = state[\"messages\"]\n",
    "    user_level = state[\"user_level\"]\n",
    "    \n",
    "    # Get last question\n",
    "    question = None\n",
    "    for msg in messages:\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            question = msg.content\n",
    "            \n",
    "    if not question:\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=\"Please rephrase your question.\")],\n",
    "            \"user_level\": user_level\n",
    "        }\n",
    "\n",
    "    docs = messages[-1].content\n",
    "    \n",
    "    if not docs or len(docs.strip()) < 10:\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=\"Please rephrase your question for more relevant results.\")], \n",
    "            \"user_level\": user_level\n",
    "        }\n",
    "        \n",
    "    try:\n",
    "        llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0, streaming=True, api_key=st.secrets[\"OpenAI_key\"])\n",
    "        \n",
    "        # Level-specific content requirements\n",
    "        level_requirements = {\n",
    "            \"beginner\": \"\"\"\n",
    "                REQUIRED CONTENT STRUCTURE FOR BEGINNER LEVEL:\n",
    "                1. Simple definition using everyday analogies\n",
    "                2. Basic step-by-step explanation with a small example (max 5 elements)\n",
    "                3. Very basic time complexity (just \"fast\" or \"slow\" for different scenarios)\n",
    "                4. ONE simple real-world application\n",
    "                5. No implementation details unless specifically asked\n",
    "                6. Avoid technical jargon - use simple terms\n",
    "                \n",
    "                TONE AND STYLE:\n",
    "                - Use simple, clear language\n",
    "                - Break complex ideas into small steps\n",
    "                - Focus on building intuition\n",
    "                - Limit mathematical notation\n",
    "                Maximum response length: 250 words\n",
    "            \"\"\",\n",
    "            \n",
    "            \"intermediate\": \"\"\"\n",
    "                REQUIRED CONTENT STRUCTURE FOR INTERMEDIATE LEVEL:\n",
    "                1. Technical definition with implementation overview\n",
    "                2. Detailed step-by-step explanation with medium example (5-10 elements)\n",
    "                3. Time/space complexity with basic explanation\n",
    "                4. Common use cases and trade-offs\n",
    "                5. Basic pseudocode if relevant\n",
    "                6. Technical terms with brief explanations\n",
    "                \n",
    "                TONE AND STYLE:\n",
    "                - Balance technical and plain language\n",
    "                - Include some implementation details\n",
    "                - Explain why certain choices are made\n",
    "                - Use some mathematical notation\n",
    "                Maximum response length: 400 words\n",
    "            \"\"\",\n",
    "            \n",
    "            \"advanced\": \"\"\"\n",
    "                REQUIRED CONTENT STRUCTURE FOR ADVANCED LEVEL:\n",
    "                1. Precise technical definition with implementation considerations\n",
    "                2. In-depth analysis with complex examples\n",
    "                3. Detailed time/space complexity analysis with proofs if relevant\n",
    "                4. Edge cases and optimization techniques\n",
    "                5. Implementation variations and trade-offs\n",
    "                6. Advanced applications and modifications\n",
    "                \n",
    "                TONE AND STYLE:\n",
    "                - Use technical terminology freely\n",
    "                - Focus on optimization and efficiency\n",
    "                - Include mathematical proofs when relevant\n",
    "                - Discuss system-level considerations\n",
    "                Maximum response length: 600 words\n",
    "            \"\"\"\n",
    "        }\n",
    "\n",
    "        print(\"\\nDebug user level: \", user_level.lower())\n",
    "        \n",
    "        # Get appropriate requirements for user level\n",
    "        level_specific_requirements = level_requirements.get(\n",
    "            user_level.lower(), \n",
    "            level_requirements[\"intermediate\"]  # Default to intermediate if level unknown\n",
    "        )\n",
    "        \n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=['context', 'question', 'level_requirements'], \n",
    "            template=\"\"\"\n",
    "                Generate a DSA explanation following these exact requirements:\n",
    "\n",
    "                {level_requirements}\n",
    "\n",
    "                Use this reference material: \"{context}\"\n",
    "                \n",
    "                Question: {question}\n",
    "                \n",
    "                Generate response following the exact structure and constraints above.\n",
    "                \"\"\"\n",
    "        )\n",
    "        \n",
    "        chain = prompt | llm | StrOutputParser()\n",
    "        response = chain.invoke({\n",
    "            \"context\": docs,\n",
    "            \"question\": question,\n",
    "            \"level_requirements\": level_specific_requirements\n",
    "        })\n",
    "        \n",
    "        return {\"messages\": [AIMessage(content=response)], \"user_level\": user_level}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=\"Please try rephrasing your question.\")], \n",
    "            \"user_level\": user_level\n",
    "        }\n",
    "\n",
    "################################################################################################################\n",
    "# Graph setup\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"classify_user_input\", classify_user_input)\n",
    "workflow.add_node(\"expand_ambiguous_question\", expand_ambiguous_question)\n",
    "workflow.add_node(\"evaluate_and_retrieve\", evaluate_and_retrieve)\n",
    "retrieve = ToolNode([retriever_tool])\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"synthesize_response\", synthesize_response)\n",
    "workflow.add_node(\"optimize_query\", optimize_query)\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(START, \"classify_user_input\")\n",
    "\n",
    "# Modify validation to return three possible outcomes\n",
    "workflow.add_conditional_edges(\n",
    "    \"classify_user_input\",\n",
    "    lambda x: x[\"next\"],\n",
    "    {\n",
    "        \"proceed\": \"evaluate_and_retrieve\",\n",
    "        \"clarify\": \"expand_ambiguous_question\",\n",
    "        \"redirect\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# After clarification, go to agent\n",
    "workflow.add_edge(\"expand_ambiguous_question\", \"evaluate_and_retrieve\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"evaluate_and_retrieve\",\n",
    "    tools_condition,\n",
    "    {\n",
    "        \"tools\": \"retrieve\",\n",
    "        END: END,\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    assess_document_relevance,\n",
    "    {\n",
    "        \"generate\": \"synthesize_response\",\n",
    "        \"rewrite\": \"optimize_query\",\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"synthesize_response\", END)\n",
    "workflow.add_edge(\"optimize_query\", \"evaluate_and_retrieve\")\n",
    "\n",
    "# Compile graph\n",
    "from test_templates.memory import memory\n",
    "graph = workflow.compile()\n",
    "\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(\"what is Insertion Sort\"),\n",
    "    ],\n",
    "    \"user_level\": \"beginner\"\n",
    "}\n",
    "\n",
    "output = graph.invoke(inputs)\n",
    "print('output:',output[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elroy\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\nltk\\metrics\\association.py:26: UserWarning: A NumPy version >=1.23.5 and <2.3.0 is required for this version of SciPy (detected version 1.23.2)\n",
      "  from scipy.stats import fisher_exact\n",
      "c:\\Users\\elroy\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "2025-02-20 20:45:18.458 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:18.467 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:18.478 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:18.485 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:18.598 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:18.599 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:18.600 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing retriever...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 20:45:18.969 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\elroy\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-02-20 20:45:18.970 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:18.971 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:18.971 Session state does not function when running a script without `streamlit run`\n",
      "2025-02-20 20:45:18.972 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:18.973 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:18.974 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:18.975 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:18.975 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:18.976 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:18.976 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:18.977 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:18.978 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:18.978 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:18.979 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:18.979 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:18.980 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:18.981 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:18.981 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:18.982 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:18.984 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:18.987 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:18.992 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:18.994 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.042 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.044 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.046 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.047 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.047 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.048 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.049 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.049 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.052 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.052 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.053 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.053 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.054 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.055 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising the app...\n",
      "\n",
      "Clearing session variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 20:45:19.756 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.757 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.758 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.759 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.760 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.760 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.761 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.762 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.763 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.763 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.764 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.765 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.765 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.766 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.766 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.767 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.768 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.768 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.769 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.771 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.771 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.776 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.777 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.778 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.778 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.780 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.781 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.782 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.783 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.785 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.785 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.786 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.786 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.787 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.788 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.789 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.790 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.792 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.793 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.794 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.796 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.797 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.798 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.798 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.800 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.801 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.802 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.802 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.804 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.805 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.806 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.808 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.809 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.810 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.810 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.811 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.812 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.814 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.816 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.817 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.817 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.818 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.819 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.819 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.821 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.822 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.822 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.824 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.826 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.827 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.828 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.829 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.830 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.831 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.832 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.834 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.834 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.835 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.837 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.838 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.838 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.839 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.840 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.841 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.842 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.844 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.844 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.845 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.845 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.881 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.883 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.884 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.884 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.885 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.887 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.888 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-20 20:45:19.889 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='explain this', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Sure! Let’s break down the concepts in the image step by step. It looks like you’re working with a sorting algorithm, specifically **Insertion Sort**. Let’s dive in!\\n\\n### What We're Looking At\\nI see you're working with a visual representation of the Insertion Sort algorithm! This method sorts an array by building a sorted section of the array one element at a time. It’s a great way to understand how sorting works, especially for beginners.\\n\\n### Key Concepts\\n\\n#### Insertion Sort\\nYou know what's cool about this? Insertion Sort works similarly to how you might sort playing cards in your hands. You take one card at a time and place it in the correct position among the cards you’ve already sorted.\\n\\n#### Steps of the Algorithm\\nLet’s break down the steps shown in the image:\\n\\n1. **Initial Position**: The first element (7) is considered sorted since there’s nothing to its left. \\n2. **Comparing and Shifting**: As you move to the next element (4), you compare it with the sorted section (just 7). Since 4 is less than 7, you shift 7 to the right and place 4 in the first position.\\n3. **Continuing the Process**: Next, you look at 5. You compare it with 4 and 7. Since 5 is less than 7 but greater than 4, you shift 7 to the right and place 5 in the correct position.\\n4. **Final Adjustments**: Finally, you check 2 against all the sorted elements. Since 2 is less than all of them, you shift them all to the right and place 2 at the start.\\n\\n### Understanding the Details\\n\\n#### Step-by-Step Breakdown\\n- **Step 1**: The array starts as [7, 4, 5, 2]. Since 7 is the first element, it stays put.\\n- **Step 2**: When you bring in 4, you see it’s smaller than 7, so you move 7 to the right and insert 4 at the start: [4, 7, 5, 2].\\n- **Step 3**: Next, you look at 5. It’s smaller than 7 but larger than 4, so you shift 7 to the right and place 5 in the middle: [4, 5, 7, 2].\\n- **Step 4**: Finally, with 2, you find it’s smaller than all the sorted elements, so you shift them all to the right and place 2 at the start: [2, 4, 5, 7].\\n\\n### Real-World Connection\\nThink about organizing your bookshelf. When you get a new book, you don’t just throw it on the shelf. Instead, you find the right spot by comparing it to the books already there. That’s exactly what Insertion Sort does!\\n\\n### Encouraging Note\\nGreat job exploring sorting algorithms! If you have any questions or want to dive deeper into any part of this process, feel free to ask. Happy learning!\", additional_kwargs={}, response_metadata={})]\n",
      "output: current_level='beginner' recommendation='Maintain' confidence=0.9 evidence=['User asked for an explanation of Insertion Sort, indicating a desire to understand basic concepts.', 'User engaged with the explanation and followed the step-by-step breakdown provided.'] reasoning=['User demonstrates a basic understanding of sorting algorithms, as evidenced by their request for clarification on Insertion Sort.', 'The interaction shows that the user is still in the early stages of learning, needing guidance and support to grasp fundamental concepts.']\n"
     ]
    }
   ],
   "source": [
    "### Analyse Chat\n",
    "# app = workflow.compile(checkpointer=memory)\n",
    "from test_templates.intial_template import app\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from app_LG import db\n",
    "langgraph_config = {\"configurable\": {\"thread_id\": \"2200499\"}}\n",
    "chat_history = db.load_chat_history(\"6fcf537a-8e1e-496b-be68-84841722fa57\", \"6fcf537a-8e1e-496b-be68-84841722fa57_1\")\n",
    "updated_messages = []\n",
    "for message in chat_history:\n",
    "    if message[\"role\"] == \"user\":\n",
    "        updated_messages.append(HumanMessage(content=message[\"content\"]))\n",
    "    else:\n",
    "        updated_messages.append(AIMessage(content=message[\"content\"]))\n",
    "\n",
    "print(updated_messages)\n",
    "\n",
    "# Process the user input\n",
    "from test_templates.analyser import graph\n",
    "\n",
    "graph.update_state(values = {\"messages\": updated_messages}, config = langgraph_config)\n",
    "\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(\"Hi\")\n",
    "    ],\n",
    "    \"user_level\": \"beginner\"\n",
    "}\n",
    "\n",
    "output = graph.invoke(inputs, langgraph_config)\n",
    "print('output:',output[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"current_level='beginner' recommendation='Maintain' confidence=0.9 evidence=['User asked for an explanation of Insertion Sort, indicating a desire to understand basic concepts.', 'User engaged with the explanation and followed the step-by-step breakdown provided.'] reasoning=['User demonstrates a basic understanding of sorting algorithms, as evidenced by their request for clarification on Insertion Sort.', 'The interaction shows that the user is still in the early stages of learning, needing guidance and support to grasp fundamental concepts.']\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat History using LangGraph\n",
    "[Langgraph][https://python.langchain.com/docs/how_to/message_history/]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=st.secrets[\"OpenAI_key\"],\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    # Update message history with response:\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Define the (single) node in the graph\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Hi! I'm Bob.\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "# for chunk in app.stream({\"messages\": input_messages}, config):\n",
    "#     print(chunk)\n",
    "    \n",
    "\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].content\n",
    "# output[\"messages\"][-1].pretty_print()  # output contains all messages in state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What's my name?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = app.get_state(config).values[\"messages\"]\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removal of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import RemoveMessage\n",
    "\n",
    "updated_messages = [RemoveMessage(m.id) for m in messages]\n",
    "app.update_state(values = {\"messages\": updated_messages}, config = config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What's my name?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"abc234\"}}\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain with Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Answer in {language}.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "runnable = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    language: str\n",
    "\n",
    "\n",
    "workflow = StateGraph(state_schema=State)\n",
    "\n",
    "\n",
    "def call_model(state: State):\n",
    "    response = runnable.invoke(state)\n",
    "    # Update message history with response:\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "# input_dict = {\n",
    "#     \"messages\": [HumanMessage(\"Hi, I'm Bob.\")],\n",
    "#     \"language\": \"Spanish\",\n",
    "# }\n",
    "\n",
    "# output = app.invoke(input_dict, config)\n",
    "print(output)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "state = app.get_state(config).values\n",
    "\n",
    "# print(f'Language: {state[\"language\"]}')\n",
    "for message in state[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append new messages manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "_ = app.update_state(config, {\"messages\": [HumanMessage(\"Test\")]})\n",
    "_ = app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = app.get_state(config).values\n",
    "\n",
    "print(f'Language: {state[\"language\"]}')\n",
    "for message in state[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from utils.chunk_doc import get_retriever\n",
    "import os\n",
    "import streamlit as st\n",
    "\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY']= st.secrets[\"New_Langsmith_key\"]\n",
    "os.environ['LANGCHAIN_PROJECT']=\"default\"\n",
    "\n",
    "retriever = get_retriever()\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retrieve_documents\",\n",
    "    \"Search and return relevant documents based on user's query.\",\n",
    ")\n",
    "\n",
    "tools = [retriever_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # The add_messages function defines how an update should be processed\n",
    "    # Default is to replace. add_messages says \"append\"\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************Prompt[rlm/rag-prompt]********************\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: \u001b[33;1m\u001b[1;3m{question}\u001b[0m \n",
      "Context: \u001b[33;1m\u001b[1;3m{context}\u001b[0m \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated, Literal, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "### Edges\n",
    "\n",
    "\n",
    "def grade_documents(state) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        str: A decision for whether the documents are relevant or not\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK RELEVANCE---\")\n",
    "\n",
    "    # Data model\n",
    "    class grade(BaseModel):\n",
    "        \"\"\"Binary score for relevance check.\"\"\"\n",
    "\n",
    "        binary_score: str = Field(description=\"Relevance score 'yes' or 'no'\")\n",
    "\n",
    "    # LLM\n",
    "    model = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", streaming=True,api_key=st.secrets[\"OpenAI_key\"])\n",
    "\n",
    "    # LLM with tool and validation\n",
    "    llm_with_tool = model.with_structured_output(grade)\n",
    "\n",
    "    # Prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
    "        Here is the user question: {question} \\n\n",
    "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "    # Chain\n",
    "    chain = prompt | llm_with_tool\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    question = messages[0].content\n",
    "    docs = last_message.content\n",
    "\n",
    "    scored_result = chain.invoke({\"question\": question, \"context\": docs})\n",
    "\n",
    "    score = scored_result.binary_score\n",
    "\n",
    "    if score == \"yes\":\n",
    "        print(\"---DECISION: DOCS RELEVANT---\")\n",
    "        return \"generate\"\n",
    "\n",
    "    else:\n",
    "        print(\"---DECISION: DOCS NOT RELEVANT---\")\n",
    "        print(score)\n",
    "        return \"rewrite\"\n",
    "\n",
    "\n",
    "### Nodes\n",
    "\n",
    "\n",
    "def agent(state):\n",
    "    \"\"\"\n",
    "    Invokes the agent model to generate a response based on the current state. Given\n",
    "    the question, it will decide to retrieve using the retriever tool, or simply end.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with the agent response appended to messages\n",
    "    \"\"\"\n",
    "    print(\"---CALL AGENT---\")\n",
    "    messages = state[\"messages\"]\n",
    "    model = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", streaming=True,api_key=st.secrets[\"OpenAI_key\"])\n",
    "    model = model.bind_tools(tools)\n",
    "    response = model.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def rewrite(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "\n",
    "    msg = [\n",
    "        HumanMessage(\n",
    "            content=f\"\"\" \\n \n",
    "    Look at the input and try to reason about the underlying semantic intent / meaning. \\n \n",
    "    Here is the initial question:\n",
    "    \\n ------- \\n\n",
    "    {question} \n",
    "    \\n ------- \\n\n",
    "    Formulate an improved question: \"\"\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Grader\n",
    "    model = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", streaming=True,api_key=st.secrets[\"OpenAI_key\"])\n",
    "    response = model.invoke(msg)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "         dict: The updated state with re-phrased question\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    docs = last_message.content\n",
    "\n",
    "    # Prompt\n",
    "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "    # LLM\n",
    "    llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", streaming=True,api_key=st.secrets[\"OpenAI_key\"])\n",
    "\n",
    "    # Post-processing\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    # Chain\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    # Run\n",
    "    response = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "print(\"*\" * 20 + \"Prompt[rlm/rag-prompt]\" + \"*\" * 20)\n",
    "prompt = hub.pull(\"rlm/rag-prompt\").pretty_print()  # Show what the prompt looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the nodes we will cycle between\n",
    "workflow.add_node(\"agent\", agent)  # agent\n",
    "retrieve = ToolNode([retriever_tool])\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieval\n",
    "workflow.add_node(\"rewrite\", rewrite)  # Re-writing the question\n",
    "workflow.add_node(\n",
    "    \"generate\", generate\n",
    ")  # Generating a response after we know the documents are relevant\n",
    "# Call agent node to decide to retrieve or not\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# Decide whether to retrieve\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    # Assess agent decision\n",
    "    tools_condition,\n",
    "    {\n",
    "        # Translate the condition outputs to nodes in our graph\n",
    "        \"tools\": \"retrieve\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Edges taken after the `action` node is called.\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    # Assess agent decision\n",
    "    grade_documents,\n",
    ")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "workflow.add_edge(\"rewrite\", \"agent\")\n",
    "\n",
    "# Compile\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALL AGENT---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK RELEVANCE---\n",
      "---DECISION: DOCS NOT RELEVANT---\n",
      "no\n",
      "---TRANSFORM QUERY---\n",
      "---CALL AGENT---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK RELEVANCE---\n",
      "---DECISION: DOCS NOT RELEVANT---\n",
      "no\n",
      "---TRANSFORM QUERY---\n",
      "---CALL AGENT---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK RELEVANCE---\n",
      "---DECISION: DOCS NOT RELEVANT---\n",
      "no\n",
      "---TRANSFORM QUERY---\n",
      "---CALL AGENT---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK RELEVANCE---\n",
      "---DECISION: DOCS NOT RELEVANT---\n",
      "no\n",
      "---TRANSFORM QUERY---\n",
      "---CALL AGENT---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK RELEVANCE---\n",
      "---DECISION: DOCS NOT RELEVANT---\n",
      "no\n",
      "---TRANSFORM QUERY---\n",
      "---CALL AGENT---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK RELEVANCE---\n",
      "---DECISION: DOCS NOT RELEVANT---\n",
      "no\n",
      "---TRANSFORM QUERY---\n",
      "---CALL AGENT---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 15\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# inputs = {\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#     \"messages\": [\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#         HumanMessage(\"What is quick sort\")\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#     ]\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# }\u001b[39;00m\n\u001b[0;32m      9\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m     11\u001b[0m         HumanMessage(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWho is obama\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     12\u001b[0m     ]\n\u001b[0;32m     13\u001b[0m }\n\u001b[1;32m---> 15\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput:\u001b[39m\u001b[38;5;124m'\u001b[39m,output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# for output in graph.stream(inputs):\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#     for key, value in output.items():\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#         pprint.pprint(f\"Output from node '{key}':\")\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#         pprint.pprint(\"---\")\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#         pprint.pprint(value, indent=2, width=80, depth=None)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#     pprint.pprint(\"\\n---\\n\")\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Elroy Lian\\.conda\\envs\\chatbot\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1940\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[0;32m   1938\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1939\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1940\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1941\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1944\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1945\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1946\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1947\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1948\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1949\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1950\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Elroy Lian\\.conda\\envs\\chatbot\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1660\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1657\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1658\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 1660\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1661\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[0;32m   1667\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Elroy Lian\\.conda\\envs\\chatbot\\Lib\\site-packages\\langgraph\\pregel\\runner.py:167\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    165\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 167\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\Elroy Lian\\.conda\\envs\\chatbot\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\Users\\Elroy Lian\\.conda\\envs\\chatbot\\Lib\\site-packages\\langgraph\\utils\\runnable.py:408\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m    405\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    406\u001b[0m )\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 408\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\Elroy Lian\\.conda\\envs\\chatbot\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:246\u001b[0m, in \u001b[0;36mToolNode.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m    245\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Elroy Lian\\.conda\\envs\\chatbot\\Lib\\site-packages\\langgraph\\utils\\runnable.py:184\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 184\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\Elroy Lian\\.conda\\envs\\chatbot\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:219\u001b[0m, in \u001b[0;36mToolNode._func\u001b[1;34m(self, input, config, store)\u001b[0m\n\u001b[0;32m    217\u001b[0m input_types \u001b[38;5;241m=\u001b[39m [input_type] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(tool_calls)\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m--> 219\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;241m*\u001b[39mexecutor\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_one, tool_calls, input_types, config_list)\n\u001b[0;32m    221\u001b[0m     ]\n\u001b[0;32m    223\u001b[0m \u001b[38;5;66;03m# preserve existing behavior for non-command tool outputs for backwards compatibility\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(output, Command) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs):\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;66;03m# TypedDict, pydantic, dataclass, etc. should all be able to load from dict\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Elroy Lian\\.conda\\envs\\chatbot\\Lib\\concurrent\\futures\\_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[1;32mc:\\Users\\Elroy Lian\\.conda\\envs\\chatbot\\Lib\\concurrent\\futures\\_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 317\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[1;32mc:\\Users\\Elroy Lian\\.conda\\envs\\chatbot\\Lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\Elroy Lian\\.conda\\envs\\chatbot\\Lib\\threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 327\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "# inputs = {\n",
    "#     \"messages\": [\n",
    "#         HumanMessage(\"What is quick sort\")\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(\"Who is obama\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "output = graph.invoke(inputs)\n",
    "print('output:',output[\"messages\"][-1].content)\n",
    "# for output in graph.stream(inputs):\n",
    "#     for key, value in output.items():\n",
    "#         pprint.pprint(f\"Output from node '{key}':\")\n",
    "#         pprint.pprint(\"---\")\n",
    "#         pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "#     pprint.pprint(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elroy\\AppData\\Local\\Temp\\ipykernel_30700\\1394110419.py:6: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=st.secrets[\"OpenAI_key\"],\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_templates.image_template import image_app\n",
    "def read_image_bytes(image_path):\n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        return image_file.read()\n",
    "img = read_image_bytes('test_image_1.jpeg')\n",
    "import base64\n",
    "\n",
    "image_data = base64.b64encode(img).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "\n",
    "# image_chain = get_image_chain()\n",
    "\n",
    "message_content = [{\"type\": \"text\", \"text\": \"Describe the image provided\"}]\n",
    "message_content.append({\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"}\n",
    "                })\n",
    "\n",
    "final_message = {\n",
    "    \"messages\":[\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": message_content,\n",
    "    }],\n",
    "    \"user_level\": \"beginner\"}\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "image_app.invoke(input = final_message,config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing retrieval for: What is quicksort?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No index params provided. Could not determine relevance function. Use L2 distance as default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of documents found: 10\n",
      "\n",
      "--- Document 1 ---\n",
      "Source: data\\md\\algo1.md\n",
      "Content: ###### The basic algorithm  Quicksort is a divide-and-conquer method for sorting. It\n",
      "\n",
      "works by partitioning an array into two subarrays, then sorting the subarrays independently. Quicksort is compleme...\n",
      "\n",
      "--- Document 2 ---\n",
      "Source: data\\md\\algo1.md\n",
      "Content: -----\n",
      "\n",
      "###### Performance characteristics Quicksort has been subjected to very thorough\n",
      "\n",
      "mathematical analysis, so that we can make precise statements about its performance.\n",
      "The analysis has been vali...\n",
      "\n",
      "--- Document 3 ---\n",
      "Source: data\\md\\divide-and-conquer.md\n",
      "Content: - Slower than QuickSort in general. QuickSort is more cache friendly because it works in-place.\n",
      "\n",
      "\n",
      "Quick Links:\n",
      "\n",
      "\n",
      "\n",
      "- Merge Sort Based Coding Questions\n",
      "\n",
      "- Bottom up (or Iterative) Merge Sort\n",
      "\n",
      "- Recent A...\n",
      "\n",
      "--- Document 4 ---\n",
      "Source: data\\md\\randomized-algorithms.md\n",
      "Content: ### C#\n",
      "\n",
      "\n",
      "```\n",
      "// C# implementation of QuickSort// using Hoare's partition schemeusingSystem;publicclassGFG {// Driver CodepublicstaticvoidMain(){int[] arr = { 10, 7, 8, 9, 1, 5 };intn = arr.Length;quic...\n",
      "\n",
      "--- Document 5 ---\n",
      "Source: data\\md\\algo1.md\n",
      "Content: Thus, in most practical situations, quicksort is the method of choice. Still, given the\n",
      "broad reach of sorting and the broad variety of computers and systems, a flat statement\n",
      "like this is difficult t...\n",
      "\n",
      "--- Document 6 ---\n",
      "Source: data\\md\\randomized-algorithms.md\n",
      "Content: ### Javascript\n",
      "\n",
      "\n",
      "```\n",
      "// javascript implementation of QuickSort// using Hoare's partition scheme// This function takes last element as // pivot, places the pivot element at// its correct position in so...\n",
      "\n",
      "--- Document 7 ---\n",
      "Source: data\\md\\algo1.md\n",
      "Content: As with standard quicksort, the running time tends to the average as the array size\n",
      "\n",
      "grows, and large deviations from the average are extremely unlikely, so that you can\n",
      "depend on 3-way quicksort’s ru...\n",
      "\n",
      "--- Document 8 ---\n",
      "Source: data\\md\\dsa1.md\n",
      "Content: whole array to reflect the splitting. We say that we partition the array, and the Quicksort\n",
      "algorithm is then applied to the sub-arrays of this partitioned array.\n",
      "In order for the algorithm to be call...\n",
      "\n",
      "--- Document 9 ---\n",
      "Source: data\\md\\sorting-algorithms.md\n",
      "Content: def quicksort(arr, low, high):\n",
      "        if low < high:\n",
      "            pi = partition(arr, low, high)\n",
      "            quicksort(arr, low, pi - 1)\n",
      "            quicksort(arr, pi + 1, high)\n",
      "\n",
      "    quicksort(element...\n",
      "\n",
      "--- Document 10 ---\n",
      "Source: data\\md\\dsa1.md\n",
      "Content: ```\n",
      "77\n",
      "\n",
      "\n",
      "-----\n",
      "\n",
      "```\n",
      "      a[acount++] = a[i]\n",
      "    else\n",
      "      b[bcount++] = a[i]\n",
      "   }\n",
      "   for ( i = 0 ; i < bcount ; i++ )\n",
      "    a[acount++] = b[i]\n",
      "   return right-bcount+1\n",
      " }\n",
      "\n",
      "```\n",
      "Like the first partition...\n"
     ]
    }
   ],
   "source": [
    "from utils.chunk_doc import get_retriever\n",
    "\n",
    "def test_quicksort_retrieval():\n",
    "    # Get the retriever\n",
    "    retriever = get_retriever()\n",
    "    \n",
    "    # Test quicksort query\n",
    "    query = \"What is quicksort?\"\n",
    "    print(f\"\\nTesting retrieval for: {query}\")\n",
    "    \n",
    "    try:\n",
    "        # Get documents\n",
    "        docs = retriever.get_relevant_documents(query)\n",
    "        \n",
    "        print(f\"\\nNumber of documents found: {len(docs)}\")\n",
    "        \n",
    "        if len(docs) > 0:\n",
    "            for i, doc in enumerate(docs, 1):\n",
    "                print(f\"\\n--- Document {i} ---\")\n",
    "                print(f\"Source: {doc.metadata.get('source', 'No source')}\")\n",
    "                print(f\"Content: {doc.page_content[:200]}...\")\n",
    "        else:\n",
    "            print(\"No documents were retrieved!\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error during retrieval: {str(e)}\")\n",
    "\n",
    "# Run test\n",
    "if __name__ == \"__main__\":\n",
    "    test_quicksort_retrieval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
