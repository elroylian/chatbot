{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import streamlit as st\n",
    "\n",
    "# Load .env from the project root\n",
    "env_path = Path('..') / '.env'  # Go one directory up to locate .env\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY']= st.secrets[\"EXTRA_Langchain_key\"]\n",
    "# os.environ['LANGCHAIN_PROJECT']=\"pr-advanced-theism-85\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunk Retrieval using Metadata filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from utils.chunk_doc import get_retriever, get_vector_store\n",
    "\n",
    "\n",
    "\n",
    "# llm = ChatOpenAI(\n",
    "#     model=\"gpt-4o-mini\",\n",
    "#     api_key=st.secrets[\"OpenAI_key\"]\n",
    "# )\n",
    "\n",
    "vector_store = get_vector_store()\n",
    "\n",
    "query = \"What is Insertion Sort?\"\n",
    "metadata_filter = {\"keywords\": \"Insertion\"}\n",
    "# response = vector_store.search(query,search_type=\"mmr\", k=5, fetch_k=10)\n",
    "# print(response)\n",
    "found_docs = vector_store.max_marginal_relevance_search(query, filter=metadata_filter)\n",
    "print(found_docs)\n",
    "for i, doc in enumerate(found_docs):\n",
    "    print(f\"{i + 1}.\", doc.page_content, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Generation using LLAMA 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "from utils.custom_embeddings import MyEmbeddings\n",
    "from utils.chunk_doc import get_vector_store\n",
    "\n",
    "embedding_func = MyEmbeddings()\n",
    "\n",
    "# Initialize Ollama LLM\n",
    "llm = OllamaLLM(\n",
    "    # model=\"gemma2:2b\",\n",
    "    model = \"llama3.2:latest\",\n",
    "    base_url=\"http://localhost:11434\"  # Adjust this URL if needed\n",
    ")\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Define a prompt template for Ollama to generate keywords\n",
    "# Gemma2:2b Template\n",
    "# keyword_prompt_template = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\"system\", \"You are an assistant that generates keywords for a chunk of text. The keywords must be single words or two-word phrases. Format the output as: ['keyword1', 'keyword2']\"),\n",
    "#         (\"human\", \"Extract relevant keywords for the following chunk:\\n\\n{chunk_text}\")\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# Llama3.2:1b Template\n",
    "keyword_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an assistant that generates keywords for a chunk of text. \"\n",
    "                   \"Your response should only contain keywords in json format.\"),\n",
    "        (\"human\", \"Extract relevant keywords from the following chunk:\\n\\n{chunk_text}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = keyword_prompt_template | llm\n",
    "\n",
    "# Initialize Vector Store\n",
    "vector_store = get_vector_store()\n",
    "\n",
    "def split_chunks():\n",
    "    try:\n",
    "        from pathlib import Path\n",
    "        from langchain_core.documents import Document\n",
    "        from langchain_text_splitters import RecursiveCharacterTextSplitter as Rec\n",
    "        \n",
    "        # Path to markdown directory\n",
    "        md_dir = Path(\"../data/md/\")\n",
    "        chunk_id_counter = 1  # Initialize a counter for unique chunk IDs\n",
    "        ids = []\n",
    "        documents = []\n",
    "\n",
    "        # Loop through all markdown files in the md directory\n",
    "        for md_file in md_dir.glob(\"*.md\"):\n",
    "            with open(md_file, \"r\") as f:\n",
    "                md_content = f.read()\n",
    "\n",
    "            # Chunk the markdown content\n",
    "            text_splitter = Rec(\n",
    "                chunk_size=2000,\n",
    "                chunk_overlap=500,\n",
    "                length_function=len,\n",
    "                add_start_index=True\n",
    "            )\n",
    "            chunks = text_splitter.split_text(md_content)\n",
    "            \n",
    "            for chunk in chunks:\n",
    "                # Generate keywords for the chunk using Ollama\n",
    "                response = chain.invoke({\"chunk_text\": chunk})\n",
    "                \n",
    "                import json\n",
    "                # Convert the JSON string to a Python dictionary\n",
    "                dictionary_output = json.loads(response)\n",
    "\n",
    "                # Access the \"keywords\" list\n",
    "                keywords_list = dictionary_output[\"keywords\"]\n",
    "                \n",
    "                # Create a Document object with metadata for the chunk, including keywords\n",
    "                document_to_add = Document(\n",
    "                    page_content=chunk,\n",
    "                    metadata={\"source\": str(md_file), \"keywords\": str(keywords_list)}\n",
    "                )\n",
    "                \n",
    "                documents.append(document_to_add)\n",
    "                ids.append(str(chunk_id_counter))  # Add document ID to the list\n",
    "                chunk_id_counter += 1  # Increment the ID counter\n",
    "        \n",
    "        # Assuming vector_store is defined and initialized elsewhere\n",
    "        vector_store.add_documents(documents=documents, ids=ids)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    # split_chunks()\n",
    "    \n",
    "    # print(response)\n",
    "\n",
    "    response = chain.invoke({\"chunk_text\": \"\"\" ###### 2.1.1 Insertion\n",
    "\n",
    "In general when people talk about insertion with respect to linked lists of any\n",
    "form they implicitly refer to the adding of a node to the tail of the list. When\n",
    "you use an API like that of DSA and you see a general purpose method that\n",
    "adds a node to the list, you can assume that you are adding the node to the tail\n",
    "of the list not the head.\n",
    "\n",
    "Adding a node to a singly linked list has only two cases:\n",
    "\n",
    "1. head = in which case the node we are adding is now both the head and\n",
    "_∅_\n",
    "_tail of the list; or_\n",
    "\n",
    "2. we simply need to append our node onto the end of the list updating the\n",
    "_tail reference appropriately._\n",
    "\n",
    "1) algorithm Add(value)\n",
    "2) **Pre: value is the value to add to the list**\n",
    "3) **Post: value has been placed at the tail of the list**\n",
    "4) _n_ node(value)\n",
    "_←_\n",
    "5) **if head =**\n",
    "_∅_\n",
    "6) _head_ _n_\n",
    "_←_\n",
    "7) _tail_ _n_\n",
    "_←_\n",
    "8) **else**\n",
    "9) _tail.Next_ _n_\n",
    "_←_\n",
    "10) _tail_ _n_\n",
    "_←_\n",
    "11) **end if**\n",
    "12) end Add\n",
    "\n",
    "As an example of the previous algorithm consider adding the following sequence of integers to the list: 1, 45, 60, and 12, the resulting list is that of\n",
    "Figure 2.2.\n",
    "\n",
    "###### 2.1.2 Searching\n",
    "\n",
    "Searching a linked list is straightforward: we simply traverse the list checking\n",
    "the value we are looking for with the value of each node in the linked list. The\n",
    "algorithm listed in this section is very similar to that used for traversal in 2.1.4.\n",
    "_§_\n",
    "\n",
    "\n",
    "-----\n",
    "\n",
    "_CHAPTER 2. LINKED LISTS_ 11\n",
    "\n",
    "1) algorithm Contains(head, value)\n",
    "2) **Pre: head is the head node in the list**\n",
    "3) _value is the value to search for_\n",
    "4) **Post: the item is either in the linked list, true; otherwise false**\n",
    "5) _n_ _head_\n",
    "_←_\n",
    "6) **while n** = **and n.Value** = value\n",
    "_̸_ _∅_ _̸_\n",
    "7) _n_ _n.Next_\n",
    "_←_\n",
    "8) **end while**\n",
    "9) **if n =**\n",
    "_∅_\n",
    "10) **return false**\n",
    "11) **end if**\n",
    "12) **return true**\n",
    "13) end Contains\n",
    "\n",
    "###### 2.1.3 Deletion\n",
    "\n",
    "Deleting a node from a linked list is straightforward but there are a few cases\n",
    "we need to account for:\n",
    "\n",
    "1. the list is empty; or\n",
    "\n",
    "2. the node to remove is the only node in the linked list; or\n",
    "\n",
    "3. we are removing the head node; or\n",
    "\n",
    "4. we are removing the tail node; or\n",
    "\n",
    "5. the node to remove is somewhere in between the head and tail; or\n",
    "\n",
    "6. the item to remove doesn’t exist in the linked list\n",
    "\n",
    "The algorithm whose cases we have described will remove a node from anywhere within a list irrespective of whether the node is the head etc. If you know\n",
    "that items will only ever be removed from the head or tail of the list then you\n",
    "can create much more concise algorithms. In the case of always removing from\n",
    "the front of the linked list deletion becomes an O(1) operation.\"\"\"})\n",
    "\n",
    "    # print(dictionary_output)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from utils.custom_embeddings import MyEmbeddings\n",
    "import os\n",
    "import streamlit as st\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import OllamaLLM\n",
    "from utils.chunk_doc import get_vector_store\n",
    "\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY']= st.secrets[\"EXTRA_Langchain_key\"]\n",
    "os.environ['LANGCHAIN_PROJECT']=\"chatbot-test\"\n",
    "\n",
    "\n",
    "\n",
    "embedding_func = MyEmbeddings()\n",
    "\n",
    "\n",
    "# Multi Query: Different Perspectives\n",
    "template = \"\"\"You are an AI language model assistant. Your task is to generate five \n",
    "different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by a single newline. Original question: {question}\"\"\"\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "gpt4 = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    # api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    api_key=st.secrets[\"OpenAI_key\"],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# llm = OllamaLLM(model=\"gemma2:2b\", base_url=\"http://localhost:11434\")\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_perspectives \n",
    "    | gpt4\n",
    "    | StrOutputParser() \n",
    "    | (lambda x: [line for line in x.split(\"\\n\") if line.strip() != \"\"])  # Ensure empty strings are removed\n",
    ")\n",
    "\n",
    "from langchain.load import dumps, loads\n",
    "\n",
    "def get_unique_union(documents: list[list]):\n",
    "    \"\"\" Unique union of retrieved docs \"\"\"\n",
    "    # Flatten list of lists, and convert each Document to string\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    # Get unique documents\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "    # Return\n",
    "    return [loads(doc) for doc in unique_docs]\n",
    "\n",
    "# Initialize ChromaDB client\n",
    "vector_store = get_vector_store()\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# Retrieve\n",
    "question = \"What is Insertion Sort?\"\n",
    "retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
    "docs = retrieval_chain.invoke({\"question\":question})\n",
    "# print(docs)\n",
    "len(docs)\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | prompt\n",
    "    | gpt4\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\":question})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG-Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_chroma import Chroma\n",
    "from utils.custom_embeddings import MyEmbeddings\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from utils.chunk_doc import get_retriever, get_vector_store\n",
    "\n",
    "\n",
    "embedding_func = MyEmbeddings()\n",
    "\n",
    "\n",
    "# RAG-Fusion: Related\n",
    "template = \"\"\"You are a helpful assistant that generates multiple search queries based on a single input query. \\n\n",
    "Generate multiple search queries related to: {question} \\n\n",
    "Output (4 queries):\"\"\"\n",
    "prompt_rag_fusion = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    # api_key=st.secrets[\"OpenAI_key\"],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_rag_fusion \n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")\n",
    "\n",
    "from langchain.load import dumps, loads\n",
    "\n",
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    \"\"\" Reciprocal_rank_fusion that takes multiple lists of ranked documents \n",
    "        and an optional parameter k used in the RRF formula \"\"\"\n",
    "    \n",
    "    # Initialize a dictionary to hold fused scores for each unique document\n",
    "    fused_scores = {}\n",
    "\n",
    "    # Iterate through each list of ranked documents\n",
    "    for docs in results:\n",
    "        # Iterate through each document in the list, with its rank (position in the list)\n",
    "        for rank, doc in enumerate(docs):\n",
    "            # Convert the document to a string format to use as a key (assumes documents can be serialized to JSON)\n",
    "            doc_str = dumps(doc)\n",
    "            # If the document is not yet in the fused_scores dictionary, add it with an initial score of 0\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            # Retrieve the current score of the document, if any\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            # Update the score of the document using the RRF formula: 1 / (rank + k)\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "\n",
    "    # Sort the documents based on their fused scores in descending order to get the final reranked results\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "\n",
    "    # Return the reranked results as a list of tuples, each containing the document and its fused score\n",
    "    return reranked_results\n",
    "\n",
    "# Initialize Vector Store\n",
    "# vector_store = get_vector_store()\n",
    "\n",
    "retriever = get_retriever()\n",
    "\n",
    "# Retrieve\n",
    "question = \"What is Insertion Sort?\"\n",
    "retrieval_chain_rag_fusion  = generate_queries | retriever.map() | reciprocal_rank_fusion\n",
    "docs = retrieval_chain.invoke({\"question\":question})\n",
    "# print(docs)\n",
    "len(docs)\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\":question})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_chroma import Chroma\n",
    "from utils.custom_embeddings import MyEmbeddings\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from utils.chunk_doc import get_retriever, get_vector_store\n",
    "from prompt_templates.retrieval_check import get_rc_chain\n",
    "import streamlit as st\n",
    "from langchain_core.messages import HumanMessage\n",
    "from utils.image_processing import process_image, encode_image\n",
    "from prompt_templates.image_template import get_image_chain\n",
    "\n",
    "embedding_func = MyEmbeddings()\n",
    "\n",
    "def read_image_bytes(image_path):\n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        return image_file.read()\n",
    "\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    # api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    api_key=st.secrets[\"OpenAI_key\"],\n",
    "    temperature=0\n",
    ")\n",
    "import base64\n",
    "\n",
    "\n",
    "img = read_image_bytes('46bfac9.png')\n",
    "\n",
    "\n",
    "image_data = base64.b64encode(img).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "\n",
    "image_chain = get_image_chain(llm)\n",
    "\n",
    "message_content = [\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"}\n",
    "                    }\n",
    "                ]\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"\"),\n",
    "        (\n",
    "            \"human\",\n",
    "            [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Describe the image provided\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": \"data:image/jpeg;base64,{image_data}\"},\n",
    "                }\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({\"image_data\": image_data})\n",
    "print(response.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve\n",
    "question = \"Okay thank you so much thats all?\"\n",
    "retrieval_chain  = get_rc_chain(llm)\n",
    "response = retrieval_chain.invoke({\"input\":question})\n",
    "print(response)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from db.db_connection import ChatDatabase\n",
    "\n",
    "db = ChatDatabase('chat.db')\n",
    "\n",
    "print(db.load_chat_history(chat_id=\"6fcf537a-8e1e-496b-be68-84841722fa57_1\",user_id=\"6fcf537a-8e1e-496b-be68-84841722fa57\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit User Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.save_user_data(\"6fcf537a-8e1e-496b-be68-84841722fa57\",\"\",\"elroy7602@gmail.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "users = db.get_all_users()\n",
    "\n",
    "for user in users:\n",
    "    print(user['user_id'],\" \",db.get_user_level(user['user_id']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Specific User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.delete_user(\"5b2429f2-7dde-4469-8b88-75910f2e5a5b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_level = \"intermediate\"\n",
    "levels = (\"Beginner\", \"Intermediate\", \"Advanced\")\n",
    "print(levels.index(user_level.capitalize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_level_tool(user_id: str) -> str:\n",
    "    \"\"\"Get user level for given user_id\"\"\"\n",
    "    try:\n",
    "        user_level = db.get_user_level(user_id)\n",
    "        return f\"Current user level is {user_level}.\" if user_level else \"User not found.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving user level: {str(e)}\"\n",
    "    \n",
    "\n",
    "hello = get_user_level_tool(\"6fcf537a-8e1e-496b-be68-84841722fa57\")\n",
    "\n",
    "print(hello)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tools with Langchain LCEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_StJMon95i5N4wk1gyNP4oyOr', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': 'call_l9XGcLbfxcdPv4w09zg1hzNR', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_chroma import Chroma\n",
    "from utils.custom_embeddings import MyEmbeddings\n",
    "import streamlit as st\n",
    "from langchain_openai import ChatOpenAI\n",
    "from utils.chunk_doc import get_retriever, get_vector_store\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "        model_name=\"gpt-4o-mini\", \n",
    "        temperature=0, \n",
    "        streaming=True, \n",
    "        api_key=st.secrets[\"OpenAI_key\"]\n",
    "    )\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "tools = [add, multiply]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "\n",
    "print(ai_msg.tool_calls)\n",
    "\n",
    "messages.append(ai_msg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 3 * 12? Also, what is 11 + 49?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_StJMon95i5N4wk1gyNP4oyOr', 'function': {'arguments': '{\"a\": 3, \"b\": 12}', 'name': 'multiply'}, 'type': 'function'}, {'index': 1, 'id': 'call_l9XGcLbfxcdPv4w09zg1hzNR', 'function': {'arguments': '{\"a\": 11, \"b\": 49}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c'}, id='run-6f538260-5986-4429-af39-b01af767677a-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_StJMon95i5N4wk1gyNP4oyOr', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': 'call_l9XGcLbfxcdPv4w09zg1hzNR', 'type': 'tool_call'}]),\n",
       " ToolMessage(content='36', name='multiply', tool_call_id='call_StJMon95i5N4wk1gyNP4oyOr'),\n",
       " ToolMessage(content='60', name='add', tool_call_id='call_l9XGcLbfxcdPv4w09zg1hzNR')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The result of \\\\(3 \\\\times 12\\\\) is 36, and the result of \\\\(11 + 49\\\\) is 60.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63'}, id='run-9c6964b2-9be9-4755-bc21-d71b95e0d175-0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current Retrieval Tool for Langgraph [Important]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing retriever...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from utils.chunk_doc import get_retriever\n",
    "import os\n",
    "import streamlit as st\n",
    "from langchain import hub\n",
    "from typing import Annotated, Literal, Sequence, Any, Dict\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate, ChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from model import llm_selected\n",
    "\n",
    "# TODO\n",
    "# LLM still unsure how to respond to Thank you, Goodbye, etc. Hi, still okay i guess\n",
    "# Keep testing!\n",
    "# Change clarification method\n",
    "\n",
    "# Initialize the retriever\n",
    "print(\"Initializing retriever...\")\n",
    "retriever = get_retriever()\n",
    "\n",
    "# Create the retriever tool\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retrieve_documents\",\n",
    "    \"\"\"Search and return relevant documents based on user's query.\"\"\"\n",
    ")\n",
    "\n",
    "# Add the retriever tool to the list of tools\n",
    "tools = [retriever_tool]\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    user_level: str\n",
    "\n",
    "def validate_dsa_question(state) -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Validates input to either handle DSA questions or engage in friendly conversation,\n",
    "    while redirecting other technical questions.\n",
    "    \n",
    "    Args:\n",
    "        state: Current state containing messages and user_level\n",
    "        \n",
    "    Returns:\n",
    "        dict[str, Any]: Dictionary containing:\n",
    "            - messages: List of conversation messages\n",
    "            - user_level: User's current level\n",
    "            - next: Literal[\"proceed\", \"redirect\"] indicating next action\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[-1].content\n",
    "    user_level = state[\"user_level\"]\n",
    "    \n",
    "    class ValidationResult(BaseModel):\n",
    "        message_type: str = Field(\n",
    "            description=\"Type of message: 'dsa', 'pleasantry', or 'other'\",\n",
    "        )\n",
    "        response: str = Field(\n",
    "        description=\"Customized response for pleasantries or redirects\",\n",
    "        default=\"\"  # Provide dynamic responses instead of a static default\n",
    "        )\n",
    "\n",
    "    # Get context from previous messages if they exist\n",
    "    context_messages = messages[-6:-1] if len(messages) > 6 else messages[:-1]\n",
    "    conversation_context = \"\\n\".join([\n",
    "        f\"{'User: ' if isinstance(m, HumanMessage) else 'Assistant: '}{m.content}\"\n",
    "        for m in context_messages\n",
    "    ])\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"Analyze the input as a friendly DSA tutor:\n",
    "\n",
    "Previous conversation:\n",
    "{context}\n",
    "\n",
    "Current input: {question}\n",
    "\n",
    "Classify the input into one of three categories:\n",
    "\n",
    "1. 'dsa' - Questions directly about:\n",
    "   - Data Structures (arrays, linked lists, trees, graphs, etc.)\n",
    "   - Algorithms (sorting, searching, traversal, etc.)\n",
    "   - Algorithm analysis (complexity, Big O notation)\n",
    "   - DSA implementation\n",
    "   - DSA problem-solving\n",
    "\n",
    "2. 'pleasantry' - Friendly conversation:\n",
    "   - Greetings (hi, hello, hey)\n",
    "   - Thanks/gratitude\n",
    "   - Goodbyes\n",
    "   - Emotional responses (\"that makes sense\", \"I'm confused\")\n",
    "   - Small encouragements (\"got it\", \"okay I understand\")\n",
    "   \n",
    "3. 'other' - Non-DSA technical content:\n",
    "   - General programming\n",
    "   - Math questions\n",
    "   - Other CS topics\n",
    "   - Non-technical questions\n",
    "\n",
    "For pleasantries: Respond naturally like a friendly tutor\n",
    "For other: Redirect to DSA while being encouraging\n",
    "\n",
    "Return:\n",
    "1. message_type: 'dsa', 'pleasantry', or 'other'\n",
    "2. response: Natural response for pleasantries or friendly redirect for other\"\"\",\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        model = ChatOpenAI(\n",
    "            model_name=\"gpt-4o-mini\", \n",
    "            temperature=0.4,  # Slightly higher temperature for more natural responses\n",
    "            streaming=True, \n",
    "            api_key=st.secrets[\"OpenAI_key\"]\n",
    "        )\n",
    "        chain = prompt | model.with_structured_output(ValidationResult)\n",
    "        result = chain.invoke({\n",
    "            \"context\": conversation_context,\n",
    "            \"question\": question\n",
    "        })\n",
    "        \n",
    "        # Add refined responses for pleasantries or \"other\"\n",
    "        if result.message_type == \"pleasantry\":\n",
    "            if \"thanks\" in question.lower():\n",
    "                result.response = \"You're very welcome! Let me know if there's anything else you'd like to explore about DSA.\"\n",
    "            elif any(greet in question.lower() for greet in [\"hi\", \"hello\", \"hey\"]):\n",
    "                result.response = \"Hi there! I'm here to help with any questions about data structures and algorithms. What would you like to learn about today?\"\n",
    "            elif any(farewell in question.lower() for farewell in [\"bye\", \"goodbye\"]):\n",
    "                result.response = \"Take care! Feel free to reach out whenever you're ready to dive into DSA again!\"\n",
    "\n",
    "        elif result.message_type == \"other\":\n",
    "            result.response = (\"That's an interesting topic, but my expertise is in data structures and algorithms. \"\n",
    "                               \"I'd be happy to help you explore concepts like trees, graphs, or sorting algorithms. \"\n",
    "                               \"Let me know what you'd like to dive into!\")\n",
    "        \n",
    "        # Determine the next step\n",
    "        if result.message_type == \"dsa\":\n",
    "            return {\n",
    "                \"messages\": messages,\n",
    "                \"user_level\": user_level,\n",
    "                \"next\": \"proceed\"\n",
    "            }\n",
    "        else:  # pleasantry or other\n",
    "            return {\n",
    "                \"messages\": [*messages, AIMessage(content=result.response)],\n",
    "                \"user_level\": user_level,\n",
    "                \"next\": \"redirect\"\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Validation error: {str(e)}\")\n",
    "        # On error, proceed with original message\n",
    "        return {\n",
    "            \"messages\": messages,\n",
    "            \"user_level\": user_level,\n",
    "            \"next\": \"proceed\"\n",
    "        }\n",
    "\n",
    "def clarify_question(state):\n",
    "    \"\"\"\n",
    "    Clarifies ambiguous questions by maintaining conversation context,\n",
    "    with improved handling of pronoun references to DSA concepts.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== DEBUG: CLARIFY NODE ===\")\n",
    "    messages = state[\"messages\"]\n",
    "    current_question = messages[-1].content\n",
    "    print(f\"Original question: {current_question}\")\n",
    "    \n",
    "    # Get the last 3 exchanges (up to 6 messages) for relevant context\n",
    "    context_messages = messages[-6:-1] if len(messages) > 6 else messages[:-1]\n",
    "    conversation_context = \"\\n\".join([\n",
    "        f\"{'User: ' if isinstance(m, HumanMessage) else 'Assistant: '}{m.content}\"\n",
    "        for m in context_messages\n",
    "    ])\n",
    "    \n",
    "    class ClarificationResult(BaseModel):\n",
    "        clarified_question: str = Field(\n",
    "            description=\"The clarified version of the question with pronouns replaced by their referents\",\n",
    "            default=\"\"  # Provide empty string as default\n",
    "        )\n",
    "        referenced_concept: str = Field(\n",
    "            description=\"The main DSA concept being referenced from previous context\",\n",
    "            default=\"\"  # Provide empty string as default\n",
    "        )\n",
    "    \n",
    "    model = ChatOpenAI(\n",
    "        model_name=\"gpt-4o-mini\", \n",
    "        temperature=0, \n",
    "        streaming=True, \n",
    "        api_key=st.secrets[\"OpenAI_key\"]\n",
    "    )\n",
    "    llm_with_clarification = model.with_structured_output(ClarificationResult)\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "You are a DSA question processor. Transform user's prompt into clear, context-aware queries.\n",
    "\n",
    "OBJECTIVE: Rewrite user's prompt to include relevant context from chat history while maintaining original intent.\n",
    "\n",
    "Previous conversation:\n",
    "{context}\n",
    "\n",
    "Current question: {question}\n",
    "\n",
    "TRANSFORMATION RULES:\n",
    "1. Replace pronouns with specific references\n",
    "   Before: \"How do I implement it?\"\n",
    "   After: \"How do I implement a binary search tree?\"\n",
    "\n",
    "2. Include relevant context\n",
    "   Before: \"What about the time complexity?\"\n",
    "   After: \"What is the time complexity of quicksort's partitioning step?\"\n",
    "\n",
    "3. Maintain technical precision\n",
    "   Before: \"How does the fast one work?\"\n",
    "   After: \"How does the O(n log n) merge sort algorithm work?\"\n",
    "\n",
    "4. Keep original meaning\n",
    "   Do NOT add assumptions or change the question's scope\n",
    "\n",
    "Return ONLY the reformulated question without explanation.\n",
    "\n",
    "\"\"\",\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm_with_clarification\n",
    "    \n",
    "    try:\n",
    "        result = chain.invoke({\n",
    "            \"context\": conversation_context,\n",
    "            \"question\": current_question\n",
    "        })\n",
    "        \n",
    "        # For non-DSA questions or greetings, use original question\n",
    "        if not result.needs_clarification:\n",
    "            print(\"No clarification needed - using original question\")\n",
    "            return {\"messages\": messages, \"user_level\": state[\"user_level\"]}\n",
    "            \n",
    "        # For questions needing clarification, verify we have the clarified version\n",
    "        if result.needs_clarification and result.clarified_question:\n",
    "            print(f\"Referenced concept: {result.referenced_concept}\")\n",
    "            print(f\"Clarified to: {result.clarified_question}\")\n",
    "            return {\"messages\": [HumanMessage(content=result.clarified_question)], \"user_level\": state[\"user_level\"]}\n",
    "        else:\n",
    "            print(\"No clarification needed\")\n",
    "            return {\"messages\": messages, \"user_level\": state[\"user_level\"]}\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in clarification: {str(e)}\")\n",
    "        # On error, proceed with original question\n",
    "        return {\"messages\": messages, \"user_level\": state[\"user_level\"]}\n",
    "\n",
    "\n",
    "# def agent(state):\n",
    "#     \"\"\"\n",
    "#     Enhanced agent function with correct retrieval method\n",
    "#     \"\"\"\n",
    "#     print(\"\\n=== DEBUG: AGENT NODE ===\")\n",
    "#     messages = state[\"messages\"]\n",
    "#     question = messages[-1].content\n",
    "#     print(f\"Question received by agent: {question}\")\n",
    "    \n",
    "#     try:\n",
    "#         # Create system message to enforce proper tool usage and response format\n",
    "#         system_message = \"\"\"You are a DSA expert assistant. Follow these steps for EVERY question:\n",
    "#         1. ALWAYS use the retrieve_documents tool first to get information\n",
    "#         2. Wait for the tool's response\n",
    "#         3. Synthesize the retrieved information into a clear explanation\n",
    "#         4. If the retrieved information is insufficient, clearly state that and provide a general explanation\n",
    "        \n",
    "#         IMPORTANT: \n",
    "#         - Always complete the full retrieval and response process\n",
    "#         - Never return just a message about needing to retrieve information\n",
    "#         - Provide complete, informative responses\n",
    "#         \"\"\"\n",
    "        \n",
    "#         # Prepare messages with system instruction\n",
    "#         full_messages = [\n",
    "#             HumanMessage(content=system_message),\n",
    "#             *messages\n",
    "#         ]\n",
    "        \n",
    "#         # Initialize model with tools and strict temperature\n",
    "#         model = ChatOpenAI(\n",
    "#             model_name=\"gpt-4o-mini\", \n",
    "#             temperature=0, \n",
    "#             streaming=True, \n",
    "#             api_key=st.secrets[\"OpenAI_key\"]\n",
    "#         )\n",
    "#         model_with_tools = model.bind_tools(tools)\n",
    "        \n",
    "#         # Create a specific prompt to force tool usage\n",
    "#         tool_prompt = HumanMessage(content=f\"\"\"Please provide information about: {question}\n",
    "#         Remember to:\n",
    "#         1. Use the retrieve_documents tool first\n",
    "#         2. Process the retrieved information\n",
    "#         3. Provide a complete response\"\"\")\n",
    "        \n",
    "#         # Get response with explicit tool usage\n",
    "#         response = model_with_tools.invoke([*full_messages, tool_prompt])\n",
    "        \n",
    "#         # Validate response\n",
    "#         if not response.content.strip() or \"need to retrieve\" in response.content.lower():\n",
    "#             print(\"Warning: Invalid response detected, forcing retrieval\")\n",
    "#             # Force direct retrieval as fallback\n",
    "#             docs = retriever.invoke(question)\n",
    "#             if docs:\n",
    "#                 # Process the retrieved documents\n",
    "#                 context = \"\\n\".join(doc.page_content for doc in docs)\n",
    "                \n",
    "#                 # Generate response with retrieved context\n",
    "#                 prompt = PromptTemplate(\n",
    "#                     template=\"\"\"Based on the following information, provide a complete explanation about {question}.\n",
    "                    \n",
    "#                     Retrieved information:\n",
    "#                     {context}\n",
    "                    \n",
    "#                     If the retrieved information is insufficient, provide a general explanation based on your knowledge\n",
    "#                     but clearly state that you're doing so.\n",
    "#                     \"\"\",\n",
    "#                     input_variables=[\"question\", \"context\"]\n",
    "#                 )\n",
    "                \n",
    "#                 chain = prompt | model | StrOutputParser()\n",
    "#                 response_content = chain.invoke({\n",
    "#                     \"question\": question,\n",
    "#                     \"context\": context\n",
    "#                 })\n",
    "#             else:\n",
    "#                 response_content = \"I apologize, but I couldn't find specific information about that. Let me provide a general explanation based on my knowledge.\"\n",
    "#         else:\n",
    "#             response_content = response.content\n",
    "            \n",
    "#         print(f\"Final response length: {len(response_content)}\")\n",
    "#         return {\"messages\": [AIMessage(content=response_content)], \"user_level\": state[\"user_level\"]}\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error in agent: {str(e)}\")\n",
    "#         # Fallback to direct explanation\n",
    "#         try:\n",
    "#             print(\"Attempting fallback retrieval...\")\n",
    "#             docs = retriever.invoke(question)\n",
    "#             if docs:\n",
    "#                 context = \"\\n\".join(doc.page_content for doc in docs)\n",
    "#                 return {\n",
    "#                     \"messages\": [AIMessage(content=f\"Here's what I found about {question}: {context}\")],\n",
    "#                     \"user_level\": state[\"user_level\"]\n",
    "#                 }\n",
    "#             else:\n",
    "#                 return {\n",
    "#                     \"messages\": [AIMessage(content=f\"I apologize, but I encountered an issue retrieving specific information about {question}. Please try rephrasing your question.\")],\n",
    "#                     \"user_level\": state[\"user_level\"]\n",
    "#                 }\n",
    "#         except Exception as e2:\n",
    "#             print(f\"Fallback retrieval failed: {str(e2)}\")\n",
    "#             return {\n",
    "#                 \"messages\": [AIMessage(content=\"I encountered an error processing your question. Please try asking in a different way.\")],\n",
    "#                 \"user_level\": state[\"user_level\"]\n",
    "#             }\n",
    "\n",
    "# def rewrite(state):\n",
    "#     \"\"\"Debug version of rewrite with validation\"\"\"\n",
    "#     print(\"\\n=== DEBUG: REWRITE NODE ===\")\n",
    "#     messages = state[\"messages\"]\n",
    "#     question = messages[-1].content\n",
    "#     print(f\"Rewriting question: {question}\")\n",
    "\n",
    "#     try:\n",
    "#         msg = [\n",
    "#             HumanMessage(\n",
    "#                 content=\"\"\"Improve this question to be more specific and searchable:\n",
    "#                 Question: {question}\n",
    "#                 Make it clearly about DSA concepts.\"\"\".format(question=question)\n",
    "#             )\n",
    "#         ]\n",
    "\n",
    "#         model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0, streaming=True, api_key=st.secrets[\"OpenAI_key\"])\n",
    "#         response = model.invoke(msg)\n",
    "#         print(f\"Rewritten as: {response.content}\")\n",
    "#         return {\"messages\": [AIMessage(content=response.content)], \"user_level\": state[\"user_level\"]}\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error in rewrite: {str(e)}\")\n",
    "#         return {\"messages\": [HumanMessage(content=question)], \"user_level\": state[\"user_level\"]}\n",
    "\n",
    "# def grade_documents(state) -> Literal[\"generate\", \"rewrite\"]:\n",
    "#     \"\"\"Debug version of grading with content validation\"\"\"\n",
    "#     print(\"\\n=== DEBUG: GRADE DOCUMENTS ===\")\n",
    "    \n",
    "#     messages = state[\"messages\"]\n",
    "#     last_message = messages[-1]\n",
    "#     question = messages[0].content\n",
    "#     docs = last_message.content\n",
    "    \n",
    "#     print(f\"Grading question: {question}\")\n",
    "#     print(f\"Documents content length: {len(docs) if docs else 'None'}\")\n",
    "    \n",
    "#     # Basic content validation\n",
    "#     if not docs or len(docs.strip()) < 10:\n",
    "#         print(\"---NO VALID DOCS TO GRADE---\")\n",
    "#         return \"rewrite\"\n",
    "        \n",
    "#     try:\n",
    "#         class grade(BaseModel):\n",
    "#             binary_score: str = Field(description=\"Relevance score 'yes' or 'no'\")\n",
    "            \n",
    "#         model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0, streaming=True, api_key=st.secrets[\"OpenAI_key\"])\n",
    "#         llm_with_tool = model.with_structured_output(grade)\n",
    "        \n",
    "#         prompt = PromptTemplate(\n",
    "#             template=\"\"\"Grade if this content is relevant to the question.\n",
    "#             Question: {question}\n",
    "#             Content: {context}\n",
    "#             Give 'yes' if there's ANY relevant information about the topic.\"\"\",\n",
    "#             input_variables=[\"context\", \"question\"],\n",
    "#         )\n",
    "        \n",
    "#         chain = prompt | llm_with_tool\n",
    "#         result = chain.invoke({\"question\": question, \"context\": docs})\n",
    "#         print(f\"Grade result: {result.binary_score}\")\n",
    "        \n",
    "#         return \"generate\" if result.binary_score.lower() == \"yes\" else \"rewrite\"\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error in grading: {str(e)}\")\n",
    "#         return \"generate\" if docs else \"rewrite\"\n",
    "\n",
    "\n",
    "################################################################################################################\n",
    "# def agent(state):\n",
    "#     \"\"\"\n",
    "#     Invokes the agent model to generate a response based on the current state. Given\n",
    "#     the question, it will decide to retrieve using the retriever tool, or simply end.\n",
    "\n",
    "#     Args:\n",
    "#         state (messages): The current state\n",
    "\n",
    "#     Returns:\n",
    "#         dict: The updated state with the agent response appended to messages\n",
    "#     \"\"\"\n",
    "#     print(\"---CALL AGENT---\")\n",
    "    \n",
    "#     # Prompt\n",
    "#     prompt = ChatMessagePromptTemplate\n",
    "    \n",
    "#     messages = state[\"messages\"]\n",
    "#     model = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", streaming=True,api_key=st.secrets[\"OpenAI_key\"])\n",
    "#     model = model.bind_tools(tools)\n",
    "#     response = model.invoke(messages)\n",
    "#     # We return a list, because this will get added to the existing list\n",
    "#     return {\"messages\": [response]}\n",
    "def agent(state):\n",
    "    \"\"\"\n",
    "    Invokes the agent model to generate a response based on confidence level.\n",
    "    \n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with the agent response appended to messages\n",
    "    \"\"\"\n",
    "    print(\"---CALL AGENT---\")\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # System message that enforces confidence-based retrieval\n",
    "    system_message = \"\"\"You are a DSA expert assistant. For every question:\n",
    "\n",
    "1. First, assess your confidence in providing a complete, accurate answer:\n",
    "   - Consider if you need specific implementation details\n",
    "   - Consider if you need exact complexity analysis\n",
    "   - Consider if you need specific examples or edge cases\n",
    "\n",
    "2. If your confidence is less than 90%%:\n",
    "   - ALWAYS use the retrieve_documents tool\n",
    "   - Base your answer on the retrieved information\n",
    "   - Acknowledge when using retrieved information\n",
    "\n",
    "3. If your confidence is 90%% or higher:\n",
    "   - You may answer directly from your knowledge\n",
    "   - Still use the tool if additional detail would be helpful\n",
    "   - Mention that you're confident in your direct answer\n",
    "\n",
    "4. Always be explicit about tool usage:\n",
    "   - \"Let me check our reference materials for specific details...\"\n",
    "   - \"I'm very confident about this, but let me verify some details...\"\n",
    "   - \"This requires checking our documentation for precise information...\"\n",
    "\n",
    "Remember: It's better to verify with the tool than risk providing incomplete or inaccurate information.\"\"\"\n",
    "\n",
    "    # Prepare messages with system instruction\n",
    "    full_messages = [\n",
    "        HumanMessage(content=system_message),\n",
    "        *messages\n",
    "    ]\n",
    "    \n",
    "    # Initialize model with tools\n",
    "    model = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", streaming=True, api_key=st.secrets[\"OpenAI_key\"])\n",
    "    model = model.bind_tools(tools)\n",
    "    \n",
    "    # Get response\n",
    "    response = model.invoke(full_messages)\n",
    "    \n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def grade_documents(state) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    \"\"\"\n",
    "    Enhanced grading system for retrieved DSA documents.\n",
    "    \n",
    "    Evaluates:\n",
    "    1. Relevance to the question\n",
    "    2. Completeness of the answer\n",
    "    3. Technical accuracy\n",
    "    4. Need for clarification\n",
    "    \n",
    "    Returns:\n",
    "    - \"generate\": When documents are good enough to generate response\n",
    "    - \"rewrite\": When documents aren't relevant enough\n",
    "    - \"clarify\": When question needs clarification\n",
    "    \"\"\"\n",
    "    print(\"---ENHANCED GRADING SYSTEM---\")\n",
    "    \n",
    "    class GradeResult(BaseModel):\n",
    "        relevance_score: float = Field(description=\"0-1 score for topic relevance\")\n",
    "        completeness_score: float = Field(description=\"0-1 score for answer completeness\")\n",
    "        technical_accuracy: float = Field(description=\"0-1 score for technical accuracy\")\n",
    "        reasoning: str = Field(description=\"Explanation for the grading decision\")\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    retrieved_docs = messages[-1].content\n",
    "\n",
    "    # Define the grading prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a DSA expert grading retrieved content.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Retrieved Content:\n",
    "{content}\n",
    "\n",
    "Grade this content on:\n",
    "1. Relevance: Does it directly address the DSA concepts in the question?\n",
    "2. Completeness: Does it cover all aspects needed for a good answer?\n",
    "3. Technical Accuracy: Is the DSA information correct and precise?\n",
    "4. Clarity: Is the question clear or needs clarification?\n",
    "\n",
    "Example DSA concepts to check for:\n",
    "- Data structure definitions and properties\n",
    "- Algorithm steps and processes\n",
    "- Time/space complexity mentions\n",
    "- Implementation details\n",
    "- Common use cases and examples\n",
    "\n",
    "Return scores as decimals between 0 and 1, where:\n",
    "- 0.0-0.3: Poor\n",
    "- 0.4-0.6: Moderate\n",
    "- 0.7-1.0: Good\n",
    "\n",
    "Also explain your reasoning.\"\"\",\n",
    "        input_variables=[\"question\", \"content\"]\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Initialize model with lower temperature for consistent grading\n",
    "        model = ChatOpenAI(\n",
    "            model_name=\"gpt-4o-mini\",\n",
    "            temperature=0,\n",
    "            streaming=True,\n",
    "            api_key=st.secrets[\"OpenAI_key\"]\n",
    "        )\n",
    "        \n",
    "        # Grade with structured output\n",
    "        chain = prompt | model.with_structured_output(GradeResult)\n",
    "        result = chain.invoke({\n",
    "            \"question\": question,\n",
    "            \"content\": retrieved_docs\n",
    "        })\n",
    "        \n",
    "        print(f\"Grading Results:\\n\"\n",
    "              f\"Relevance: {result.relevance_score:.2f}\\n\"\n",
    "              f\"Completeness: {result.completeness_score:.2f}\\n\"\n",
    "              f\"Technical Accuracy: {result.technical_accuracy:.2f}\\n\")\n",
    "            \n",
    "        # Calculate weighted average score\n",
    "        weighted_score = (\n",
    "            result.relevance_score * 0.4 +      # Relevance is most important\n",
    "            result.completeness_score * 0.3 +    # Completeness next\n",
    "            result.technical_accuracy * 0.3      # Technical accuracy equally important\n",
    "        )\n",
    "        \n",
    "        # Decision thresholds\n",
    "        GOOD_THRESHOLD = 0.65\n",
    "        \n",
    "        if weighted_score >= GOOD_THRESHOLD:\n",
    "            print(\"---DECISION: CONTENT GOOD ENOUGH TO GENERATE---\")\n",
    "            return \"generate\"\n",
    "        else:\n",
    "            print(\"---DECISION: NEED TO REWRITE QUERY---\")\n",
    "            return \"rewrite\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Grading error: {str(e)}\")\n",
    "        # On error, default to rewrite for safety\n",
    "        return \"rewrite\"\n",
    "    \n",
    "def rewrite(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "\n",
    "    msg = [\n",
    "        HumanMessage(\n",
    "            content=f\"\"\" \\n \n",
    "    Look at the input and try to reason about the underlying semantic intent / meaning. \\n \n",
    "    Here is the initial question:\n",
    "    \\n ------- \\n\n",
    "    {question} \n",
    "    \\n ------- \\n\n",
    "    Formulate an improved question: \"\"\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Grader\n",
    "    model = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", streaming=True,api_key=st.secrets[\"OpenAI_key\"])\n",
    "    response = model.invoke(msg)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"Generate response based on retrieved content and question\"\"\"\n",
    "    print(\"\\n=== DEBUG: GENERATE NODE ===\")\n",
    "    messages = state[\"messages\"]\n",
    "    print(\"Messages: \", state[\"messages\"])\n",
    "    \n",
    "    # Find the last actual question by looking for the last HumanMessage\n",
    "    # that triggered the retrieval flow\n",
    "    question = None\n",
    "    \n",
    "    for msg in messages:\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            question = msg.content\n",
    "            \n",
    "    if not question:\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=\"I couldn't properly process your question. Could you please rephrase it?\")],\n",
    "            \"user_level\": state[\"user_level\"]\n",
    "        }\n",
    "        \n",
    "    user_level = state[\"user_level\"]\n",
    "    docs = messages[-1].content  # Retrieved content is always last\n",
    "    \n",
    "    print(f\"Generate received question: {question}\")\n",
    "    print(f\"User level: {user_level}\")\n",
    "    # print(f\"Docs length: {len(docs) if docs else 'None'}\")\n",
    "    \n",
    "    if not docs or len(docs.strip()) < 10:\n",
    "        print(\"---NO CONTENT TO GENERATE FROM---\")\n",
    "        return {\"messages\": [AIMessage(content=\"I apologize, but I couldn't find relevant information to answer your question. Please try rephrasing it.\")], \"user_level\": state[\"user_level\"]}\n",
    "        \n",
    "    try:\n",
    "        llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0, streaming=True, api_key=st.secrets[\"OpenAI_key\"])\n",
    "        \n",
    "        # prompt = PromptTemplate(\n",
    "        #     template=\"\"\"Answer based on the following context. If context is insufficient, say so clearly.\n",
    "        #     Question: {question}\n",
    "        #     User Level: {user_level}\n",
    "        #     Context: {context}\n",
    "            \n",
    "        #     If you don't find specific information about the topic, you can provide a general explanation based on your knowledge, but clearly state that you're doing so.\"\"\",\n",
    "        #     input_variables=[\"context\", \"question\", \"user_level\"],\n",
    "        # )\n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=['context', 'question','user_level'], \n",
    "            input_types={}, \n",
    "            partial_variables={}, \n",
    "            template=\"\"\"You are a DSA expert tutor. Adapt your teaching style to the user's level while maintaining technical accuracy.\n",
    "\n",
    "Current User Level: {user_level}\n",
    "\n",
    "• BEGINNER LEVEL APPROACH:\n",
    "  • Use simple analogies and metaphors\n",
    "    • Compare arrays to parking lots\n",
    "    • Explain stacks like plates in a cafeteria\n",
    "    • Describe trees as family trees\n",
    "  • Focus on basic understanding\n",
    "    • Avoid complexity discussions\n",
    "    • Use step-by-step explanations\n",
    "    • Provide visual examples when possible\n",
    "  • Keep language simple\n",
    "    • Minimize technical jargon\n",
    "    • Use everyday examples\n",
    "    • Explain concepts interactively\n",
    "\n",
    "• INTERMEDIATE LEVEL APPROACH:\n",
    "  • Technical content focus\n",
    "    • Include basic time/space complexity\n",
    "    • Show implementation details\n",
    "    • Provide code examples\n",
    "  • Teaching methods\n",
    "    • Compare different approaches\n",
    "    • Explain basic trade-offs\n",
    "    • Connect related concepts\n",
    "  • Code implementation\n",
    "    • Show practical examples\n",
    "    • Discuss common patterns\n",
    "    • Address basic optimizations\n",
    "\n",
    "• ADVANCED LEVEL APPROACH:\n",
    "  • Technical depth\n",
    "    • Deep optimization discussions\n",
    "    • Thorough edge case analysis\n",
    "    • Performance considerations\n",
    "  • System considerations\n",
    "    • Memory/cache implications\n",
    "    • Concurrency aspects\n",
    "    • Scalability factors\n",
    "  • Implementation focus\n",
    "    • Advanced optimization techniques\n",
    "    • System design impacts\n",
    "    • Complex trade-offs\n",
    "\n",
    "• UNIVERSAL RULES:\n",
    "  • Stay within DSA scope\n",
    "    • Redirect non-DSA questions politely\n",
    "    • Focus on one concept at a time\n",
    "    • Offer to explore related topics after\n",
    "  • Use context appropriately\n",
    "    • Start with provided context: \"{context}\"\n",
    "    • Clearly indicate when using general knowledge\n",
    "    • Stay within user's competency level\n",
    "  • Maintain level-appropriate depth\n",
    "    • Match technical depth to user level\n",
    "    • Scale example complexity appropriately\n",
    "    • Use suitable terminology\n",
    "\n",
    "Question: {question}\"\"\")\n",
    "        # prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "        \n",
    "        chain = prompt | llm | StrOutputParser()\n",
    "        response = chain.invoke({\n",
    "            \"context\": docs,\n",
    "            \"question\": question,\n",
    "            \"user_level\": user_level\n",
    "        })\n",
    "        \n",
    "        print(f\"Generated response length: {len(response)}\")\n",
    "        return {\"messages\": [AIMessage(content=response)], \"user_level\": state[\"user_level\"]}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in generate: {str(e)}\")\n",
    "        return {\"messages\": [AIMessage(content=\"I encountered an error generating a response. Please try asking your question again.\")], \"user_level\": state[\"user_level\"]}\n",
    "\n",
    "################################################################################################################\n",
    "# Graph setup\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"validate_topic\", validate_dsa_question)\n",
    "workflow.add_node(\"clarify\", clarify_question)\n",
    "workflow.add_node(\"agent\", agent)\n",
    "retrieve = ToolNode([retriever_tool])\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "workflow.add_node(\"rewrite\", rewrite)\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(START, \"validate_topic\")\n",
    "\n",
    "# Modify validation to return three possible outcomes\n",
    "workflow.add_conditional_edges(\n",
    "    \"validate_topic\",\n",
    "    lambda x: x[\"next\"],\n",
    "    {\n",
    "        \"proceed\": \"agent\",\n",
    "        \"clarify\": \"clarify\",\n",
    "        \"redirect\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# After clarification, go to agent\n",
    "workflow.add_edge(\"clarify\", \"agent\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    tools_condition,\n",
    "    {\n",
    "        \"tools\": \"retrieve\",\n",
    "        END: END,\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    grade_documents,\n",
    "    {\n",
    "        \"generate\": \"generate\",\n",
    "        \"rewrite\": \"rewrite\",\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"generate\", END)\n",
    "workflow.add_edge(\"rewrite\", \"agent\")\n",
    "\n",
    "# Compile graph\n",
    "from test_templates.memory import memory\n",
    "graph = workflow.compile()\n",
    "\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elroy\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing retriever...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from utils.chunk_doc import get_retriever\n",
    "import os\n",
    "import streamlit as st\n",
    "from langchain import hub\n",
    "from typing import Annotated, Literal, Sequence, Any, Dict\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate, ChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# TODO\n",
    "# LLM still unsure how to respond to Thank you, Goodbye, etc. Hi, still okay i guess\n",
    "# Keep testing!\n",
    "# Change clarification method\n",
    "\n",
    "# Initialize the retriever\n",
    "print(\"Initializing retriever...\")\n",
    "retriever = get_retriever()\n",
    "\n",
    "# Create the retriever tool\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retrieve_documents\",\n",
    "    \"\"\"Search and return relevant documents based on user's query.\"\"\"\n",
    ")\n",
    "\n",
    "# Add the retriever tool to the list of tools\n",
    "tools = [retriever_tool]\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    user_level: str\n",
    "\n",
    "def validate_dsa_question(state) -> dict[str, Any]:\n",
    "    \"\"\"Validates input to handle DSA questions, ensuring English-only interaction.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[-1].content\n",
    "    user_level = state[\"user_level\"]\n",
    "    \n",
    "    class ValidationResult(BaseModel):\n",
    "        message_type: str = Field(description=\"Type of message: 'dsa', 'pleasantry', 'non_english', or 'other'\")\n",
    "        response: str = Field(description=\"Response for non-DSA inputs\")\n",
    "\n",
    "    context_messages = messages[-6:-1] if len(messages) > 6 else messages[:-1]\n",
    "    conversation_context = \"\\n\".join([f\"{'User: ' if isinstance(m, HumanMessage) else 'Assistant: '}{m.content}\" for m in context_messages])\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"Analyze the input as a friendly DSA tutor:\n",
    "\n",
    "    Previous conversation:\n",
    "    {context}\n",
    "\n",
    "    Current input: {question}\n",
    "\n",
    "    Classify the input into:\n",
    "\n",
    "    1. 'dsa' - Questions directly about:\n",
    "    - Data Structures (arrays, linked lists, trees, graphs, etc.)\n",
    "    - Algorithms (sorting, searching, traversal, etc.)\n",
    "    - Algorithm analysis (complexity, Big O notation)\n",
    "    - DSA implementation\n",
    "    - DSA problem-solving\n",
    "    - Must be in English\n",
    "\n",
    "    2. 'pleasantry' - Friendly conversation:\n",
    "    - Greetings (hi, hello, hey)\n",
    "    - Thanks/gratitude\n",
    "    - Goodbyes\n",
    "    - Emotional responses (\"that makes sense\", \"I'm confused\")\n",
    "    - Small encouragements (\"got it\", \"okay I understand\")\n",
    "    \n",
    "    3. 'non_english' - Any non-English input:\n",
    "    - Questions in other languages\n",
    "    - Mixed language content\n",
    "    - Non-English characters/scripts\n",
    "    \n",
    "    4. 'other' - Non-DSA technical content:\n",
    "    - General programming\n",
    "    - Math questions\n",
    "    - Other CS topics\n",
    "    - Non-technical questions\n",
    "\n",
    "    For pleasantries: Respond naturally like a friendly tutor\n",
    "    For non_english: Respond with English-only policy reminder\n",
    "    For other: Redirect to DSA while being encouraging\n",
    "\n",
    "    Return:\n",
    "    1. message_type: 'dsa', 'pleasantry', 'non_english', or 'other'\n",
    "    2. response: Appropriate response for non-DSA inputs\"\"\",\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.5, streaming=True, api_key=st.secrets[\"OpenAI_key\"])\n",
    "        chain = prompt | model.with_structured_output(ValidationResult)\n",
    "        result = chain.invoke({\"context\": conversation_context, \"question\": question})\n",
    "        \n",
    "        if result.message_type == \"dsa\":\n",
    "            return {\"messages\": messages, \"user_level\": user_level, \"next\": \"proceed\"}\n",
    "        elif result.message_type == \"non_english\":\n",
    "            return {\n",
    "                \"messages\": [*messages, AIMessage(content=\"I can only communicate in English. Please rephrase your question in English.\")],\n",
    "                \"user_level\": user_level,\n",
    "                \"next\": \"redirect\"\n",
    "            }\n",
    "        else:\n",
    "            return {\"messages\": [*messages, AIMessage(content=result.response)], \"user_level\": user_level, \"next\": \"redirect\"}\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Validation error: {str(e)}\")\n",
    "        return {\"messages\": messages, \"user_level\": user_level, \"next\": \"proceed\"}\n",
    "\n",
    "def clarify_question(state):\n",
    "    \"\"\"\n",
    "    Clarifies ambiguous questions by maintaining conversation context,\n",
    "    with improved handling of pronoun references to DSA concepts.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== CLARIFY NODE ===\")\n",
    "    messages = state[\"messages\"]\n",
    "    current_question = messages[-1].content\n",
    "    print(f\"Original question: {current_question}\")\n",
    "    \n",
    "    # Get the last 3 exchanges (up to 6 messages) for relevant context\n",
    "    context_messages = messages[-6:-1] if len(messages) > 6 else messages[:-1]\n",
    "    conversation_context = \"\\n\".join([\n",
    "        f\"{'User: ' if isinstance(m, HumanMessage) else 'Assistant: '}{m.content}\"\n",
    "        for m in context_messages\n",
    "    ])\n",
    "    \n",
    "    class ClarificationResult(BaseModel):\n",
    "        clarified_question: str = Field(\n",
    "            description=\"The clarified version of the question with pronouns replaced by their referents\",\n",
    "            default=\"\"  # Provide empty string as default\n",
    "        )\n",
    "        referenced_concept: str = Field(\n",
    "            description=\"The main DSA concept being referenced from previous context\",\n",
    "            default=\"\"  # Provide empty string as default\n",
    "        )\n",
    "    \n",
    "    model = ChatOpenAI(\n",
    "        model_name=\"gpt-4o-mini\", \n",
    "        temperature=0, \n",
    "        streaming=True, \n",
    "        api_key=st.secrets[\"OpenAI_key\"]\n",
    "    )\n",
    "    llm_with_clarification = model.with_structured_output(ClarificationResult)\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "You are a DSA question processor. Transform user's prompt into clear, context-aware queries.\n",
    "\n",
    "OBJECTIVE: Rewrite user's prompt to include relevant context from chat history while maintaining original intent.\n",
    "\n",
    "Previous conversation:\n",
    "{context}\n",
    "\n",
    "Current question: {question}\n",
    "\n",
    "TRANSFORMATION RULES:\n",
    "1. Replace pronouns with specific references\n",
    "   Before: \"How do I implement it?\"\n",
    "   After: \"How do I implement a binary search tree?\"\n",
    "\n",
    "2. Include relevant context\n",
    "   Before: \"What about the time complexity?\"\n",
    "   After: \"What is the time complexity of quicksort's partitioning step?\"\n",
    "\n",
    "3. Maintain technical precision\n",
    "   Before: \"How does the fast one work?\"\n",
    "   After: \"How does the O(n log n) merge sort algorithm work?\"\n",
    "\n",
    "4. Keep original meaning\n",
    "   Do NOT add assumptions or change the question's scope\n",
    "\n",
    "Return ONLY the reformulated question without explanation.\n",
    "\n",
    "\"\"\",\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm_with_clarification\n",
    "    \n",
    "    try:\n",
    "        result = chain.invoke({\n",
    "            \"context\": conversation_context,\n",
    "            \"question\": current_question\n",
    "        })\n",
    "        \n",
    "        # For non-DSA questions or greetings, use original question\n",
    "        if not result.needs_clarification:\n",
    "            print(\"No clarification needed - using original question\")\n",
    "            return {\"messages\": messages, \"user_level\": state[\"user_level\"]}\n",
    "            \n",
    "        # For questions needing clarification, verify we have the clarified version\n",
    "        if result.needs_clarification and result.clarified_question:\n",
    "            print(f\"Referenced concept: {result.referenced_concept}\")\n",
    "            print(f\"Clarified to: {result.clarified_question}\")\n",
    "            return {\"messages\": [HumanMessage(content=result.clarified_question)], \"user_level\": state[\"user_level\"]}\n",
    "        else:\n",
    "            print(\"No clarification needed\")\n",
    "            return {\"messages\": messages, \"user_level\": state[\"user_level\"]}\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in clarification: {str(e)}\")\n",
    "        # On error, proceed with original question\n",
    "        return {\"messages\": messages, \"user_level\": state[\"user_level\"]}\n",
    "\n",
    "\n",
    "# def agent(state):\n",
    "#     \"\"\"\n",
    "#     Enhanced agent function with correct retrieval method\n",
    "#     \"\"\"\n",
    "#     print(\"\\n=== DEBUG: AGENT NODE ===\")\n",
    "#     messages = state[\"messages\"]\n",
    "#     question = messages[-1].content\n",
    "#     print(f\"Question received by agent: {question}\")\n",
    "    \n",
    "#     try:\n",
    "#         # Create system message to enforce proper tool usage and response format\n",
    "#         system_message = \"\"\"You are a DSA expert assistant. Follow these steps for EVERY question:\n",
    "#         1. ALWAYS use the retrieve_documents tool first to get information\n",
    "#         2. Wait for the tool's response\n",
    "#         3. Synthesize the retrieved information into a clear explanation\n",
    "#         4. If the retrieved information is insufficient, clearly state that and provide a general explanation\n",
    "        \n",
    "#         IMPORTANT: \n",
    "#         - Always complete the full retrieval and response process\n",
    "#         - Never return just a message about needing to retrieve information\n",
    "#         - Provide complete, informative responses\n",
    "#         \"\"\"\n",
    "        \n",
    "#         # Prepare messages with system instruction\n",
    "#         full_messages = [\n",
    "#             HumanMessage(content=system_message),\n",
    "#             *messages\n",
    "#         ]\n",
    "        \n",
    "#         # Initialize model with tools and strict temperature\n",
    "#         model = ChatOpenAI(\n",
    "#             model_name=\"gpt-4o-mini\", \n",
    "#             temperature=0, \n",
    "#             streaming=True, \n",
    "#             api_key=st.secrets[\"OpenAI_key\"]\n",
    "#         )\n",
    "#         model_with_tools = model.bind_tools(tools)\n",
    "        \n",
    "#         # Create a specific prompt to force tool usage\n",
    "#         tool_prompt = HumanMessage(content=f\"\"\"Please provide information about: {question}\n",
    "#         Remember to:\n",
    "#         1. Use the retrieve_documents tool first\n",
    "#         2. Process the retrieved information\n",
    "#         3. Provide a complete response\"\"\")\n",
    "        \n",
    "#         # Get response with explicit tool usage\n",
    "#         response = model_with_tools.invoke([*full_messages, tool_prompt])\n",
    "        \n",
    "#         # Validate response\n",
    "#         if not response.content.strip() or \"need to retrieve\" in response.content.lower():\n",
    "#             print(\"Warning: Invalid response detected, forcing retrieval\")\n",
    "#             # Force direct retrieval as fallback\n",
    "#             docs = retriever.invoke(question)\n",
    "#             if docs:\n",
    "#                 # Process the retrieved documents\n",
    "#                 context = \"\\n\".join(doc.page_content for doc in docs)\n",
    "                \n",
    "#                 # Generate response with retrieved context\n",
    "#                 prompt = PromptTemplate(\n",
    "#                     template=\"\"\"Based on the following information, provide a complete explanation about {question}.\n",
    "                    \n",
    "#                     Retrieved information:\n",
    "#                     {context}\n",
    "                    \n",
    "#                     If the retrieved information is insufficient, provide a general explanation based on your knowledge\n",
    "#                     but clearly state that you're doing so.\n",
    "#                     \"\"\",\n",
    "#                     input_variables=[\"question\", \"context\"]\n",
    "#                 )\n",
    "                \n",
    "#                 chain = prompt | model | StrOutputParser()\n",
    "#                 response_content = chain.invoke({\n",
    "#                     \"question\": question,\n",
    "#                     \"context\": context\n",
    "#                 })\n",
    "#             else:\n",
    "#                 response_content = \"I apologize, but I couldn't find specific information about that. Let me provide a general explanation based on my knowledge.\"\n",
    "#         else:\n",
    "#             response_content = response.content\n",
    "            \n",
    "#         print(f\"Final response length: {len(response_content)}\")\n",
    "#         return {\"messages\": [AIMessage(content=response_content)], \"user_level\": state[\"user_level\"]}\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error in agent: {str(e)}\")\n",
    "#         # Fallback to direct explanation\n",
    "#         try:\n",
    "#             print(\"Attempting fallback retrieval...\")\n",
    "#             docs = retriever.invoke(question)\n",
    "#             if docs:\n",
    "#                 context = \"\\n\".join(doc.page_content for doc in docs)\n",
    "#                 return {\n",
    "#                     \"messages\": [AIMessage(content=f\"Here's what I found about {question}: {context}\")],\n",
    "#                     \"user_level\": state[\"user_level\"]\n",
    "#                 }\n",
    "#             else:\n",
    "#                 return {\n",
    "#                     \"messages\": [AIMessage(content=f\"I apologize, but I encountered an issue retrieving specific information about {question}. Please try rephrasing your question.\")],\n",
    "#                     \"user_level\": state[\"user_level\"]\n",
    "#                 }\n",
    "#         except Exception as e2:\n",
    "#             print(f\"Fallback retrieval failed: {str(e2)}\")\n",
    "#             return {\n",
    "#                 \"messages\": [AIMessage(content=\"I encountered an error processing your question. Please try asking in a different way.\")],\n",
    "#                 \"user_level\": state[\"user_level\"]\n",
    "#             }\n",
    "\n",
    "# def rewrite(state):\n",
    "#     \"\"\"Debug version of rewrite with validation\"\"\"\n",
    "#     print(\"\\n=== DEBUG: REWRITE NODE ===\")\n",
    "#     messages = state[\"messages\"]\n",
    "#     question = messages[-1].content\n",
    "#     print(f\"Rewriting question: {question}\")\n",
    "\n",
    "#     try:\n",
    "#         msg = [\n",
    "#             HumanMessage(\n",
    "#                 content=\"\"\"Improve this question to be more specific and searchable:\n",
    "#                 Question: {question}\n",
    "#                 Make it clearly about DSA concepts.\"\"\".format(question=question)\n",
    "#             )\n",
    "#         ]\n",
    "\n",
    "#         model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0, streaming=True, api_key=st.secrets[\"OpenAI_key\"])\n",
    "#         response = model.invoke(msg)\n",
    "#         print(f\"Rewritten as: {response.content}\")\n",
    "#         return {\"messages\": [AIMessage(content=response.content)], \"user_level\": state[\"user_level\"]}\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error in rewrite: {str(e)}\")\n",
    "#         return {\"messages\": [HumanMessage(content=question)], \"user_level\": state[\"user_level\"]}\n",
    "\n",
    "# def grade_documents(state) -> Literal[\"generate\", \"rewrite\"]:\n",
    "#     \"\"\"Debug version of grading with content validation\"\"\"\n",
    "#     print(\"\\n=== DEBUG: GRADE DOCUMENTS ===\")\n",
    "    \n",
    "#     messages = state[\"messages\"]\n",
    "#     last_message = messages[-1]\n",
    "#     question = messages[0].content\n",
    "#     docs = last_message.content\n",
    "    \n",
    "#     print(f\"Grading question: {question}\")\n",
    "#     print(f\"Documents content length: {len(docs) if docs else 'None'}\")\n",
    "    \n",
    "#     # Basic content validation\n",
    "#     if not docs or len(docs.strip()) < 10:\n",
    "#         print(\"---NO VALID DOCS TO GRADE---\")\n",
    "#         return \"rewrite\"\n",
    "        \n",
    "#     try:\n",
    "#         class grade(BaseModel):\n",
    "#             binary_score: str = Field(description=\"Relevance score 'yes' or 'no'\")\n",
    "            \n",
    "#         model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0, streaming=True, api_key=st.secrets[\"OpenAI_key\"])\n",
    "#         llm_with_tool = model.with_structured_output(grade)\n",
    "        \n",
    "#         prompt = PromptTemplate(\n",
    "#             template=\"\"\"Grade if this content is relevant to the question.\n",
    "#             Question: {question}\n",
    "#             Content: {context}\n",
    "#             Give 'yes' if there's ANY relevant information about the topic.\"\"\",\n",
    "#             input_variables=[\"context\", \"question\"],\n",
    "#         )\n",
    "        \n",
    "#         chain = prompt | llm_with_tool\n",
    "#         result = chain.invoke({\"question\": question, \"context\": docs})\n",
    "#         print(f\"Grade result: {result.binary_score}\")\n",
    "        \n",
    "#         return \"generate\" if result.binary_score.lower() == \"yes\" else \"rewrite\"\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error in grading: {str(e)}\")\n",
    "#         return \"generate\" if docs else \"rewrite\"\n",
    "\n",
    "\n",
    "################################################################################################################\n",
    "# def agent(state):\n",
    "#     \"\"\"\n",
    "#     Invokes the agent model to generate a response based on the current state. Given\n",
    "#     the question, it will decide to retrieve using the retriever tool, or simply end.\n",
    "\n",
    "#     Args:\n",
    "#         state (messages): The current state\n",
    "\n",
    "#     Returns:\n",
    "#         dict: The updated state with the agent response appended to messages\n",
    "#     \"\"\"\n",
    "#     print(\"---CALL AGENT---\")\n",
    "    \n",
    "#     # Prompt\n",
    "#     prompt = ChatMessagePromptTemplate\n",
    "    \n",
    "#     messages = state[\"messages\"]\n",
    "#     model = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", streaming=True,api_key=st.secrets[\"OpenAI_key\"])\n",
    "#     model = model.bind_tools(tools)\n",
    "#     response = model.invoke(messages)\n",
    "#     # We return a list, because this will get added to the existing list\n",
    "#     return {\"messages\": [response]}\n",
    "def agent(state):\n",
    "    \"\"\"\n",
    "    Invokes the agent model to generate a response based on confidence level.\n",
    "    \n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with the agent response appended to messages\n",
    "    \"\"\"\n",
    "    print(\"---CALL AGENT---\")\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # System message that enforces confidence-based retrieval\n",
    "    system_message = \"\"\"You are a DSA expert assistant. For every question:\n",
    "\n",
    "1. First, assess your confidence in providing a complete, accurate answer:\n",
    "   - Consider if you need specific implementation details\n",
    "   - Consider if you need exact complexity analysis\n",
    "   - Consider if you need specific examples or edge cases\n",
    "\n",
    "2. If your confidence is less than 90%%:\n",
    "   - ALWAYS use the retrieve_documents tool\n",
    "   - Base your answer on the retrieved information\n",
    "\n",
    "3. If your confidence is 90%% or higher:\n",
    "   - You may answer directly from your knowledge\n",
    "   - Still use the tool if additional detail would be helpful\n",
    "\n",
    "Remember: It's better to verify with the tool than risk providing incomplete or inaccurate information.\"\"\"\n",
    "\n",
    "    # Prepare messages with system instruction\n",
    "    full_messages = [\n",
    "        HumanMessage(content=system_message),\n",
    "        *messages\n",
    "    ]\n",
    "    \n",
    "    # Initialize model with tools\n",
    "    model = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", streaming=True, api_key=st.secrets[\"OpenAI_key\"])\n",
    "    model = model.bind_tools(tools)\n",
    "    \n",
    "    # Get response\n",
    "    response = model.invoke(full_messages)\n",
    "    \n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def grade_documents(state) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    \"\"\"\n",
    "    Enhanced grading system for retrieved DSA documents.\n",
    "    \n",
    "    Evaluates:\n",
    "    1. Relevance to the question\n",
    "    2. Completeness of the answer\n",
    "    3. Technical accuracy\n",
    "    4. Need for clarification\n",
    "    \n",
    "    Returns:\n",
    "    - \"generate\": When documents are good enough to generate response\n",
    "    - \"rewrite\": When documents aren't relevant enough\n",
    "    - \"clarify\": When question needs clarification\n",
    "    \"\"\"\n",
    "    print(\"---ENHANCED GRADING SYSTEM---\")\n",
    "    \n",
    "    class GradeResult(BaseModel):\n",
    "        relevance_score: float = Field(description=\"0-1 score for topic relevance\")\n",
    "        completeness_score: float = Field(description=\"0-1 score for answer completeness\")\n",
    "        technical_accuracy: float = Field(description=\"0-1 score for technical accuracy\")\n",
    "        reasoning: str = Field(description=\"Explanation for the grading decision\")\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    retrieved_docs = messages[-1].content\n",
    "\n",
    "    # Define the grading prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a DSA expert grading retrieved content.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Retrieved Content:\n",
    "{content}\n",
    "\n",
    "Grade this content on:\n",
    "1. Relevance: Does it directly address the DSA concepts in the question?\n",
    "2. Completeness: Does it cover all aspects needed for a good answer?\n",
    "3. Technical Accuracy: Is the DSA information correct and precise?\n",
    "4. Clarity: Is the question clear or needs clarification?\n",
    "\n",
    "Example DSA concepts to check for:\n",
    "- Data structure definitions and properties\n",
    "- Algorithm steps and processes\n",
    "- Time/space complexity mentions\n",
    "- Implementation details\n",
    "- Common use cases and examples\n",
    "\n",
    "Return scores as decimals between 0 and 1, where:\n",
    "- 0.0-0.3: Poor\n",
    "- 0.4-0.6: Moderate\n",
    "- 0.7-1.0: Good\n",
    "\n",
    "Also explain your reasoning.\"\"\",\n",
    "        input_variables=[\"question\", \"content\"]\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Initialize model with lower temperature for consistent grading\n",
    "        model = ChatOpenAI(\n",
    "            model_name=\"gpt-4o-mini\",\n",
    "            temperature=0,\n",
    "            streaming=True,\n",
    "            api_key=st.secrets[\"OpenAI_key\"]\n",
    "        )\n",
    "        \n",
    "        # Grade with structured output\n",
    "        chain = prompt | model.with_structured_output(GradeResult)\n",
    "        result = chain.invoke({\n",
    "            \"question\": question,\n",
    "            \"content\": retrieved_docs\n",
    "        })\n",
    "        \n",
    "        print(f\"Grading Results:\\n\"\n",
    "              f\"Relevance: {result.relevance_score:.2f}\\n\"\n",
    "              f\"Completeness: {result.completeness_score:.2f}\\n\"\n",
    "              f\"Technical Accuracy: {result.technical_accuracy:.2f}\\n\")\n",
    "            \n",
    "        # Calculate weighted average score\n",
    "        weighted_score = (\n",
    "            result.relevance_score * 0.4 +      # Relevance is most important\n",
    "            result.completeness_score * 0.3 +    # Completeness next\n",
    "            result.technical_accuracy * 0.3      # Technical accuracy equally important\n",
    "        )\n",
    "        \n",
    "        # Decision thresholds\n",
    "        GOOD_THRESHOLD = 0.65\n",
    "        \n",
    "        if weighted_score >= GOOD_THRESHOLD:\n",
    "            print(\"---DECISION: CONTENT GOOD ENOUGH TO GENERATE---\")\n",
    "            return \"generate\"\n",
    "        else:\n",
    "            print(\"---DECISION: NEED TO REWRITE QUERY---\")\n",
    "            return \"rewrite\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Grading error: {str(e)}\")\n",
    "        # On error, default to rewrite for safety\n",
    "        return \"rewrite\"\n",
    "    \n",
    "def rewrite(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "\n",
    "    msg = [\n",
    "        HumanMessage(\n",
    "            content=f\"\"\" \\n \n",
    "    Look at the input and try to reason about the underlying semantic intent / meaning. \\n \n",
    "    Here is the initial question:\n",
    "    \\n ------- \\n\n",
    "    {question} \n",
    "    \\n ------- \\n\n",
    "    Formulate an improved question: \"\"\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Grader\n",
    "    model = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", streaming=True,api_key=st.secrets[\"OpenAI_key\"])\n",
    "    response = model.invoke(msg)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"Generate response based on retrieved content and question\"\"\"\n",
    "    print(\"\\n=== DEBUG: GENERATE NODE ===\")\n",
    "    messages = state[\"messages\"]\n",
    "    print(\"Messages: \", state[\"messages\"])\n",
    "    \n",
    "    # Find the last actual question by looking for the last HumanMessage\n",
    "    # that triggered the retrieval flow\n",
    "    question = None\n",
    "    \n",
    "    for msg in messages:\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            question = msg.content\n",
    "            \n",
    "    if not question:\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=\"I couldn't properly process your question. Could you please rephrase it?\")],\n",
    "            \"user_level\": state[\"user_level\"]\n",
    "        }\n",
    "        \n",
    "    user_level = state[\"user_level\"]\n",
    "    docs = messages[-1].content  # Retrieved content is always last\n",
    "    \n",
    "    print(f\"Generate received question: {question}\")\n",
    "    print(f\"User level: {user_level}\")\n",
    "    # print(f\"Docs length: {len(docs) if docs else 'None'}\")\n",
    "    \n",
    "    if not docs or len(docs.strip()) < 10:\n",
    "        print(\"---NO CONTENT TO GENERATE FROM---\")\n",
    "        return {\"messages\": [AIMessage(content=\"I apologize, but I couldn't find relevant information to answer your question. Please try rephrasing it.\")], \"user_level\": state[\"user_level\"]}\n",
    "        \n",
    "    try:\n",
    "        llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0, streaming=True, api_key=st.secrets[\"OpenAI_key\"])\n",
    "        \n",
    "        # prompt = PromptTemplate(\n",
    "        #     template=\"\"\"Answer based on the following context. If context is insufficient, say so clearly.\n",
    "        #     Question: {question}\n",
    "        #     User Level: {user_level}\n",
    "        #     Context: {context}\n",
    "            \n",
    "        #     If you don't find specific information about the topic, you can provide a general explanation based on your knowledge, but clearly state that you're doing so.\"\"\",\n",
    "        #     input_variables=[\"context\", \"question\", \"user_level\"],\n",
    "        # )\n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=['context', 'question','user_level'], \n",
    "            input_types={}, \n",
    "            partial_variables={}, \n",
    "            template=\"\"\"\n",
    "                You are a DSA expert tutor. Adapt your teaching style to the user's level while maintaining technical accuracy.\n",
    "\n",
    "                Current User Level: {user_level}\n",
    "\n",
    "                [TEACHING APPROACHES]\n",
    "                BEGINNER: Simple analogies, basic understanding, minimal jargon\n",
    "                INTERMEDIATE: Basic complexity, implementation details, code examples\n",
    "                ADVANCED: Deep optimization, system considerations, complex trade-offs\n",
    "\n",
    "                • UNIVERSAL RULES:\n",
    "                • Stay within DSA scope\n",
    "                    • Focus on one concept at a time\n",
    "                    • Offer to explore related topics after\n",
    "                • Use context appropriately\n",
    "                    • Start with provided context: \"{context}\"\n",
    "                    • Clearly indicate when using general knowledge\n",
    "                    • Stay within user's competency level\n",
    "                • Maintain level-appropriate depth\n",
    "                    • Match technical depth to user level\n",
    "                    • Scale example complexity appropriately\n",
    "                    • Use suitable terminology\n",
    "\n",
    "                Question: {question}\n",
    "                \"\"\")\n",
    "        # prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "        \n",
    "        chain = prompt | llm | StrOutputParser()\n",
    "        response = chain.invoke({\n",
    "            \"context\": docs,\n",
    "            \"question\": question,\n",
    "            \"user_level\": user_level\n",
    "        })\n",
    "        \n",
    "        print(f\"Generated response length: {len(response)}\")\n",
    "        return {\"messages\": [AIMessage(content=response)], \"user_level\": state[\"user_level\"]}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in generate: {str(e)}\")\n",
    "        return {\"messages\": [AIMessage(content=\"I encountered an error generating a response. Please try asking your question again.\")], \"user_level\": state[\"user_level\"]}\n",
    "\n",
    "################################################################################################################\n",
    "# Graph setup\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"validate_topic\", validate_dsa_question)\n",
    "workflow.add_node(\"clarify\", clarify_question)\n",
    "workflow.add_node(\"agent\", agent)\n",
    "retrieve = ToolNode([retriever_tool])\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "workflow.add_node(\"rewrite\", rewrite)\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(START, \"validate_topic\")\n",
    "\n",
    "# Modify validation to return three possible outcomes\n",
    "workflow.add_conditional_edges(\n",
    "    \"validate_topic\",\n",
    "    lambda x: x[\"next\"],\n",
    "    {\n",
    "        \"proceed\": \"agent\",\n",
    "        \"clarify\": \"clarify\",\n",
    "        \"redirect\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# After clarification, go to agent\n",
    "workflow.add_edge(\"clarify\", \"agent\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    tools_condition,\n",
    "    {\n",
    "        \"tools\": \"retrieve\",\n",
    "        END: END,\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    grade_documents,\n",
    "    {\n",
    "        \"generate\": \"generate\",\n",
    "        \"rewrite\": \"rewrite\",\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"generate\", END)\n",
    "workflow.add_edge(\"rewrite\", \"agent\")\n",
    "\n",
    "# Compile graph\n",
    "from test_templates.memory import memory\n",
    "graph = workflow.compile()\n",
    "\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(\"what is Insertion Sort\"),\n",
    "    ],\n",
    "    \"user_level\": \"beginner\"\n",
    "}\n",
    "\n",
    "output = graph.invoke(inputs)\n",
    "print('output:',output[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elroy\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\nltk\\metrics\\association.py:26: UserWarning: A NumPy version >=1.23.5 and <2.3.0 is required for this version of SciPy (detected version 1.23.2)\n",
      "  from scipy.stats import fisher_exact\n",
      "c:\\Users\\elroy\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "2025-02-16 21:25:06.619 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.626 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.633 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.641 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.758 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.759 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.760 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.848 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\elroy\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-02-16 21:25:06.849 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.850 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.851 Session state does not function when running a script without `streamlit run`\n",
      "2025-02-16 21:25:06.852 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.852 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.853 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.854 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.855 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.855 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.856 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.856 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.856 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.857 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.857 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.858 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.858 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.858 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.859 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.860 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.860 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.862 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.863 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.864 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.866 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.867 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.868 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.869 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.869 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.870 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.870 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.871 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.871 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.872 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.872 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.872 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.873 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:06.873 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing retriever...\n",
      "Initialising the app...\n",
      "\n",
      "Clearing session variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:25:07.575 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.576 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.578 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.581 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.582 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.583 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.585 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.586 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.587 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.588 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.590 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.593 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.598 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.599 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.600 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.601 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.602 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.603 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.604 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.604 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.605 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.606 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.607 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.608 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.609 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.610 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.610 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.611 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.613 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.614 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.615 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.616 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.617 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.618 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.618 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.619 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.620 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.620 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.621 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.621 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.622 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.623 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.624 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.625 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.626 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.627 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.627 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.628 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.628 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.629 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.630 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.631 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.632 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.633 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.633 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.634 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.635 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.636 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.636 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.637 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.638 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.638 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.639 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.639 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.640 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.641 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.641 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.642 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.642 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.643 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.644 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.645 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.646 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.646 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.647 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.648 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.649 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.649 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.650 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.651 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.652 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.653 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.653 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.654 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.654 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.656 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.657 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.657 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.657 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.677 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.679 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.680 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.681 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.682 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.683 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.684 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-16 21:25:07.684 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='explain this', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Sure! Let’s break down the concepts in the image step by step. It looks like you’re working with a sorting algorithm, specifically **Insertion Sort**. Let’s dive in!\\n\\n### What We're Looking At\\nI see you're working with a visual representation of the Insertion Sort algorithm! This method sorts an array by building a sorted section of the array one element at a time. It’s a great way to understand how sorting works, especially for beginners.\\n\\n### Key Concepts\\n\\n#### Insertion Sort\\nYou know what's cool about this? Insertion Sort works similarly to how you might sort playing cards in your hands. You take one card at a time and place it in the correct position among the cards you’ve already sorted.\\n\\n#### Steps of the Algorithm\\nLet’s break down the steps shown in the image:\\n\\n1. **Initial Position**: The first element (7) is considered sorted since there’s nothing to its left. \\n2. **Comparing and Shifting**: As you move to the next element (4), you compare it with the sorted section (just 7). Since 4 is less than 7, you shift 7 to the right and place 4 in the first position.\\n3. **Continuing the Process**: Next, you look at 5. You compare it with 4 and 7. Since 5 is less than 7 but greater than 4, you shift 7 to the right and place 5 in the correct position.\\n4. **Final Adjustments**: Finally, you check 2 against all the sorted elements. Since 2 is less than all of them, you shift them all to the right and place 2 at the start.\\n\\n### Understanding the Details\\n\\n#### Step-by-Step Breakdown\\n- **Step 1**: The array starts as [7, 4, 5, 2]. Since 7 is the first element, it stays put.\\n- **Step 2**: When you bring in 4, you see it’s smaller than 7, so you move 7 to the right and insert 4 at the start: [4, 7, 5, 2].\\n- **Step 3**: Next, you look at 5. It’s smaller than 7 but larger than 4, so you shift 7 to the right and place 5 in the middle: [4, 5, 7, 2].\\n- **Step 4**: Finally, with 2, you find it’s smaller than all the sorted elements, so you shift them all to the right and place 2 at the start: [2, 4, 5, 7].\\n\\n### Real-World Connection\\nThink about organizing your bookshelf. When you get a new book, you don’t just throw it on the shelf. Instead, you find the right spot by comparing it to the books already there. That’s exactly what Insertion Sort does!\\n\\n### Encouraging Note\\nGreat job exploring sorting algorithms! If you have any questions or want to dive deeper into any part of this process, feel free to ask. Happy learning!\", additional_kwargs={}, response_metadata={})]\n",
      "output: current_level='beginner' recommendation='Maintain' confidence=0.9 evidence=['User asked for an explanation of Insertion Sort, indicating a desire to understand sorting algorithms.', 'User engaged with the detailed breakdown of the algorithm and related it to real-world scenarios.'] reasoning=['The user demonstrated a basic understanding of the Insertion Sort algorithm and its steps, which is appropriate for a beginner level.', \"The user's engagement with the explanation and ability to relate it to real-world examples shows they are grasping the foundational concepts, but further practice is needed to solidify their understanding.\"]\n"
     ]
    }
   ],
   "source": [
    "# app = workflow.compile(checkpointer=memory)\n",
    "from test_templates.intial_template import app\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from app_LG import db\n",
    "langgraph_config = {\"configurable\": {\"thread_id\": \"2200499\"}}\n",
    "chat_history = db.load_chat_history(\"6fcf537a-8e1e-496b-be68-84841722fa57\", \"6fcf537a-8e1e-496b-be68-84841722fa57_1\")\n",
    "updated_messages = []\n",
    "for message in chat_history:\n",
    "    if message[\"role\"] == \"user\":\n",
    "        updated_messages.append(HumanMessage(content=message[\"content\"]))\n",
    "    else:\n",
    "        updated_messages.append(AIMessage(content=message[\"content\"]))\n",
    "\n",
    "print(updated_messages)\n",
    "\n",
    "# Process the user input\n",
    "from test_templates.analyser import graph\n",
    "\n",
    "graph.update_state(values = {\"messages\": updated_messages}, config = langgraph_config)\n",
    "\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(\"Hi\")\n",
    "    ],\n",
    "    \"user_level\": \"beginner\"\n",
    "}\n",
    "\n",
    "output = graph.invoke(inputs, langgraph_config)\n",
    "print('output:',output[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat History using LangGraph\n",
    "[Langgraph][https://python.langchain.com/docs/how_to/message_history/]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=st.secrets[\"OpenAI_key\"],\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    # Update message history with response:\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Define the (single) node in the graph\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Hi! I'm Bob.\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "# for chunk in app.stream({\"messages\": input_messages}, config):\n",
    "#     print(chunk)\n",
    "    \n",
    "\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].content\n",
    "# output[\"messages\"][-1].pretty_print()  # output contains all messages in state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What's my name?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = app.get_state(config).values[\"messages\"]\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removal of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import RemoveMessage\n",
    "\n",
    "updated_messages = [RemoveMessage(m.id) for m in messages]\n",
    "app.update_state(values = {\"messages\": updated_messages}, config = config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What's my name?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"abc234\"}}\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain with Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Answer in {language}.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "runnable = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    language: str\n",
    "\n",
    "\n",
    "workflow = StateGraph(state_schema=State)\n",
    "\n",
    "\n",
    "def call_model(state: State):\n",
    "    response = runnable.invoke(state)\n",
    "    # Update message history with response:\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "# input_dict = {\n",
    "#     \"messages\": [HumanMessage(\"Hi, I'm Bob.\")],\n",
    "#     \"language\": \"Spanish\",\n",
    "# }\n",
    "\n",
    "# output = app.invoke(input_dict, config)\n",
    "print(output)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "state = app.get_state(config).values\n",
    "\n",
    "# print(f'Language: {state[\"language\"]}')\n",
    "for message in state[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append new messages manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "_ = app.update_state(config, {\"messages\": [HumanMessage(\"Test\")]})\n",
    "_ = app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = app.get_state(config).values\n",
    "\n",
    "print(f'Language: {state[\"language\"]}')\n",
    "for message in state[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from utils.chunk_doc import get_retriever\n",
    "import os\n",
    "import streamlit as st\n",
    "\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY']= st.secrets[\"New_Langsmith_key\"]\n",
    "os.environ['LANGCHAIN_PROJECT']=\"default\"\n",
    "\n",
    "retriever = get_retriever()\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retrieve_documents\",\n",
    "    \"Search and return relevant documents based on user's query.\",\n",
    ")\n",
    "\n",
    "tools = [retriever_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # The add_messages function defines how an update should be processed\n",
    "    # Default is to replace. add_messages says \"append\"\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************Prompt[rlm/rag-prompt]********************\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: \u001b[33;1m\u001b[1;3m{question}\u001b[0m \n",
      "Context: \u001b[33;1m\u001b[1;3m{context}\u001b[0m \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated, Literal, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "### Edges\n",
    "\n",
    "\n",
    "def grade_documents(state) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        str: A decision for whether the documents are relevant or not\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK RELEVANCE---\")\n",
    "\n",
    "    # Data model\n",
    "    class grade(BaseModel):\n",
    "        \"\"\"Binary score for relevance check.\"\"\"\n",
    "\n",
    "        binary_score: str = Field(description=\"Relevance score 'yes' or 'no'\")\n",
    "\n",
    "    # LLM\n",
    "    model = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", streaming=True,api_key=st.secrets[\"OpenAI_key\"])\n",
    "\n",
    "    # LLM with tool and validation\n",
    "    llm_with_tool = model.with_structured_output(grade)\n",
    "\n",
    "    # Prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
    "        Here is the user question: {question} \\n\n",
    "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "    # Chain\n",
    "    chain = prompt | llm_with_tool\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    question = messages[0].content\n",
    "    docs = last_message.content\n",
    "\n",
    "    scored_result = chain.invoke({\"question\": question, \"context\": docs})\n",
    "\n",
    "    score = scored_result.binary_score\n",
    "\n",
    "    if score == \"yes\":\n",
    "        print(\"---DECISION: DOCS RELEVANT---\")\n",
    "        return \"generate\"\n",
    "\n",
    "    else:\n",
    "        print(\"---DECISION: DOCS NOT RELEVANT---\")\n",
    "        print(score)\n",
    "        return \"rewrite\"\n",
    "\n",
    "\n",
    "### Nodes\n",
    "\n",
    "\n",
    "def agent(state):\n",
    "    \"\"\"\n",
    "    Invokes the agent model to generate a response based on the current state. Given\n",
    "    the question, it will decide to retrieve using the retriever tool, or simply end.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with the agent response appended to messages\n",
    "    \"\"\"\n",
    "    print(\"---CALL AGENT---\")\n",
    "    messages = state[\"messages\"]\n",
    "    model = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", streaming=True,api_key=st.secrets[\"OpenAI_key\"])\n",
    "    model = model.bind_tools(tools)\n",
    "    response = model.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def rewrite(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "\n",
    "    msg = [\n",
    "        HumanMessage(\n",
    "            content=f\"\"\" \\n \n",
    "    Look at the input and try to reason about the underlying semantic intent / meaning. \\n \n",
    "    Here is the initial question:\n",
    "    \\n ------- \\n\n",
    "    {question} \n",
    "    \\n ------- \\n\n",
    "    Formulate an improved question: \"\"\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Grader\n",
    "    model = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", streaming=True,api_key=st.secrets[\"OpenAI_key\"])\n",
    "    response = model.invoke(msg)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "         dict: The updated state with re-phrased question\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    docs = last_message.content\n",
    "\n",
    "    # Prompt\n",
    "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "    # LLM\n",
    "    llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", streaming=True,api_key=st.secrets[\"OpenAI_key\"])\n",
    "\n",
    "    # Post-processing\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    # Chain\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    # Run\n",
    "    response = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "print(\"*\" * 20 + \"Prompt[rlm/rag-prompt]\" + \"*\" * 20)\n",
    "prompt = hub.pull(\"rlm/rag-prompt\").pretty_print()  # Show what the prompt looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the nodes we will cycle between\n",
    "workflow.add_node(\"agent\", agent)  # agent\n",
    "retrieve = ToolNode([retriever_tool])\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieval\n",
    "workflow.add_node(\"rewrite\", rewrite)  # Re-writing the question\n",
    "workflow.add_node(\n",
    "    \"generate\", generate\n",
    ")  # Generating a response after we know the documents are relevant\n",
    "# Call agent node to decide to retrieve or not\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# Decide whether to retrieve\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    # Assess agent decision\n",
    "    tools_condition,\n",
    "    {\n",
    "        # Translate the condition outputs to nodes in our graph\n",
    "        \"tools\": \"retrieve\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Edges taken after the `action` node is called.\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    # Assess agent decision\n",
    "    grade_documents,\n",
    ")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "workflow.add_edge(\"rewrite\", \"agent\")\n",
    "\n",
    "# Compile\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALL AGENT---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK RELEVANCE---\n",
      "---DECISION: DOCS NOT RELEVANT---\n",
      "no\n",
      "---TRANSFORM QUERY---\n",
      "---CALL AGENT---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK RELEVANCE---\n",
      "---DECISION: DOCS NOT RELEVANT---\n",
      "no\n",
      "---TRANSFORM QUERY---\n",
      "---CALL AGENT---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK RELEVANCE---\n",
      "---DECISION: DOCS NOT RELEVANT---\n",
      "no\n",
      "---TRANSFORM QUERY---\n",
      "---CALL AGENT---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK RELEVANCE---\n",
      "---DECISION: DOCS NOT RELEVANT---\n",
      "no\n",
      "---TRANSFORM QUERY---\n",
      "---CALL AGENT---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK RELEVANCE---\n",
      "---DECISION: DOCS NOT RELEVANT---\n",
      "no\n",
      "---TRANSFORM QUERY---\n",
      "---CALL AGENT---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK RELEVANCE---\n",
      "---DECISION: DOCS NOT RELEVANT---\n",
      "no\n",
      "---TRANSFORM QUERY---\n",
      "---CALL AGENT---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 15\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# inputs = {\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#     \"messages\": [\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#         HumanMessage(\"What is quick sort\")\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#     ]\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# }\u001b[39;00m\n\u001b[0;32m      9\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m     11\u001b[0m         HumanMessage(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWho is obama\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     12\u001b[0m     ]\n\u001b[0;32m     13\u001b[0m }\n\u001b[1;32m---> 15\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput:\u001b[39m\u001b[38;5;124m'\u001b[39m,output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# for output in graph.stream(inputs):\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#     for key, value in output.items():\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#         pprint.pprint(f\"Output from node '{key}':\")\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#         pprint.pprint(\"---\")\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#         pprint.pprint(value, indent=2, width=80, depth=None)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#     pprint.pprint(\"\\n---\\n\")\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Elroy Lian\\.conda\\envs\\chatbot\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1940\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[0;32m   1938\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1939\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1940\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1941\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1944\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1945\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1946\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1947\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1948\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1949\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1950\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Elroy Lian\\.conda\\envs\\chatbot\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1660\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1657\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1658\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 1660\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1661\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[0;32m   1667\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Elroy Lian\\.conda\\envs\\chatbot\\Lib\\site-packages\\langgraph\\pregel\\runner.py:167\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    165\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 167\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\Elroy Lian\\.conda\\envs\\chatbot\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\Users\\Elroy Lian\\.conda\\envs\\chatbot\\Lib\\site-packages\\langgraph\\utils\\runnable.py:408\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m    405\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    406\u001b[0m )\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 408\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\Elroy Lian\\.conda\\envs\\chatbot\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:246\u001b[0m, in \u001b[0;36mToolNode.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m    245\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Elroy Lian\\.conda\\envs\\chatbot\\Lib\\site-packages\\langgraph\\utils\\runnable.py:184\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 184\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\Elroy Lian\\.conda\\envs\\chatbot\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:219\u001b[0m, in \u001b[0;36mToolNode._func\u001b[1;34m(self, input, config, store)\u001b[0m\n\u001b[0;32m    217\u001b[0m input_types \u001b[38;5;241m=\u001b[39m [input_type] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(tool_calls)\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m--> 219\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;241m*\u001b[39mexecutor\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_one, tool_calls, input_types, config_list)\n\u001b[0;32m    221\u001b[0m     ]\n\u001b[0;32m    223\u001b[0m \u001b[38;5;66;03m# preserve existing behavior for non-command tool outputs for backwards compatibility\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(output, Command) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs):\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;66;03m# TypedDict, pydantic, dataclass, etc. should all be able to load from dict\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Elroy Lian\\.conda\\envs\\chatbot\\Lib\\concurrent\\futures\\_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[1;32mc:\\Users\\Elroy Lian\\.conda\\envs\\chatbot\\Lib\\concurrent\\futures\\_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 317\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[1;32mc:\\Users\\Elroy Lian\\.conda\\envs\\chatbot\\Lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\Elroy Lian\\.conda\\envs\\chatbot\\Lib\\threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 327\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "# inputs = {\n",
    "#     \"messages\": [\n",
    "#         HumanMessage(\"What is quick sort\")\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(\"Who is obama\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "output = graph.invoke(inputs)\n",
    "print('output:',output[\"messages\"][-1].content)\n",
    "# for output in graph.stream(inputs):\n",
    "#     for key, value in output.items():\n",
    "#         pprint.pprint(f\"Output from node '{key}':\")\n",
    "#         pprint.pprint(\"---\")\n",
    "#         pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "#     pprint.pprint(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elroy\\AppData\\Local\\Temp\\ipykernel_30700\\1394110419.py:6: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=st.secrets[\"OpenAI_key\"],\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_templates.image_template import image_app\n",
    "def read_image_bytes(image_path):\n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        return image_file.read()\n",
    "img = read_image_bytes('test_image_1.jpeg')\n",
    "import base64\n",
    "\n",
    "image_data = base64.b64encode(img).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "\n",
    "# image_chain = get_image_chain()\n",
    "\n",
    "message_content = [{\"type\": \"text\", \"text\": \"Describe the image provided\"}]\n",
    "message_content.append({\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"}\n",
    "                })\n",
    "\n",
    "final_message = {\n",
    "    \"messages\":[\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": message_content,\n",
    "    }],\n",
    "    \"user_level\": \"beginner\"}\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "image_app.invoke(input = final_message,config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing retrieval for: What is quicksort?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No index params provided. Could not determine relevance function. Use L2 distance as default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of documents found: 10\n",
      "\n",
      "--- Document 1 ---\n",
      "Source: data\\md\\algo1.md\n",
      "Content: ###### The basic algorithm  Quicksort is a divide-and-conquer method for sorting. It\n",
      "\n",
      "works by partitioning an array into two subarrays, then sorting the subarrays independently. Quicksort is compleme...\n",
      "\n",
      "--- Document 2 ---\n",
      "Source: data\\md\\algo1.md\n",
      "Content: -----\n",
      "\n",
      "###### Performance characteristics Quicksort has been subjected to very thorough\n",
      "\n",
      "mathematical analysis, so that we can make precise statements about its performance.\n",
      "The analysis has been vali...\n",
      "\n",
      "--- Document 3 ---\n",
      "Source: data\\md\\divide-and-conquer.md\n",
      "Content: - Slower than QuickSort in general. QuickSort is more cache friendly because it works in-place.\n",
      "\n",
      "\n",
      "Quick Links:\n",
      "\n",
      "\n",
      "\n",
      "- Merge Sort Based Coding Questions\n",
      "\n",
      "- Bottom up (or Iterative) Merge Sort\n",
      "\n",
      "- Recent A...\n",
      "\n",
      "--- Document 4 ---\n",
      "Source: data\\md\\randomized-algorithms.md\n",
      "Content: ### C#\n",
      "\n",
      "\n",
      "```\n",
      "// C# implementation of QuickSort// using Hoare's partition schemeusingSystem;publicclassGFG {// Driver CodepublicstaticvoidMain(){int[] arr = { 10, 7, 8, 9, 1, 5 };intn = arr.Length;quic...\n",
      "\n",
      "--- Document 5 ---\n",
      "Source: data\\md\\algo1.md\n",
      "Content: Thus, in most practical situations, quicksort is the method of choice. Still, given the\n",
      "broad reach of sorting and the broad variety of computers and systems, a flat statement\n",
      "like this is difficult t...\n",
      "\n",
      "--- Document 6 ---\n",
      "Source: data\\md\\randomized-algorithms.md\n",
      "Content: ### Javascript\n",
      "\n",
      "\n",
      "```\n",
      "// javascript implementation of QuickSort// using Hoare's partition scheme// This function takes last element as // pivot, places the pivot element at// its correct position in so...\n",
      "\n",
      "--- Document 7 ---\n",
      "Source: data\\md\\algo1.md\n",
      "Content: As with standard quicksort, the running time tends to the average as the array size\n",
      "\n",
      "grows, and large deviations from the average are extremely unlikely, so that you can\n",
      "depend on 3-way quicksort’s ru...\n",
      "\n",
      "--- Document 8 ---\n",
      "Source: data\\md\\dsa1.md\n",
      "Content: whole array to reflect the splitting. We say that we partition the array, and the Quicksort\n",
      "algorithm is then applied to the sub-arrays of this partitioned array.\n",
      "In order for the algorithm to be call...\n",
      "\n",
      "--- Document 9 ---\n",
      "Source: data\\md\\sorting-algorithms.md\n",
      "Content: def quicksort(arr, low, high):\n",
      "        if low < high:\n",
      "            pi = partition(arr, low, high)\n",
      "            quicksort(arr, low, pi - 1)\n",
      "            quicksort(arr, pi + 1, high)\n",
      "\n",
      "    quicksort(element...\n",
      "\n",
      "--- Document 10 ---\n",
      "Source: data\\md\\dsa1.md\n",
      "Content: ```\n",
      "77\n",
      "\n",
      "\n",
      "-----\n",
      "\n",
      "```\n",
      "      a[acount++] = a[i]\n",
      "    else\n",
      "      b[bcount++] = a[i]\n",
      "   }\n",
      "   for ( i = 0 ; i < bcount ; i++ )\n",
      "    a[acount++] = b[i]\n",
      "   return right-bcount+1\n",
      " }\n",
      "\n",
      "```\n",
      "Like the first partition...\n"
     ]
    }
   ],
   "source": [
    "from utils.chunk_doc import get_retriever\n",
    "\n",
    "def test_quicksort_retrieval():\n",
    "    # Get the retriever\n",
    "    retriever = get_retriever()\n",
    "    \n",
    "    # Test quicksort query\n",
    "    query = \"What is quicksort?\"\n",
    "    print(f\"\\nTesting retrieval for: {query}\")\n",
    "    \n",
    "    try:\n",
    "        # Get documents\n",
    "        docs = retriever.get_relevant_documents(query)\n",
    "        \n",
    "        print(f\"\\nNumber of documents found: {len(docs)}\")\n",
    "        \n",
    "        if len(docs) > 0:\n",
    "            for i, doc in enumerate(docs, 1):\n",
    "                print(f\"\\n--- Document {i} ---\")\n",
    "                print(f\"Source: {doc.metadata.get('source', 'No source')}\")\n",
    "                print(f\"Content: {doc.page_content[:200]}...\")\n",
    "        else:\n",
    "            print(\"No documents were retrieved!\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error during retrieval: {str(e)}\")\n",
    "\n",
    "# Run test\n",
    "if __name__ == \"__main__\":\n",
    "    test_quicksort_retrieval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
