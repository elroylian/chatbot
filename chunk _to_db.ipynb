{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Store with Custom Embeddings Using Langchain and Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the cell below if db is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elroy\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for punkt data in C:\\Users\\elroy/nltk_data\\tokenizers\\punkt\n",
      "punkt data found in C:\\Users\\elroy/nltk_data\\tokenizers\\punkt\n",
      "Checking for punkt_tab data in C:\\Users\\elroy/nltk_data\\tokenizers\\punkt_tab\n",
      "punkt_tab data found in C:\\Users\\elroy/nltk_data\\tokenizers\\punkt_tab\n"
     ]
    }
   ],
   "source": [
    "from utils.sentence_chunking import get_sentence_chunks\n",
    "\n",
    "import chromadb\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter as Rec\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/multi-qa-MiniLM-L6-cos-v1')\n",
    "# model = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1')\n",
    "\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from typing import List\n",
    "\n",
    "class MyEmbeddings(Embeddings):\n",
    "        def __init__(self):\n",
    "            self.model = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1')\n",
    "    \n",
    "        def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "            return [self.model.encode(t).tolist() for t in texts]\n",
    "        \n",
    "        def embed_query(self, query: str) -> List[float]:\n",
    "            return self.model.encode(query).tolist()\n",
    "\n",
    "embedding_func = MyEmbeddings()\n",
    "\n",
    "# Initialize ChromaDB client\n",
    "client = chromadb.PersistentClient(path=\"db/pdfs\")\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "vector_store = Chroma(\n",
    "    client = client,\n",
    "    collection_name=\"markdown_chunks_collection\",\n",
    "    embedding_function=embedding_func,\n",
    "    # persist_directory = \"db/pdfs\",\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "def split_chunks():\n",
    "    try:\n",
    "        # Path to markdown directory\n",
    "        md_dir = Path(\"data/md/\")\n",
    "        chunk_id_counter = 1  # Initialize a counter for unique chunk IDs\n",
    "        ids = []\n",
    "        documents = []\n",
    "\n",
    "        # Loop through all markdown files in the md directory\n",
    "        for md_file in md_dir.glob(\"*.md\"):\n",
    "            with open(md_file, \"r\") as f:\n",
    "                md_content = f.read()\n",
    "\n",
    "            # Chunk the markdown content\n",
    "            ## Chunk Method 1: Sentence Chunking\n",
    "            # chunks = get_sentence_chunks(md_content, tokenizer)\n",
    "            \n",
    "            ## Chunk Method 2: CST Token Chunking\n",
    "            # chunks = get_cst_token_chunks(md_content, tokenizer)\n",
    "            \n",
    "            ## Chunk Method 3: Recursive Character Chunking\n",
    "            text_splitter = Rec(\n",
    "                chunk_size=1000,\n",
    "                chunk_overlap=200,\n",
    "                length_function=len,\n",
    "                add_start_index=True\n",
    "            )\n",
    "            chunks = text_splitter.split_text(md_content)\n",
    "            \n",
    "            for chunk in chunks:\n",
    "                # Create a Document object for the chunk\n",
    "                document_to_add = Document(\n",
    "                    page_content = chunk,\n",
    "                    metadata = {\"source\": str(md_file)}\n",
    "                )\n",
    "                \n",
    "                documents.append(document_to_add)\n",
    "                \n",
    "                ids.append(str(chunk_id_counter)) # Add document ID to the list\n",
    "\n",
    "                chunk_id_counter += 1  # Increment the ID counter\n",
    "        \n",
    "        vector_store.add_documents(documents = documents, ids = ids)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    split_chunks()\n",
    "    \n",
    "    # results = vector_store.similarity_search(query=\"insertion sort\",k=1)\n",
    "    # for doc in results:\n",
    "    #     print(f\"* {doc.page_content} [{doc.metadata}]\")\n",
    "    \n",
    "    # retriever = vector_store.as_retriever(\n",
    "    # search_type=\"mmr\",\n",
    "    # search_kwargs={\"k\": 10, \"fetch_k\": 20, \"lambda_mult\": 0.5},\n",
    "    # )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search relevant documents based on query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* |2|4|54|74|75|\n",
      "|---|---|---|---|---|\n",
      "\n",
      "|4|74|75|2|54|\n",
      "|---|---|---|---|---|\n",
      "||||||\n",
      "\n",
      "|2|4|74|75|54|\n",
      "|---|---|---|---|---|\n",
      "||||||\n",
      "\n",
      "\n",
      "-----\n",
      "\n",
      "_CHAPTER 8. SORTING_ 68\n",
      "\n",
      "###### 8.5 Shell Sort\n",
      "\n",
      "Put simply shell sort can be thought of as a more efficient variation of insertion\n",
      "sort as described in 8.4, it achieves this mainly by comparing items of varying\n",
      "_§_\n",
      "distances apart resulting in a run time complexity of O(n log[2] _n)._\n",
      "\n",
      "Shell sort is fairly straight forward but may seem somewhat confusing at\n",
      "first as it differs from other sorting algorithms in the way it selects items to\n",
      "compare. Figure 8.5 shows shell sort being ran on an array of integers, the red\n",
      "coloured square is the current value we are holding. [{'source': 'data\\\\md\\\\dsa.md'}]\n",
      "* 4 75 74\n",
      "\n",
      "4 75 74 2 54 4 75 74 2 54 4 75 74 2 54\n",
      "\n",
      "2 54\n",
      "\n",
      "4 74 75 2 54 2 4 74 75 54 2 4 54 74 75\n",
      "\n",
      "Figure 8.4: Insertion Sort Iterations\n",
      "\n",
      "1) algorithm Insertionsort(list)\n",
      "2) **Pre:** _list_ =\n",
      "_̸_ _∅_\n",
      "3) **Post: list has been sorted into values of ascending order**\n",
      "4) _unsorted_ 1\n",
      "_←_\n",
      "5) **while unsorted < list.Count**\n",
      "6) _hold_ _list[unsorted]_\n",
      "_←_\n",
      "7) _i_ _unsorted_ 1\n",
      "_←_ _−_\n",
      "8) **while i** 0 and hold < list[i]\n",
      "_≥_\n",
      "9) _list[i + 1]_ _list[i]_\n",
      "_←_\n",
      "10) _i_ _i_ 1\n",
      "_←_ _−_\n",
      "11) **end while**\n",
      "12) _list[i + 1]_ _hold_\n",
      "_←_\n",
      "13) _unsorted_ _unsorted + 1_\n",
      "_←_\n",
      "14) **end while**\n",
      "15) **return list**\n",
      "16) end Insertionsort\n",
      "\n",
      "|4|Col2|\n",
      "|---|---|\n",
      "|||\n",
      "\n",
      "|75|Col2|\n",
      "|---|---|\n",
      "|||\n",
      "\n",
      "|4|75|74|2|54|\n",
      "|---|---|---|---|---|\n",
      "\n",
      "|4|75|74|2|54|\n",
      "|---|---|---|---|---|\n",
      "\n",
      "|4|75|74|2|54|\n",
      "|---|---|---|---|---|\n",
      "||||||\n",
      "\n",
      "|2|4|54|74|75|\n",
      "|---|---|---|---|---|\n",
      "\n",
      "|4|74|75|2|54|\n",
      "|---|---|---|---|---|\n",
      "||||||\n",
      "\n",
      "|2|4|74|75|54|\n",
      "|---|---|---|---|---|\n",
      "||||||\n",
      "\n",
      "\n",
      "-----\n",
      "\n",
      "_CHAPTER 8. SORTING_ 68\n",
      "\n",
      "###### 8.5 Shell Sort [{'source': 'data\\\\md\\\\dsa.md'}]\n",
      "* |4|75|74|2|54 Pivot|\n",
      "|---|---|---|---|---|\n",
      "\n",
      "|Col1|Col2|Col3|Col4|Col5|\n",
      "|---|---|---|---|---|\n",
      "|4|75|74|2|54 Pivot|\n",
      "||||||\n",
      "|4|54 Pivot|74|2|75|\n",
      "||||||\n",
      "|4|2|74|54 Pivot|75|\n",
      "||||||\n",
      "\n",
      "|4|2|54 Pivot|74|75|\n",
      "|---|---|---|---|---|\n",
      "\n",
      "|4|2 Pivot|\n",
      "|---|---|\n",
      "\n",
      "|74|75 Pivot|\n",
      "|---|---|\n",
      "\n",
      "|2 Pivot|4|\n",
      "|---|---|\n",
      "\n",
      "|74|75 Pivot|\n",
      "|---|---|\n",
      "\n",
      "|2|4|54|74|75|\n",
      "|---|---|---|---|---|\n",
      "\n",
      "\n",
      "-----\n",
      "\n",
      "_CHAPTER 8. SORTING_ 67\n",
      "\n",
      "###### 8.4 Insertion Sort\n",
      "\n",
      "Insertion sort is a somewhat interesting algorithm with an expensive runtime of\n",
      "_O(n[2]). It can be best thought of as a sorting scheme similar to that of sorting_\n",
      "a hand of playing cards, i.e. you take one card and then look at the rest with\n",
      "the intent of building up an ordered set of cards in your hand.\n",
      "\n",
      "4 75 74\n",
      "\n",
      "4 75 74 2 54 4 75 74 2 54 4 75 74 2 54\n",
      "\n",
      "2 54\n",
      "\n",
      "4 74 75 2 54 2 4 74 75 54 2 4 54 74 75\n",
      "\n",
      "Figure 8.4: Insertion Sort Iterations [{'source': 'data\\\\md\\\\dsa.md'}]\n",
      "* 1. O(n[2]) comparison-based sorting algorithms [4]: Bubble/Selection/Insertion Sort.\n",
      "These algorithms are slow and usually avoided, but understanding them is important.\n",
      "\n",
      "2. O(n log n) comparison-based sorting algorithms [4]: Merge/Heap/Random Quick Sort.\n",
      "We can use C++ STL sort, partial sort, stable sort, in <algorithm> to achieve\n",
      "this purpose (Java Collections.sort). We only need to specify the required comparison\n",
      "function and these library routines will handle the rest.\n",
      "\n",
      "3. Special purpose sorting algorithms [4]: O(n) Counting Sort, Radix Sort, Bucket Sort.\n",
      "These special purpose algorithms are good to know, as they can speed up the sorting time\n",
      "if the problem has special characteristics, like small range of integers for Counting Sort,\n",
      "but they rarely appear in programming contests.\n",
      "\n",
      "Then, there are basically three ways to search for an item in Array, which we classify as:\n",
      "\n",
      "1. O(n) Linear Search from index 0 to index n 1 (avoid this in programming contests).\n",
      "_−_ [{'source': 'data\\\\md\\\\cp1.md'}]\n",
      "* 1. Insertion is O(1)\n",
      "\n",
      "2. Deletion is O(n)\n",
      "\n",
      "3. Searching is O(n)\n",
      "\n",
      "Out of the three operations the one that stands out is that of insertion. In\n",
      "DSA we chose to always maintain pointers (or more aptly references) to the\n",
      "node(s) at the head and tail of the linked list and so performing a traditional\n",
      "insertion to either the front or back of the linked list is an O(1) operation. An\n",
      "exception to this rule is performing an insertion before a node that is neither\n",
      "the head nor tail in a singly linked list. When the node we are inserting before\n",
      "is somewhere in the middle of the linked list (known as random insertion) the\n",
      "complexity is O(n). In order to add before the designated node we need to\n",
      "traverse the linked list to find that node’s current predecessor. This traversal\n",
      "yields an O(n) run time.\n",
      "\n",
      "This data structure is trivial, but linked lists have a few key points which at\n",
      "times make them very attractive: [{'source': 'data\\\\md\\\\dsa.md'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(query=\"insertion sort\",k=5)\n",
    "for doc in results:\n",
    "    print(f\"* {doc.page_content} [{doc.metadata}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
